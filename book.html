<!DOCTYPE html>
<html>
  <head>
    <link href="./css/bootstrap/bootstrap.css" rel="stylesheet" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link href="./css/bootstrap/bootstrap-responsive.css" rel="stylesheet" />
    <link rel="stylesheet" type="text/css" href="./css/swc.css" />
    <link rel="stylesheet" type="text/css" href="./css/swc-bootstrap.css" />
    <meta http-equiv="last-modified" content="" />
  </head>
  <body>
    <div class="container">
      <div class="row-fluid">
        <div class="span10 offset1">

          <h1>The Unix Shell</h1>

<p>Nelle Nemo, a marine biologist,
has just returned from a six-month survey of the
<a href="http://en.wikipedia.org/wiki/North_Pacific_Gyre">North Pacific Gyre</a>,
where she has been sampling gelatinous marine life in the
<a href="http://en.wikipedia.org/wiki/Great_Pacific_Garbage_Patch">Great Pacific Garbage Patch</a>.
She has 1520 samples in all, and now needs to:</p>

<ol>
  <li>Run each sample through an assay machine
that will measure the relative abundance of 300 different proteins.
The machine's output for a single sample is
a file with one line for each protein.</li>
  <li>Calculate statistics for each of the proteins separately
using a program her supervisor wrote called <code>goostat</code>.</li>
  <li>Compare the statistics for each protein
with corresponding statistics for each other protein
using a program one of the other graduate students wrote called <code>goodiff</code>.</li>
  <li>Write up.
Her supervisor would really like her to do this by the end of the month
so that her paper can appear in an upcoming special issue of <em>Aquatic Goo Letters</em>.</li>
</ol>

<p>It takes about half an hour for the assay machine to process each sample.
The good news is,
it only takes two minutes to set each one up.
Since her lab has eight assay machines that she can use in parallel,
this step will "only" take about two weeks.</p>

<p>The bad news is that if she has to run <code>goostat</code> and <code>goodiff</code> by hand,
she'll have to enter filenames and click "OK" roughly 300<sup>2</sup> times
(300 runs of <code>goostat</code>, plus 300&times;299 runs of <code>goodiff</code>).
At 30 seconds each,
that will take 18 weeks.
Not only would she miss her paper deadline,
the chances of her getting all 90,000 commands right are approximately zero.</p>

<p>The next few lessons will explore what she should do instead.
More specifically,
they explain how she can use a command shell
to automate the repetitive steps in her processing pipeline
so that her computer can work 24 hours a day while she writes her paper.
As a bonus,
once she has put a processing pipeline together,
she will be able to use it again whenever she collects more data.</p>

          <p>The Unix shell has been around longer than most of its users have been alive.
It has survived so long because it's a power tool
that allows people to do complex things with just a few keystrokes.
More importantly,
it helps them combine existing programs in new ways
and automate repetitive tasks
so that they don't have to type the same things over and over again.</p>

          <h2>Introducing the Shell</h2>

          <div class="objectives">
  <h3>Objectives</h3>
  <ul>
    <li>Explain how the shell relates to the keyboard, the screen, the operating system, and users' programs.</li>
    <li>Explain when and why command-line interfaces should be used instead of graphical interfaces.</li>
  </ul>
</div>

<p>At a high level, computers do four things:</p>

<ul>
  <li>run programs;</li>
  <li>store data;</li>
  <li>communicate with each other; and</li>
  <li>interact with us.</li>
</ul>

<p>They can do the last of these in many different ways,
including direct brain-computer links and speech interfaces.
Since these are still in their infancy,
most of us use windows, icons, mice, and pointers.
These technologies didn't become widespread until the 1980s,
but their roots go back to Doug Engelbart's work in the 1960s,
which you can see in what has been called
"<a href="http://video.google.com/videoplay?docid=-8734787622017763097#">The Mother of All Demos</a>".</p>

<p>Going back even further,
the only way to interact with early computers was to rewire them.
But in between,
from the 1950s to the 1980s,
most people used line printers.
These devices only allowed input and output of the letters, numbers, and punctuation found on a standard keyboard,
so programming languages and interfaces had to be designed around that constraint.</p>

<p>This kind of interface is called a
<a href="#gloss:cli">command-line interface</a>, or CLI,
to distinguish it from the
<a href="#gloss:gui">graphical user interface</a>, or GUI,
that most people now use.
The heart of a CLI is a <a href="#gloss:repl">read-evaluate-print loop</a>, or REPL:
when the user types a command and then presses the enter (or return) key,
the computer reads it,
executes it,
and prints its output.
The user then types another command,
and so on until the user logs off.</p>

<p>This description makes it sound as though the user sends commands directly to the computer,
and the computer sends output directly to the user.
In fact,
there is usually a program in between called a
<a href="#gloss:shell">command shell</a>.
What the user types goes into the shell;
it figures out what commands to run and orders the computer to execute them.</p>

<p>A shell is a program like any other.
What's special about it is that its job is to run other programs
rather than to do calculations itself.
The most popular Unix shell is Bash,
the Bourne Again SHell
(so-called because it's derived from a shell written by Stephen Bourne&mdash;this
is what passes for wit among programmers).
Bash is the default shell on most modern implementations of Unix,
and in most packages that provide Unix-like tools for Windows.</p>

<p>Using Bash or any other shell
sometimes feels more like programming than like using a mouse.
Commands are terse (often only a couple of characters long),
their names are frequently cryptic,
and their output is lines of text rather than something visual like a graph.
On the other hand,
the shell allows us to combine existing tools in powerful ways with only a few keystrokes.
and to set up pipelines to handle large volumes of data automatically.
In addition,
the command line is often the easiest way to interact with remote machines.
As clusters and cloud computing become more popular for scientific data crunching,
being able to drive them is becoming a necessary skill.</p>

<div class="keypoints">
  <h3>Key Points</h3>
  <ul>
    <li>A shell is a program whose primary purpose is to read commands and run other programs.</li>
    <li>The shell's main advantages are its high action-to-keystroke ratio,
its support for automating repetitive tasks,
and that it can be used to access networked machines.</li>
    <li>The shell's main disadvantages are its primarily textual nature
and how cryptic its commands and operation can be.</li>
  </ul>
</div>

          <h2>Files and Directories</h2>

          <div class="objectives">
  <h3>Objectives</h3>
  <ul>
    <li>Explain the similarities and differences between a file and a directory.</li>
    <li>Translate an absolute path into a relative path and vice versa.</li>
    <li>Construct absolute and relative paths that identify specific files and directories.</li>
    <li>Explain the steps in the shell's read-run-print cycle.</li>
    <li>Identify the actual command, flags, and filenames in a command-line call.</li>
    <li>Demonstrate the use of tab completion, and explain its advantages.</li>
  </ul>
</div>

<p>The part of the operating system responsible for managing files and directories
is called the <a href="#gloss:filesystem">file system</a>.
It organizes our data into files,
which hold information,
and directories (also called "folders"),
which hold files or other directories.</p>

<p>Several commands are frequently used to create, inspect, rename, and delete files and directories.
To start exploring them,
let's log in to the computer by typing our user ID and password.
Most systems will print stars to obscure the password,
or nothing at all,
in case some evildoer is shoulder surfing behind us:</p>

<pre>login: vlad
password: ********
$</pre>

<p>Once we have logged in we'll see a <a href="#gloss:prompt">prompt</a>,
which is how the shell tells us that it's waiting for input.
This is usually just a dollar sign,
but which may show extra information such as our user ID or the current time.
Type the command <code>whoami</code>,
then press the Enter key (sometimes marked Return) to send the command to the shell.
The command's output is the ID of the current user,
i.e.,
it shows us who the shell thinks we are:</p>

<pre>$ whoami
vlad
$</pre>

<p>More specifically, when we type <code>whoami</code> the shell:</p>

<ol>
  <li>finds a program called <code>whoami</code>,</li>
  <li>runs it,</li>
  <li>waits for it to produce some output (which the shell displays), and</li>
  <li>displays a new prompt to tell us that it's ready for more commands.</li>
</ol>

<p>Next,
let's find out where we are by running a command called <code>pwd</code>
(which stands for "print working directory").
At any moment,
our <a href="#gloss:current-working-directory">current working directory</a>
is our current default directory,
i.e.,
the directory that the computer assumes we want to run commands in
unless we explicitly specify something else.
Here,
the computer's response is <code>/users/vlad</code>,
which is Vlad's <a href="#gloss:home-directory">home directory</a>:</p>

<pre>$ pwd
/users/vlad
$</pre>

<blockquote>
  <h3>Alphabet Soup</h3>

  <p>If the command to find out who we are is <code>whoami</code>, the command to find
out where we are ought to be called <code>whereami</code>, so why is it <code>pwd</code>
instead? The usual answer is that in the early 1970s, when Unix was
first being developed, every keystroke counted: the devices of the day
were slow, and backspacing on a teletype was so painful that cutting the
number of keystrokes in order to cut the number of typing mistakes was
actually a win for usability. The reality is that commands were added to
Unix one by one, without any master plan, by people who were immersed in
its jargon. The result is as inconsistent as the roolz uv Inglish
speling, but we're stuck with it now.</p>
</blockquote>

<p>To understand what a "home directory" is,
let's have a look at how the file system as a whole is organized.
At the top is the <a href="#gloss:root-directory">root directory</a>
that holds everything else.
We refer to it using a slash character <code>/</code> on its own;
this is the leading slash in <code>/users/vlad</code>.</p>

<p>Inside that directory are several other directories:
<code>bin</code> (which is where some built-in programs are stored),
<code>data</code> (for miscellaneous data files),
<code>users</code> (where users' personal directories are located),
<code>tmp</code> (for temporary files that don't need to be stored long-term),
and so on:</p>

<p><img src="bash/novice/img/filesystem.svg" alt="The Filesystem" /></p>

<p>We know that our current working directory <code>/users/vlad</code> is stored inside <code>/users</code>
because <code>/users</code> is the first part of its name.
Similarly,
we know that <code>/users</code> is stored inside the root directory <code>/</code>
because its name begins with <code>/</code>.</p>

<p>Underneath <code>/users</code>,
we find one directory for each user with an account on this machine.
The Mummy's files are stored in <code>/users/imhotep</code>,
Wolfman's in <code>/users/larry</code>,
and ours in <code>/users/vlad</code>,
which is why <code>vlad</code> is the last part of the directory's name.</p>

<p><img src="bash/novice/img/home-directories.svg" alt="Home Directories" /></p>

<blockquote>
  <p>Notice that there are two meanings for the <code>/</code> character.
When it appears at the front of a file or directory name,
it refers to the root directory. When it appears <em>inside</em> a name,
it's just a separator.</p>
</blockquote>

<p>Let's see what's in Vlad's home directory by running <code>ls</code>,
which stands for "listing":</p>

<pre>$ ls
bin          data      mail       music
notes.txt    papers    pizza.cfg  solar
solar.pdf    swc
$</pre>

<p><img src="bash/novice/img/vlad-homedir.svg" alt="Vlad's Home Directory" /></p>

<p><code>ls</code> prints the names of the files and directories in the current directory in alphabetical order,
arranged neatly into columns.
We can make its output more comprehensible by using the <a href="#gloss:command-line-flag">flag</a> <code>-F</code>,
which tells <code>ls</code> to add a trailing <code>/</code> to the names of directories:</p>

<pre>$ ls -F
bin/         data/     mail/      music/
notes.txt    papers/   pizza.cfg  solar/
solar.pdf    swc/
$</pre>

<p>Here,
we can see that <code>/users/vlad</code> contains seven <a href="#gloss:sub-directory">sub-directories</a>.
The names that don't have trailing slashes,
like <code>notes.txt</code>, <code>pizza.cfg</code>, and <code>solar.pdf</code>,
are plain old files.
And note that there is a space between <code>ls</code> and <code>-F</code>:
without it,
the shell thinks we're trying to run a command called <code>ls-F</code>,
which doesn't exist.</p>

<blockquote>
  <h3>What's In A Name?</h3>

  <p>You may have noticed that all of Vlad's files' names are "something dot
something". This is just a convention: we can call a file <code>mythesis</code> or
almost anything else we want. However, most people use two-part names
most of the time to help them (and their programs) tell different kinds
of files apart. The second part of such a name is called the
<a href="#gloss:filename-extension">filename extension</a>, and indicates
what type of data the file holds: <code>.txt</code> signals a plain text file, <code>.pdf</code>
indicates a PDF document, <code>.cfg</code> is a configuration file full of parameters
for some program or other, and so on.</p>

  <p>It's important to remember that this is just a convention. Files contain
bytes: it's up to us and our programs to interpret those bytes according
to the rules for PDF documents, images, and so on. For example, naming a
PNG image of a whale as <code>whale.mp3</code> doesn't somehow magically turn it
into a recording of whalesong.</p>
</blockquote>

<p>Now let's take a look at what's in Vlad's <code>data</code> directory by running the command <code>ls -F data</code>.
The second parameter&mdash;the one <em>without</em> a leading dash&mdash;tells <code>ls</code> that
we want a listing of something other than our current working directory:</p>

<pre>$ ls -F data
amino-acids.txt   elements/     morse.txt
pdb/              planets.txt   sunspot.txt
$</pre>

<p>The output shows us that there are four text files and two sub-sub-directories.
Organizing things hierarchically in this way helps us keep track of our work:
it's possible to put hundreds of files in our home directory,
just as it's possible to pile hundreds of printed papers on our desk,
but it's a self-defeating strategy.</p>

<p>Notice, by the way that we spelled the directory name <code>data</code>.
It doesn't have a trailing slash:
that's added to directory names by <code>ls</code> when we use the <code>-F</code> flag to help us tell things apart.
And it doesn't begin with a slash because it's a <a href="#gloss:relative-path">relative path</a>,
i.e., it tells <code>ls</code> how to find something from where we are,
rather than from the root of the file system.</p>

<p>If we run <code>ls -F /data</code> (<em>with</em> a leading slash) we get a different answer,
because <code>/data</code> is an <a href="#gloss:absolute-path">absolute path</a>:</p>

<pre>$ ls -F /data
access.log    backup/    hardware.cfg
network.cfg
$</pre>

<p>The leading <code>/</code> tells the computer to follow the path from the root of the filesystem,
so it always refers to exactly one directory,
no matter where we are when we run the command.</p>

<p>What if we want to change our current working directory?
Before we do this,
<code>pwd</code> shows us that we're in <code>/users/vlad</code>,
and <code>ls</code> without any parameters shows us that directory's contents:</p>

<pre>$ pwd
/users/vlad
$ ls
bin/         data/     mail/      music/
notes.txt    papers/   pizza.cfg  solar/
solar.pdf    swc/
$</pre>

<p>We can use <code>cd</code> followed by a directory name to change our working directory.
<code>cd</code> stands for "change directory",
which is a bit misleading:
the command doesn't change the directory,
it changes the shell's idea of what directory we are in.</p>

<pre>$ cd data
$</pre>

<p><code>cd</code> doesn't print anything,
but if we run <code>pwd</code> after it, we can see that we are now in <code>/users/vlad/data</code>.
If we run <code>ls</code> without parameters now,
it lists the contents of <code>/users/vlad/data</code>,
because that's where we now are:</p>

<pre>$ pwd
/users/vlad/data
$ ls
amino-acids.txt   elements/     morse.txt
pdb/              planets.txt   sunspot.txt
$</pre>

<p>We now know how to go down the directory tree:
how do we go up?
We could use an absolute path:</p>

<pre>$ cd /users/vlad
$</pre>

<p>but it's almost always simpler to use <code>cd ..</code> to go up one level:</p>

<pre>$ pwd
/users/vlad/data
$ cd ..</pre>

<p><code>..</code> is a special directory name meaning
"the directory containing this one",
or more succinctly,
the <a href="#gloss:parent-directory">parent</a> of the current directory.
Sure enough,
if we run <code>pwd</code> after running <code>cd ..</code>, we're back in <code>/users/vlad</code>:</p>

<pre>$ pwd
/users/vlad
$</pre>

<p>The special directory <code>..</code> doesn't usually show up when we run <code>ls</code>.
If we want to display it, we can give <code>ls</code> the <code>-a</code> flag:</p>

<pre>$ ls -F -a
./           ../       bin/       data/
mail/        music/    notes.txt  papers/
pizza.cfg    solar/    solar.pdf    swc/</pre>

<p><code>-a</code> stands for "show all";
it forces <code>ls</code> to show us file and directory names that begin with <code>.</code>,
such as <code>..</code> (which, if we're in <code>/users/vlad</code>, refers to the <code>/users</code> directory).
As you can see,
it also displays another special directory that's just called <code>.</code>,
which means "the current working directory".
It may seem redundant to have a name for it,
but we'll see some uses for it soon.</p>

<blockquote>
  <h3>Orthogonality</h3>

  <p>The special names <code>.</code> and <code>..</code> don't belong to <code>ls</code>;
they are interpreted the same way by every program.
For example,
if we are in <code>/users/vlad/data</code>,
the command <code>ls ..</code> will give us a listing of <code>/users/vlad</code>.
When the meanings of the parts are the same no matter how they're combined,
programmers say they are <a href="#gloss:orthogonal">orthogonal</a>:
Orthogonal systems tend to be easier for people to learn
because there are fewer special cases and exceptions to keep track of.</p>
</blockquote>

<h3>Nelle's Pipeline: Organizing Files</h3>

<p>Knowing just this much about files and directories,
Nelle is ready to organize the files that the protein assay machine will create.
First,
she creates a directory called <code>north-pacific-gyre</code>
(to remind herself where the data came from).
Inside that,
she creates a directory called <code>2012-07-03</code>,
which is the date she started processing the samples.
She used to use names like <code>conference-paper</code> and <code>revised-results</code>,
but she found them hard to understand after a couple of years.
(The final straw was when she found herself creating
a directory called <code>revised-revised-results-3</code>.)</p>

<blockquote>
  <p>Nelle names her directories "year-month-day",
with leading zeroes for months and days,
because the shell displays file and directory names in alphabetical order.
If she used month names,
December would come before July;
if she didn't use leading zeroes,
November ('11') would come before July ('7').</p>
</blockquote>

<p>Each of her physical samples is labelled according to her lab's convention
with a unique ten-character ID,
such as "NENE01729A".
This is what she used in her collection log
to record the location, time, depth, and other characteristics of the sample,
so she decides to use it as part of each data file's name.
Since the assay machine's output is plain text,
she will call her files <code>NENE01729A.txt</code>, <code>NENE01812A.txt</code>, and so on.
All 1520 files will go into the same directory.</p>

<p>If she is in her home directory,
Nelle can see what files she has using the command:</p>

<pre>$ ls north-pacific-gyre/2012-07-03/</pre>

<p>This is a lot to type,
but she can let the shell do most of the work.
If she types:</p>

<pre>$ ls no</pre>

<p>and then presses tab,
the shell automatically completes the directory name for her:</p>

<pre>$ ls north-pacific-gyre/</pre>

<p>If she presses tab again,
Bash will add <code>2012-07-03/</code> to the command,
since it's the only possible completion.
Pressing tab again does nothing,
since there are 1520 possibilities;
pressing tab twice brings up a list of all the files,
and so on.
This is called <a href="#gloss:tab-completion">tab completion</a>,
and we will see it in many other tools as we go on.</p>

<div class="keypoints">
  <h3>Key Points</h3>
  <ul>
    <li>The file system is responsible for managing information on disk.</li>
    <li>Information is stored in files, which are stored in directories (folders).</li>
    <li>Directories can also store other directories, which forms a directory tree.</li>
    <li><code>/</code> on its own is the root directory of the whole filesystem.</li>
    <li>A relative path specifies a location starting from the current location.</li>
    <li>An absolute path specifies a location from the root of the filesystem.</li>
    <li>Directory names in a path are separated with '/' on Unix, but '' on Windows.</li>
    <li>'..' means "the directory above the current one";
'.' on its own means "the current directory".</li>
    <li>Most files' names are <code>something.extension</code>.
The extension isn't required,
and doesn't guarantee anything,
but is normally used to indicate the type of data in the file.</li>
    <li><code>cd <em>path</em></code> changes the current working directory.</li>
    <li><code>ls <em>path</em></code> prints a listing of a specific file or directory; <code>ls</code> on its own lists the current working directory.</li>
    <li><code>pwd</code> prints the user's current working directory (current default location in the filesystem).</li>
    <li><code>whoami</code> shows the user's current identity.</li>
    <li>Most commands take options (flags) which begin with a '-'.</li>
  </ul>
</div>

<div class="challenges">
  <h3>Challenges</h3>

  <p><img src="bash/novice/img/filesystem-challenge.svg" alt="Filesystem for Challenge Questions" /></p>

  <ol>
    <li>If <code>pwd</code> displays <code>/users/thing</code>, what will <code>ls ../backup</code> display?
      <ol>
        <li><code>../backup: No such file or directory</code></li>
        <li><code>2012-12-01 2013-01-08 2013-01-27</code></li>
        <li><code>2012-12-01/ 2013-01-08/ 2013-01-27/</code></li>
        <li><code>original pnas_final pnas_sub</code></li>
      </ol>
    </li>
    <li>
      <p>If <code>pwd</code> displays <code>/users/backup</code>, what command will display</p>

<pre>pnas-sub/ pnas-final/ original/</pre>

      <ol>
        <li><code>ls pwd</code></li>
        <li><code>ls -r -F</code></li>
        <li><code>ls -r -F /users/backup</code></li>
        <li>Either #2 or #3 above, but not #1.</li>
      </ol>
    </li>
    <li>What does the command <code>cd</code> without a directory name do?
      <ol>
        <li>It has no effect.</li>
        <li>It changes the working directory to <code>/</code>.</li>
        <li>It changes the working directory to the user's home directory.</li>
        <li>It is an error.</li>
      </ol>
    </li>
  </ol>
</div>

	</div>
      </div>

          <h2>Creating Things</h2>

          <div class="objectives">
  <h3>Objectives</h3>
  <ul>
    <li>Create a directory hierarchy that matches a given diagram.</li>
    <li>Create files in that hierarchy using an editor or by copying and renaming existing files.</li>
    <li>Display the contents of a directory using the command line.</li>
    <li>Delete specified files and/or directories.</li>
  </ul>
</div>

<p>We now know how to explore files and directories,
but how do we create them in the first place?
Let's go back to Vlad's home directory,
<code>/users/vlad</code>,
and use <code>ls -F</code> to see what it contains:</p>

<pre>$ pwd
/users/vlad
$ ls -F
bin/         data/     mail/      music/
notes.txt    papers/   pizza.cfg  solar/
solar.pdf    swc/</pre>

<p>Let's create a new directory called <code>thesis</code> using the command <code>mkdir thesis</code>
(which has no output):</p>

<pre>$ mkdir thesis</pre>

<p>As you might (or might not) guess from its name,
<code>mkdir</code> means "make directory".
Since <code>thesis</code> is a relative path
(i.e., doesn't have a leading slash),
the new directory is made below the current working directory:</p>

<pre>$ ls -F
bin/         data/     mail/      music/
notes.txt    papers/   pizza.cfg  solar/
solar.pdf    swc/      thesis/</pre>

<p>However, there's nothing in it yet:</p>

<pre>$ ls -F thesis</pre>

<p>Let's change our working directory to <code>thesis</code> using <code>cd</code>,
then run a text editor called Nano to create a file called <code>draft.txt</code>:</p>

<pre>$ cd thesis
$ nano draft.txt</pre>

<blockquote>
  <h3>Which Editor?</h3>

  <p>When we say, "<code>nano</code> is a text editor," we really do mean "text": it can
only work with plain character data, not tables, images, or any other
human-friendly media. We use it in examples because almost anyone can
drive it anywhere without training, but please use something more
powerful for real work. On Unix systems (such as Linux and Mac OS X),
many programmers use <a href="http://www.gnu.org/software/emacs/">Emacs</a> or
<a href="http://www.vim.org/">Vim</a> (both of which are completely unintuitive,
even by Unix standards), or a graphical editor such as
<a href="http://projects.gnome.org/gedit/">Gedit</a>. On Windows, you may wish to
use <a href="http://notepad-plus-plus.org/">Notepad++</a>.</p>

  <p>No matter what editor you use, you will need to know where it searches
for and saves files. If you start it from the shell, it will (probably)
use your current working directory as its default location. If you use
your computer's start menu, it may want to save files in your desktop or
documents directory instead. You can change this by navigating to
another directory the first time you "Save As..."</p>
</blockquote>

<p>Let's type in a few lines of text,
then use Control-O to write our data to disk:</p>

<p><img src="bash/novice/img/nano-screenshot.png" alt="Nano in Action" /></p>

<p>Once our file is saved,
we can use Control-X to quit the editor and return to the shell.
<code>nano</code> doesn't leave any output on the screen after it exits,
but <code>ls</code> now shows that we have created a file called <code>draft.txt</code>:</p>

<pre>$ ls
draft.txt</pre>

<p>We can run <code>ls</code> with the <code>-s</code> flag (for "size")
to show us how large <code>draft.txt</code> is:</p>

<pre>$ ls -s
   1  draft.txt</pre>

<p>Unfortunately,
Unix reports sizes in <a href="#gloss:disk-block">disk blocks</a> by default,
which might be the least helpful default possible.
If we add the <code>-h</code> flag,
<code>ls</code> switches to more human-friendly units:</p>

<pre>$ ls -s -h
 512  draft.txt</pre>

<p>Here, 512 is the number of bytes in the file.
This is more than we actually typed in because the smallest unit of storage on the disk
is typically a block of 512 bytes.</p>

<p>Let's tidy up by running <code>rm draft.txt</code>:</p>

<pre>$ rm draft.txt</pre>

<p>This command removes files ("rm" is short for "remove").
If we run <code>ls</code> again,
its output is empty once more,
which tells us that our file is gone:</p>

<pre>$ ls</pre>

<blockquote>
  <h3>Deleting Is Forever</h3>

  <p>Unix doesn't have a trash bin: when we delete files, they are unhooked
from the file system so that their storage space on disk can be
recycled. Tools for finding and recovering deleted files do exist, but
there's no guarantee they'll work in any particular situation, since the
computer may recycle the file's disk space right away.</p>
</blockquote>

<p>Let's re-create that file
and then move up one directory to <code>/users/vlad</code> using <code>cd ..</code>:</p>

<pre>$ pwd
/users/vlad/thesis
$ nano draft.txt
$ ls
draft.txt
$ cd ..</pre>

<p>If we try to remove the entire <code>thesis</code> directory using <code>rm thesis</code>,
we get an error message:</p>

<pre>$ rm thesis
rm: cannot remove 'thesis': Is a directory</pre>

<p>This happens because <code>rm</code> only works on files, not directories.
The right command is <code>rmdir</code>,
which is short for "remove directory".
It doesn't work yet either, though,
because the directory we're trying to remove isn't empty:</p>

<pre>$ rmdir thesis
rmdir: failed to remove 'thesis': Directory not empty</pre>

<p>This little safety feature can save you a lot of grief,
particularly if you are a bad typist.
To really get rid of <code>thesis</code> we must first delete the file <code>draft.txt</code>:</p>

<pre>$ rm thesis/draft.txt</pre>

<p>The directory is now empty, so <code>rmdir</code> can delete it:</p>

<pre>$ rmdir thesis</pre>

<blockquote>
  <h3>With Great Power Comes Great Responsibility</h3>

  <p>Removing the files in a directory just so that we can remove the
directory quickly becomes tedious. Instead, we can use <code>rm</code> with the
<code>-r</code> flag (which stands for "recursive"):</p>

<pre>$ rm -r thesis
$</pre>

  <p>This removes everything in the directory, then the directory itself. If
the directory contains sub-directories, <code>rm -r</code> does the same thing to
them, and so on. It's very handy, but can do a lot of damage if used
without care.</p>
</blockquote>

<p>Let's create that directory and file one more time.
(Note that this time we're running <code>nano</code> with the path <code>thesis/draft.txt</code>,
rather than going into the <code>thesis</code> directory and running <code>nano</code> on <code>draft.txt</code> there.)</p>

<pre>$ pwd
/users/vlad/thesis
$ mkdir thesis
$ nano thesis/draft.txt
$ ls thesis
draft.txt</pre>

<p><code>draft.txt</code> isn't a particularly informative name,
so let's change the file's name using <code>mv</code>,
which is short for "move":</p>

<pre>$ mv thesis/draft.txt thesis/quotes.txt</pre>

<p>The first parameter tells <code>mv</code> what we're "moving",
while the second is where it's to go.
In this case,
we're moving <code>thesis/draft.txt</code> to <code>thesis/quotes.txt</code>,
which has the same effect as renaming the file.
Sure enough,
<code>ls</code> shows us that <code>thesis</code> now contains one file called <code>quotes.txt</code>:</p>

<pre>$ ls thesis
quotes.txt</pre>

<p>Just for the sake of inconsistency,
<code>mv</code> also works on directories&mdash;there is no separate <code>mvdir</code> command.</p>

<p>Let's move <code>quotes.txt</code> into the current working directory.
We use <code>mv</code> once again,
but this time we'll just use the name of a directory as the second parameter
to tell <code>mv</code> that we want to keep the filename,
but put the file somewhere new.
(This is why the command is called "move".)
In this case,
the directory name we use is the special directory name <code>.</code> that we mentioned earlier.</p>

<pre>$ mv thesis/quotes.txt .</pre>

<p>The effect is to move the file from the directory it was in to the current working directory.
<code>ls</code> now shows us that <code>thesis</code> is empty:</p>

<pre>$ ls thesis</pre>

<p>Further,
<code>ls</code> with a filename or directory name as an parameter only lists that file or directory.
We can use this to see that <code>quotes.txt</code> is still in our current directory:</p>

<pre>$ ls quotes.txt
quotes.txt</pre>

<p>The <code>cp</code> command works very much like <code>mv</code>,
except it copies a file instead of moving it.
We can check that it did the right thing using <code>ls</code>
with two paths as parameters&mdash;like most Unix commands,
<code>ls</code> can be given thousands of paths at once:</p>

<pre>$ cp quotes.txt thesis/quotations.txt
$ ls quotes.txt thesis/quotations.txt
quotes.txt   thesis/quotations.txt</pre>

<p>To prove that we made a copy,
let's delete the <code>quotes.txt</code> file in the current directory
and then run that same <code>ls</code> again.
This time it tells us that it can't find <code>quotes.txt</code> in the current directory,
but it does find the copy in <code>thesis</code> that we didn't delete:</p>

<pre>$ ls quotes.txt thesis/quotations.txt
ls: cannot access quotes.txt: No such file or directory
thesis/quotations.txt</pre>

<blockquote>
  <h3>Another Useful Abbreviation</h3>

  <p>The shell interprets the character <code>~</code> (tilde) at the start of a path to
mean "the current user's home directory". For example, if Vlad's home
directory is <code>/home/vlad</code>, then <code>~/data</code> is equivalent to
<code>/home/vlad/data</code>. This only works if it is the first character in the
path: <code>here/there/~/elsewhere</code> is <em>not</em> <code>/home/vlad/elsewhere</code>.</p>
</blockquote>

<div class="keypoints">
  <h3>Key Points</h3>
  <ul>
    <li>Unix documentation uses '^A' to mean "control-A".</li>
    <li>The shell does not have a trash bin: once something is deleted, it's really gone.</li>
    <li><code>mkdir path</code> creates a new directory.</li>
    <li><code>cp old new</code> copies a file.</li>
    <li><code>mv old new</code> moves (renames) a file or directory.</li>
    <li><code>nano</code> is a very simple text editor&mdash;please use something else for real work.</li>
    <li><code>touch path</code> creates an empty file if it doesn't already exist.</li>
    <li><code>rm path</code> removes (deletes) a file.</li>
    <li><code>rmdir path</code> removes (deletes) an empty directory.</li>
  </ul>
</div>

<div class="challenges">
  <h3>Challenges</h3>

  <ol>
    <li>
      <p>What is the output of the closing <code>ls</code> command in the sequence shown below?</p>

<pre>$ pwd
/home/thing/data
$ ls
proteins.dat
$ mkdir recombine
$ mv proteins.dat recombine
$ cp recombine/proteins.dat ../proteins-saved.dat
$ ls</pre>
    </li>
    <li>
      <p>Suppose that:</p>

<pre>$ ls -F
analyzed/  fructose.dat    raw/   sucrose.dat</pre>

      <p>What command(s) could you run so that the commands below will produce the output shown?</p>

<pre>$ ls
analyzed   raw
$ ls analyzed
fructose.dat    sucrose.dat</pre>
    </li>
    <li>
      <p>What does <code>cp</code> do when given several filenames and a directory name, as in:</p>

<pre>$ mkdir backup
$ cp thesis/citations.txt thesis/quotations.txt backup</pre>

      <p>What does <code>cp</code> do when given three or more filenames, as in:</p>

<pre>$ ls -F
intro.txt    methods.txt    survey.txt
$ cp intro.txt methods.txt survey.txt</pre>

      <p>Why do you think <code>cp</code>'s behavior is different from <code>mv</code>'s?</p>
    </li>
    <li>
      <p>The command <code>ls -R</code> lists the contents of directories recursively,
i.e., lists their sub-directories, sub-sub-directories, and so on
in alphabetical order at each level.
The command <code>ls -t</code> lists things by time of last change,
with most recently changed files or directories first.
In what order does <code>ls -R -t</code> display things?</p>
    </li>
  </ol>
</div>

          <h2>Loops</h2>

          <div class="objectives">
  <h3>Objectives</h3>
  <ul>
    <li>Write a loop that applies one or more commands separately to each file in a set of files.</li>
    <li>Trace the values taken on by a loop variable during execution of the loop.</li>
    <li>Explain the difference between a variable's name and its value.</li>
    <li>Explain why spaces and some punctuation characters shouldn't be used in files' names.</li>
    <li>Demonstrate how to see what commands have recently been executed.</li>
    <li>Re-run recently executed commands without retyping them.</li>
  </ul>
</div>

<p>Wildcards and tab completion are two ways to reduce typing (and typing mistakes).
Another is to tell the shell to do something over and over again.
Suppose we have several hundred genome data files named <code>basilisk.dat</code>, <code>unicorn.dat</code>, and so on.
When new files arrive,
we'd like to rename the existing ones to <code>original-basilisk.dat</code> and <code>original-unicorn.dat</code>.
We can't use:</p>

<pre>mv *.dat original-*.dat</pre>

<p>because that would expand (in the two-file case) to:</p>

<pre>mv basilisk.dat unicorn.dat</pre>

<p>This wouldn't back up our files:
it would replace the content of <code>unicorn.dat</code> with whatever's in <code>basilisk.dat</code>.</p>

<p>Instead, we can use a <a href="#gloss:for-loop">loop</a>
to do some operation once for each thing in a list.
Here's a simple example that displays the first three lines of each file in turn:</p>

<pre>$ for filename in basilisk.dat unicorn.dat
&gt; do
&gt;    head -3 $filename
&gt; done
COMMON NAME: basilisk
CLASSIFICATION: basiliscus vulgaris
UPDATED: 1745-05-02
COMMON NAME: unicorn
CLASSIFICATION: equus monoceros
UPDATED: 1738-11-24</pre>

<p>When the shell sees the keyword <code>for</code>,
it knows it is supposed to repeat a command (or group of commands) once for each thing in a list.
In this case, the list is the two filenames.
Each time through the loop,
the name of the thing currently being operated on is assigned to
the <a href="#gloss:variable">variable</a> called <code>filename</code>.
Inside the loop,
we get the variable's value by putting <code>$</code> in front of it:
<code>$filename</code> is <code>basilisk.dat</code> the first time through the loop,
<code>unicorn.dat</code> the second,
and so on.
Finally,
the command that's actually being run is our old friend <code>head</code>,
so this loop prints out the first three lines of each data file in turn.</p>

<blockquote>
  <h3>Follow the Prompt</h3>

  <p>The shell prompt changes from <code>$</code> to <code>&gt;</code> and back again as we were
typing in our loop. The second prompt, <code>&gt;</code>, is different to remind
us that we haven't finished typing a complete command yet.</p>
</blockquote>

<p>We have called the variable in this loop <code>filename</code>
in order to make its purpose clearer to human readers.
The shell itself doesn't care what the variable is called;
if we wrote this loop as:</p>

<pre>for x in basilisk.dat unicorn.dat
do
    head -3 $x
done</pre>

<p>or:</p>

<pre>for temperature in basilisk.dat unicorn.dat
do
    head -3 $temperature
done</pre>

<p>it would work exactly the same way.
<em>Don't do this.</em>
Programs are only useful if people can understand them,
so using meaningless names (like <code>x</code>) or misleading names (like <code>temperature</code>)
increases the likelihood of the program being wrong.</p>

<p>Here's a slightly more complicated loop:</p>

<pre>for filename in *.dat
do
    echo $filename
    head -100 $filename | tail -20
done</pre>

<p>The shell starts by expanding <code>*.dat</code> to create the list of files it will process.
The <a href="#gloss:loop-body">loop body</a>
then executes two commands for each of those files.
The first, <code>echo</code>, just prints its command-line parameters to standard output.
For example:</p>

<pre>echo hello there</pre>

<p>prints:</p>

<pre>hello there</pre>

<p>In this case,
since the shell expands <code>$filename</code> to be the name of a file,
<code>echo $filename</code> just prints the name of the file.
Note that we can't write this as:</p>

<pre>for filename in *.dat
do
    $filename
    head -100 $filename | tail -20
done</pre>

<p>because then the first time through the loop,
when <code>$filename</code> expanded to <code>basilisk.dat</code>, the shell would try to run <code>basilisk.dat</code> as a program.
Finally,
the <code>head</code> and <code>tail</code> combination selects lines 81-100 from whatever file is being processed.</p>

<blockquote>
  <h3>Spaces in Names</h3>

  <p>Filename expansion in loops is another reason you should not use spaces in filenames.
Suppose our data files are named:</p>

<pre>basilisk.dat
red dragon.dat
unicorn.dat</pre>

  <p>If we try to process them using:</p>

<pre>for filename in *.dat
do
    head -100 $filename | tail -20
done</pre>

  <p>then the shell will expand <code>*.dat</code> to create:</p>

<pre>basilisk.dat red dragon.dat unicorn.dat</pre>

  <p>With older versions of Bash,
or most other shells,
<code>filename</code> will then be assigned the following values in turn:</p>

<pre>basilisk.dat
red
dragon.dat
unicorn.dat</pre>

  <p>That's a problem: <code>head</code> can't read files called <code>red</code> and <code>dragon.dat</code>
because they don't exist,
and won't be asked to read the file <code>red dragon.dat</code>.</p>

  <p>We can make our script a little bit more robust
by <a href="#gloss:shell-quoting">quoting</a> our use of the variable:</p>

<pre>for filename in *.dat
do
    head -100 "$filename" | tail -20
done</pre>

  <p>but it's simpler just to avoid using spaces (or other special characters) in filenames.</p>
</blockquote>

<p>Going back to our original file renaming problem,
we can solve it using this loop:</p>

<pre>for filename in *.dat
do
    mv $filename original-$filename
done</pre>

<p>This loop runs the <code>mv</code> command once for each filename.
The first time,
when <code>$filename</code> expands to <code>basilisk.dat</code>,
the shell executes:</p>

<pre>mv basilisk.dat original-basilisk.dat</pre>

<p>The second time, the command is:</p>

<pre>mv unicorn.dat original-unicorn.dat</pre>

<blockquote>
  <h3>Measure Twice, Run Once</h3>

  <p>A loop is a way to do many things at once&mdash;or to make many mistakes at
once if it does the wrong thing. One way to check what a loop <em>would</em> do
is to echo the commands it would run instead of actually running them.
For example, we could write our file renaming loop like this:</p>

<pre>for filename in *.dat
do
    echo mv $filename original-$filename
done</pre>

  <p>Instead of running <code>mv</code>, this loop runs <code>echo</code>, which prints out:</p>

<pre>mv basilisk.dat original-basilisk.dat
mv unicorn.dat original-unicorn.dat</pre>

  <p><em>without</em> actually running those commands. We can then use up-arrow to
redisplay the loop, back-arrow to get to the word <code>echo</code>, delete it, and
then press "enter" to run the loop with the actual <code>mv</code> commands. This
isn't foolproof, but it's a handy way to see what's going to happen when
you're still learning how loops work.</p>
</blockquote>

<h3>Nelle's Pipeline: Processing Files</h3>

<p>Nelle is now ready to process her data files.
Since she's still learning how to use the shell,
she decides to build up the required commands in stages.
Her first step is to make sure that she can select the right files&mdash;remember,
these are ones whose names end in 'A' or 'B', rather than 'Z':</p>

<pre>$ cd north-pacific-gyre/2012-07-03
$ for datafile in *[AB].txt
do
    echo $datafile
done
NENE01729A.txt
NENE01729B.txt
NENE01736A.txt
...
NENE02043A.txt
NENE02043B.txt</pre>

<p>Her next step is to decide
what to call the files that the <code>goostat</code> analysis program will create.
Prefixing each input file's name with "stats" seems simple,
so she modifies her loop to do that:</p>

<pre>$ for datafile in *[AB].txt
do
    echo $datafile stats-$datafile
done
NENE01729A.txt stats-NENE01729A.txt
NENE01729B.txt stats-NENE01729B.txt
NENE01736A.txt stats-NENE01736A.txt
...
NENE02043A.txt stats-NENE02043A.txt
NENE02043B.txt stats-NENE02043B.txt
$</pre>

<p>She hasn't actually run <code>goostats</code> yet,
but now she's sure she can select the right files and generate the right output filenames.</p>

<p>Typing in commands over and over again is becoming tedious,
though,
and Nelle is worried about making mistakes,
so instead of re-entering her loop,
she presses the up arrow.
In response,
the shell redisplays the whole loop on one line
(using semi-colons to separate the pieces):</p>

<pre>$ for datafile in *[AB].txt; do echo $datafile stats-$datafile; done</pre>

<p>Using the left arrow key,
Nelle backs up and changes the command <code>echo</code> to <code>goostats</code>:</p>

<pre>$ for datafile in *[AB].txt; do goostats $datafile stats-$datafile; done</pre>

<p>When she presses enter,
the shell runs the modified command.
However, nothing appears to happen&mdash;there is no output.
After a moment, Nelle realizes that since her script doesn't print anything to the screen any longer,
she has no idea whether it is running, much less how quickly.
She kills the job by typing Control-C,
uses up-arrow to repeat the command,
and edits it to read:</p>

<pre>$ for datafile in *[AB].txt; do echo $datafile; goostats $datafile stats-$datafile; done</pre>

<p>When she runs her program now,
it produces one line of output every five seconds or so:</p>

<pre>NENE01729A.txt
NENE01729B.txt
NENE01736A.txt
...</pre>

<p>1518 times 5 seconds,
divided by 60,
tells her that her script will take about two hours to run.
As a final check,
she opens another terminal window,
goes into <code>north-pacific-gyre/2012-07-03</code>,
and uses <code>cat stats-NENE01729B.txt</code>
to examine one of the output files.
It looks good,
so she decides to get some coffee and catch up on her reading.</p>

<blockquote>
  <h3>Those Who Know History Can Choose to Repeat It</h3>

  <p>Another way to repeat previous work is to use the <code>history</code> command to
get a list of the last few hundred commands that have been executed, and
then to use <code>!123</code> (where "123" is replaced by the command number) to
repeat one of those commands. For example, if Nelle types this:</p>

<pre>$ history | tail -5
  456  ls -l NENE0*.txt
  457  rm stats-NENE01729B.txt.txt
  458  goostats NENE01729B.txt stats-NENE01729B.txt
  459  ls -l NENE0*.txt
  460  history</pre>

  <p>then she can re-run <code>goostats</code> on <code>NENE01729B.txt</code> simply by typing
<code>!458</code>.</p>
</blockquote>

<div class="keypoints">
  <h3>Key Points</h3>
  <ul>
    <li>Use a <code>for</code> loop to repeat commands once for every thing in a list.</li>
    <li>Every <code>for</code> loop needs a variable to refer to the current "thing".</li>
    <li>Use <code>$name</code> to expand a variable (i.e., get its value).</li>
    <li>Do not use spaces, quotes, or wildcard characters such as '*' or '?' in filenames, as it complicates variable expansion.</li>
    <li>Give files consistent names that are easy to match with wildcard patterns to make it easy to select them for looping.</li>
    <li>Use the up-arrow key to scroll up through previous commands to edit and repeat them.</li>
    <li>Use <code>history</code> to display recent commands, and <code>!number</code> to repeat a command by number.</li>
  </ul>
</div>

<div class="challenges">
  <h3>Challenges</h3>

  <ol>
    <li>
      <p>Suppose that <code>ls</code> initially displays:</p>

<pre>fructose.dat    glucose.dat   sucrose.dat</pre>

      <p>What is the output of:</p>

<pre>for datafile in *.dat
do
    ls *.dat
done</pre>
    </li>
    <li>
      <p>In the same directory, what is the effect of this loop?</p>

<pre>for sugar in *.dat
do
    echo $sugar
    cat $sugar &gt; xylose.dat
done</pre>

      <ol>
        <li>Prints <code>fructose.dat</code>, <code>glucose.dat</code>, and <code>sucrose.dat</code>, and
copies <code>sucrose.dat</code> to create <code>xylose.dat</code>.</li>
        <li>Prints <code>fructose.dat</code>, <code>glucose.dat</code>, and <code>sucrose.dat</code>, and
concatenates all three files to create <code>xylose.dat</code>.</li>
        <li>Prints <code>fructose.dat</code>, <code>glucose.dat</code>, <code>sucrose.dat</code>, and
<code>xylose.dat</code>, and copies <code>sucrose.dat</code> to create <code>xylose.dat</code>.</li>
        <li>None of the above.</li>
      </ol>
    </li>
    <li>
      <p>The <code>expr</code> does simple arithmetic using command-line parameters:</p>

<pre>$ expr 3 + 5
8
$ expr 30 / 5 - 2
4</pre>

      <p>Given this, what is the output of:</p>

<pre>for left in 2 3
do
    for right in $left
    do
        expr $left + $right
    done
done</pre>
    </li>
    <li>
      <p>Describe in words what the following loop does.</p>

<pre>for how in frog11 prcb redig
do
    $how -limit 0.01 NENE01729B.txt
done</pre>
    </li>
  </ol>
</div>
          <h2>Shell Scripts</h2>

          <div class="objectives">
  <h3>Objectives</h3>
  <ul>
    <li>Write a shell script that runs a command or series of commands for a fixed set of files.</li>
    <li>Run a shell script from the command line.</li>
    <li>Write a shell script that operates on a set of files defined by the user on the command line.</li>
    <li>Create pipelines that include user-written shell scripts.</li>
  </ul>
</div>

<p>We are finally ready to see what makes the shell such a powerful programming environment.
We are going to take the commands we repeat frequently and save them in files
so that we can re-run all those operations again later by typing a single command.
For historical reasons,
a bunch of commands saved in a file is usually called a <a href="#gloss:shell-script">shell script</a>,
but make no mistake:
these are actually small programs.</p>

<p>Let's start by putting the following line in the file <code>middle.sh</code>:</p>

<pre>head -20 cholesterol.pdb | tail -5</pre>

<p>This is a variation on the pipe we constructed earlier:
it selects lines 16-20 of the file <code>cholesterol.pdb</code>.
Remember, we are <em>not</em> running it as a command just yet:
we are putting the commands in a file.</p>

<p>Once we have saved the file,
we can ask the shell to execute the commands it contains.
Our shell is called <code>bash</code>, so we run the following command:</p>

<pre>$ bash middle.sh
ATOM     14  C           1      -1.463  -0.666   1.001  1.00  0.00
ATOM     15  C           1       0.762  -0.929   0.295  1.00  0.00
ATOM     16  C           1       0.771  -0.937   1.840  1.00  0.00
ATOM     17  C           1      -0.664  -0.610   2.293  1.00  0.00
ATOM     18  C           1      -4.705   2.108  -0.396  1.00  0.00</pre>

<p>Sure enough,
our script's output is exactly what we would get if we ran that pipeline directly.</p>

<blockquote>
  <h3>Text vs. Whatever</h3>

  <p>We usually call programs like Microsoft Word or LibreOffice Writer "text
editors", but we need to be a bit more careful when it comes to
programming. By default, Microsoft Word uses <code>.docx</code> files to store not
only text, but also formatting information about fonts, headings, and so
on. This extra information isn't stored as characters, and doesn't mean
anything to tools like <code>head</code>: they expect input files to contain
nothing but the letters, digits, and punctuation on a standard computer
keyboard. When editing programs, therefore, you must either use a plain
text editor, or be careful to save files as plain text.</p>
</blockquote>

<p>What if we want to select lines from an arbitrary file?
We could edit <code>middle.sh</code> each time to change the filename,
but that would probably take longer than just retyping the command.
Instead,
let's edit <code>middle.sh</code> and replace <code>cholesterol.pdb</code> with a special variable called <code>$1</code>:</p>

<pre>$ cat middle.sh
head -20 $1 | tail -5</pre>

<p>Inside a shell script,
<code>$1</code> means "the first filename (or other parameter) on the command line".
We can now run our script like this:</p>

<pre>$ bash middle.sh cholesterol.pdb
ATOM     14  C           1      -1.463  -0.666   1.001  1.00  0.00
ATOM     15  C           1       0.762  -0.929   0.295  1.00  0.00
ATOM     16  C           1       0.771  -0.937   1.840  1.00  0.00
ATOM     17  C           1      -0.664  -0.610   2.293  1.00  0.00
ATOM     18  C           1      -4.705   2.108  -0.396  1.00  0.00</pre>

<p>or on a different file like this:</p>

<pre>$ bash middle.sh vitamin-a.pdb
ATOM     14  C           1       1.788  -0.987  -0.861
ATOM     15  C           1       2.994  -0.265  -0.829
ATOM     16  C           1       4.237  -0.901  -1.024
ATOM     17  C           1       5.406  -0.117  -1.087
ATOM     18  C           1      -0.696  -2.628  -0.641</pre>

<p>We still need to edit <code>middle.sh</code> each time we want to adjust the range of lines,
though.
Let's fix that by using the special variables <code>$2</code> and <code>$3</code>:</p>

<pre>$ cat middle.sh
head $2 $1 | tail $3
$ bash middle.sh vitamin-a.pdb -20 -5
ATOM     14  C           1       1.788  -0.987  -0.861
ATOM     15  C           1       2.994  -0.265  -0.829
ATOM     16  C           1       4.237  -0.901  -1.024
ATOM     17  C           1       5.406  -0.117  -1.087
ATOM     18  C           1      -0.696  -2.628  -0.641</pre>

<p>What if we want to process many files in a single pipeline?
For example, if we want to sort our PDB files by length, we would type:</p>

<pre>$ wc -l *.pdb | sort -n</pre>

<p>because <code>wc -l</code> lists the number of lines in the files
and <code>sort -n</code> sorts things numerically.
We could put this in a file,
but then it would only ever sort a list of PDB files in the current directory.
If we want to be able to get a sorted list of other kinds of files,
we need a way to get all those names into the script.
We can't use <code>$1</code>, <code>$2</code>, and so on
because we don't know how many files there are.
Instead, we use the special variable <code>$*</code>,
which means,
"All of the command-line parameters to the shell script."
Here's an example:</p>

<pre>$ cat sorted.sh
wc -l $* | sort -n
$ bash sorted.sh *.dat backup/*.dat
      29 chloratin.dat
      89 backup/chloratin.dat
      91 sphagnoi.dat
     156 sphag2.dat
     172 backup/sphag-merged.dat
     182 girmanis.dat</pre>

<blockquote>
  <h3>Why Isn't It Doing Anything?</h3>

  <p>What happens if a script is supposed to process a bunch of files, but we
don't give it any filenames? For example, what if we type:</p>

<pre>$ bash sorted.sh</pre>

  <p>but don't say <code>*.dat</code> (or anything else)? In this case, <code>$*</code> expands to
nothing at all, so the pipeline inside the script is effectively:</p>

<pre>wc -l | sort -n</pre>

  <p>Since it doesn't have any filenames, <code>wc</code> assumes it is supposed to
process standard input, so it just sits there and waits for us to give
it some data interactively. From the outside, though, all we see is it
sitting there: the script doesn't appear to do anything.</p>
</blockquote>

<p>We have two more things to do before we're finished with our simple shell scripts.
If you look at a script like:</p>

<pre>wc -l $* | sort -n</pre>

<p>you can probably puzzle out what it does.
On the other hand,
if you look at this script:</p>

<pre># List files sorted by number of lines.
wc -l $* | sort -n</pre>

<p>you don't have to puzzle it out&mdash;the comment at the top tells you what it does.
A line or two of documentation like this make it much easier for other people
(including your future self)
to re-use your work.
The only caveat is that each time you modify the script,
you should check that the comment is still accurate:
an explanation that sends the reader in the wrong direction is worse than none at all.</p>

<p>Second,
suppose we have just run a series of commands that did something useful&mdash;for example,
that created a graph we'd like to use in a paper.
We'd like to be able to re-create the graph later if we need to,
so we want to save the commands in a file.
Instead of typing them in again
(and potentially getting them wrong)
we can do this:</p>

<pre>$ history | tail -4 &gt; redo-figure-3.sh</pre>

<p>The file <code>redo-figure-3.sh</code> now contains:</p>

<pre> 297 goostats -r NENE01729B.txt stats-NENE01729B.txt
 298 goodiff stats-NENE01729B.txt /data/validated/01729.txt &gt; 01729-differences.txt
 299 cut -d ',' -f 2-3 01729-differences.txt &gt; 01729-time-series.txt
 300 ygraph --format scatter --color bw --borders none 01729-time-series.txt figure-3.png</pre>

<p>After a moment's work in an editor to remove the serial numbers on the commands,
we have a completely accurate record of how we created that figure.</p>

<blockquote>
  <h3>Unnumbering</h3>

  <p>Nelle could also use <code>colrm</code> (short for "column removal") to remove the
serial numbers on her previous commands.</p>
</blockquote>

<p>In practice, most people develop shell scripts by running commands at the shell prompt a few times
to make sure they're doing the right thing,
then saving them in a file for re-use.
This style of work allows people to recycle
what they discover about their data and their workflow
with just a few extra keystrokes.</p>

<h3>Nelle's Pipeline: Creating a Script</h3>

<p>An off-hand comment from her supervisor has made Nelle realize that
she should have provided a couple of extra parameters to <code>goostats</code> when she processed her files.
This might have been a disaster if she had done all the analysis by hand,
but thanks to for loops,
it will only take a couple of hours to re-do.</p>

<p>But experience has taught her that if something needs to be done twice,
it will probably need to be done a third or fourth time as well.
She runs the editor and writes the following:</p>

<pre># Calculate reduced stats for data files at J = 100 c/bp.
for datafile in $*
do
    echo $datafile
    goostats -J 100 -r $datafile stats-$datafile
done</pre>

<p>(The parameters <code>-J 100</code> and <code>-r</code> are the ones her supervisor said she should have used.)
She saves this in a file called <code>do-stats.sh</code>
so that she can now re-do the first stage of her analysis by typing:</p>

<pre>$ bash do-stats.sh *[AB].txt</pre>

<p>She can also do this:</p>

<pre>$ bash do-stats.sh *[AB].txt | wc -l</pre>

<p>so that the output is just the number of files processed
rather than the names of the files that were processed.</p>

<p>One thing to note about Nelle's script is that
it lets the person running it decide what files to process.
She could have written it as:</p>

<pre># Calculate reduced stats for  A and Site B data files at J = 100 c/bp.
for datafile in *[AB].txt
do
    echo $datafile
    goostats -J 100 -r $datafile stats-$datafile
done</pre>

<p>The advantage is that this always selects the right files:
she doesn't have to remember to exclude the 'Z' files.
The disadvantage is that it <em>always</em> selects just those files&mdash;she can't run it on all files
(including the 'Z' files),
or on the 'G' or 'H' files her colleagues in Antarctica are producing,
without editing the script.
If she wanted to be more adventurous,
she could modify her script to check for command-line parameters,
and use <code>*[AB].txt</code> if none were provided.
Of course, this introduces another tradeoff between flexibility and complexity.</p>

<div class="keypoints">
  <h3>Key Points</h3>
  <ul>
    <li>Save commands in files (usually called shell scripts) for re-use.</li>
    <li>Use <code>bash filename</code> to run saved commands.</li>
    <li><code>$*</code> refers to all of a shell script's command-line parameters.</li>
    <li><code>$1</code>, <code>$2</code>, etc., refer to specified command-line parameters.</li>
    <li>Letting users decide what files to process is more flexible and more consistent with built-in Unix commands.</li>
  </ul>
</div>

<div class="challenges">
  <h3>Challenges</h3>

  <ol>
    <li>
      <p>Leah has several hundred data files, each of which is formatted like this:</p>

<pre>2013-11-05,deer,5
2013-11-05,rabbit,22
2013-11-05,raccoon,7
2013-11-06,rabbit,19
2013-11-06,deer,2
2013-11-06,fox,1
2013-11-07,rabbit,18
2013-11-07,bear,1</pre>

      <p>Write a shell script called <code>species.sh</code> that takes any number of
filenames as command-line parameters, and uses <code>cut</code>, <code>sort</code>, and
<code>uniq</code> to print a list of the unique species appearing in each of
those files separately.</p>
    </li>
    <li>
      <p>Write a shell script called <code>longest.sh</code> that takes the name of a
directory and a filename extension as its parameters, and prints out
the name of the most recently modified file in that directory with
that extension. For example:</p>

<pre>$ bash largest.sh /tmp/data pdb</pre>

      <p>would print the name of the PDB file in <code>/tmp/data</code> that has been
changed most recently.</p>
    </li>
    <li>
      <p>If you run the command:</p>

<pre>history | tail -5 &gt; recent.sh</pre>

      <p>the last command in the file is the <code>history</code> command itself, i.e.,
the shell has added <code>history</code> to the command log before actually
running it. In fact, the shell <em>always</em> adds commands to the log
before running them. Why do you think it does this?</p>
    </li>
    <li>
      <p>Joel's <code>data</code> directory contains three files: <code>fructose.dat</code>,
<code>glucose.dat</code>, and <code>sucrose.dat</code>. Explain what a script called
<code>example.sh</code> would when run as <code>bash example.sh *.dat</code>
if it contained the following lines:</p>
    </li>
  </ol>

  <table>
  <tr>
    <td valign="top">1.</td>
    <td valign="top">
<pre>
echo *.*</pre>
    </td>
  </tr>
  <tr>
    <td valign="top">2.</td>
    <td valign="top">
<pre>
for filename in $1 $2 $3
do
    cat $filename
done</pre>
    </td>
  </tr>
  <tr>
    <td valign="top">3.</td>
    <td valign="top">
<pre>
echo $*.dat</pre>
    </td>
  </tr>
</table>
</div>

          <h2>Finding Things</h2>

          <div class="objectives">
  <h3>Objectives</h3>
  <ul>
    <li>Use <code>grep</code> to select lines from text files that match simple patterns.</li>
    <li>Use <code>find</code> to find files whose names match simple patterns.</li>
    <li>Use the output of one command as the command-line parameters to another command.</li>
    <li>Explain what is meant by "text" and "binary" files, and why many common tools don't handle the latter well.</li>
  </ul>
</div>

<p>You can guess someone's age by how they talk about search:
young people use "Google" as a verb,
while crusty old Unix programmers use "grep".
The word is a contraction of "global/regular expression/print",
a common sequence of operations in early Unix text editors.
It is also the name of a very useful command-line program.</p>

<p><code>grep</code> finds and prints lines in files that match a pattern.
For our examples,
we will use a file that contains three haikus taken from a
<a href="http://www.salonmagazine.com/21st/chal/1998/01/26chal.html">1998 competition in Salon magazine</a>:</p>

<pre>The Tao that is seen
Is not the true Tao, until
You bring fresh toner.

With searching comes loss
and the presence of absence:
"My Thesis" not found.

Yesterday it worked
Today it is not working
Software is like that.</pre>

<p>Let's find lines that contain the word "not":</p>

<pre>$ grep not haiku.txt
Is not the true Tao, until
"My Thesis" not found
Today it is not working</pre>

<p>Here, <code>not</code> is the pattern we're searching for.
It's pretty simple:
every alphanumeric character matches against itself.
After the pattern comes the name or names of the files we're searching in.
The output is the three lines in the file that contain the letters "not".</p>

<p>Let's try a different pattern: "day".</p>

<pre>$ grep day haiku.txt
Yesterday it worked
Today it is not working</pre>

<p>This time,
the output is lines containing the words "Yesterday" and "Today",
which both have the letters "day".
If we give <code>grep</code> the <code>-w</code> flag,
it restricts matches to word boundaries,
so that only lines with the word "day" will be printed:</p>

<pre>$ grep -w day haiku.txt</pre>

<p>In this case, there aren't any, so <code>grep</code>'s output is empty.</p>

<p>Another useful option is <code>-n</code>, which numbers the lines that match:</p>

<pre>$ grep -n it haiku.txt
5:With searching comes loss
9:Yesterday it worked
10:Today it is not working</pre>

<p>Here, we can see that lines 5, 9, and 10 contain the letters "it".</p>

<p>We can combine flags as we do with other Unix commands.
For example,
since <code>-i</code> makes matching case-insensitive and <code>-v</code> inverts the match,
using them both only prints lines that <em>don't</em> match the pattern
in any mix of upper and lower case:</p>

<pre>$ grep -i -v the haiku.txt
You bring fresh toner.

With searching comes loss

Yesterday it worked
Today it is not working
Software is like that.</pre>

<p><code>grep</code> has lots of other options.
To find out what they are, we can type <code>man grep</code>.
<code>man</code> is the Unix "manual" command:
it prints a description of a command and its options,
and (if you're lucky) provides a few examples of how to use it:</p>

<pre>$ man grep
GREP(1)                                                                                              GREP(1)

NAME
       grep, egrep, fgrep - print lines matching a pattern

SYNOPSIS
       grep [OPTIONS] PATTERN [FILE...]
       grep [OPTIONS] [-e PATTERN | -f FILE] [FILE...]

DESCRIPTION
       grep  searches the named input FILEs (or standard input if no files are named, or if a single hyphen-
       minus (-) is given as file name) for lines containing a match to the given PATTERN.  By default, grep
       prints the matching lines.
       ...        ...        ...

OPTIONS
   Generic Program Information
       --help Print  a  usage  message  briefly summarizing these command-line options and the bug-reporting
              address, then exit.

       -V, --version
              Print the version number of grep to the standard output stream.  This version number should be
              included in all bug reports (see below).

   Matcher Selection
       -E, --extended-regexp
              Interpret  PATTERN  as  an  extended regular expression (ERE, see below).  (-E is specified by
              POSIX.)

       -F, --fixed-strings
              Interpret PATTERN as a list of fixed strings, separated by newlines, any of  which  is  to  be
              matched.  (-F is specified by POSIX.)
    ...        ...        ...</pre>

<blockquote>
  <h3>Wildcards</h3>

<p><code>grep</code>'s real power doesn't come from its options, though; it comes from
the fact that patterns can include wildcards. (The technical name for
these is <a href="#gloss:regular-expression">regular expressions</a>, which
is what the "re" in "grep" stands for.) Regular expressions are complex
enough that we devoted an entire section of the website to them; if you
want to do complex searches, please check it out. As a taster, we can
find lines that have an 'o' in the second position like this:</p>

<pre>$ grep -E '^.o' haiku.txt
You bring fresh toner.
Today it is not working
Software is like that.</pre>

  <p>We use the <code>-E</code> flag and put the pattern in quotes to prevent the shell
from trying to interpret it. (If the pattern contained a '*', for
example, the shell would try to expand it before running <code>grep</code>.) The
'\^' in the pattern anchors the match to the start of the line. The '.'
matches a single character (just like '?' in the shell), while the 'o'
matches an actual 'o'.</p>
</blockquote>

<p>While <code>grep</code> finds lines in files,
the <code>find</code> command finds files themselves.
Again,
it has a lot of options;
to show how the simplest ones work, we'll use the directory tree shown below.</p>

<p><img src="bash/novice/img/find-file-tree.svg" alt="File Tree for Find Example" /></p>

<p>Vlad's home directory contains one file called <code>notes.txt</code> and four subdirectories:
<code>thesis</code> (which is sadly empty),
<code>data</code> (which contains two files <code>first.txt</code> and <code>second.txt</code>),
a <code>tools</code> directory that contains the programs <code>format</code> and <code>stats</code>,
and an empty subdirectory called <code>old</code>.</p>

<p>For our first command,
let's run <code>find . -type d</code>.
<code>.</code> (i.e., the current working directory) is where we want our search to start;
<code>-type d</code> means "things that are directories".
Sure enough,
<code>find</code>'s output is the names of the five directories in our little tree
(including <code>.</code>):</p>

<pre>$ find . -type d
./
./data
./thesis
./tools
./tools/old</pre>

<p>If we change <code>-type d</code> to <code>-type f</code>,
we get a listing of all the files instead:</p>

<pre>$ find . -type f
./data/first.txt
./data/second.txt
./notes.txt
./tools/format
./tools/stats</pre>

<p><code>find</code> automatically goes into subdirectories,
their subdirectories,
and so on to find everything that matches the pattern we've given it.
If we don't want it to,
we can use <code>-maxdepth</code> to restrict the depth of search:</p>

<pre>$ find . -maxdepth 1 -type f
./notes.txt</pre>

<p>The opposite of <code>-maxdepth</code> is <code>-mindepth</code>,
which tells <code>find</code> to only report things that are at or below a certain depth.
<code>-mindepth 2</code> therefore finds all the files that are two or more levels below us:</p>

<pre>$ find . -mindepth 2 -type f
./data/first.txt
./data/second.txt
./tools/format
./tools/stats</pre>

<p>Another option is <code>-empty</code>,
which restricts matches to empty files and directories:</p>

<pre>$ find . -empty
./thesis
./tools/old</pre>

<p>Now let's try matching by name:</p>

<pre>$ find . -name *.txt
./notes.txt</pre>

<p>We expected it to find all the text files,
but it only prints out <code>./notes.txt</code>.
The problem is that the shell expands wildcard characters like <code>*</code> <em>before</em> commands run.
Since <code>*.txt</code> in the current directory expands to <code>notes.txt</code>,
the command we actually ran was:</p>

<pre>$ find . -name notes.txt</pre>

<p><code>find</code> did what we asked; we just asked for the wrong thing.</p>

<p>To get what we want,
let's do what we did with <code>grep</code>:
put <code>*.txt</code> in single quotes to prevent the shell from expanding the <code>*</code> wildcard.
This way,
<code>find</code> actually gets the pattern <code>*.txt</code>, not the expanded filename <code>notes.txt</code>:</p>

<pre>$ find . -name '*.txt'
./data/first.txt
./data/second.txt
./notes.txt</pre>

<p>As we said earlier,
the command line's power lies in combining tools.
We've seen how to do that with pipes;
let's look at another technique.
As we just saw,
<code>find . -name '*.txt'</code> gives us a list of all text files in or below the current directory.
How can we combine that with <code>wc -l</code> to count the lines in all those files?</p>

<p>The simplest way is to put the <code>find</code> command inside <code>$()</code>:</p>

<pre>$ wc -l $(find . -name '*.txt')
  70  ./data/first.txt
 420  ./data/second.txt
  30  ./notes.txt
 520  total
$</pre>

<p>When the shell executes this command,
the first thing it does is run whatever is inside the <code>$()</code>.
It then replaces the <code>$()</code> expression with that command's output.
Since the output of <code>find</code> is the three filenames <code>./data/first.txt</code>, <code>./data/second.txt</code>, and <code>./notes.txt</code>,
the shell constructs the command:</p>

<pre>$ wc -l ./data/first.txt ./data/second.txt ./notes.txt</pre>

<p>which is what we wanted.
This expansion is exactly what the shell does when it expands wildcards like <code>*</code> and <code>?</code>,
but lets us use any command we want as our own "wildcard".</p>

<p>It's very common to use <code>find</code> and <code>grep</code> together.
The first finds files that match a pattern;
the second looks for lines inside those files that match another pattern.
Here, for example, we can find PDB files that contain iron atoms
by looking for the string "FE" in all the <code>.pdb</code> files below the current directory:</p>

<pre>$ grep FE $(find . -name '*.pdb')
./human/heme.pdb:ATOM  25  FE  1  -0.924  0.535  -0.518</pre>

<blockquote>
  <h3>Binary Files</h3>

  <p>We have focused exclusively on finding things in text files. What if
your data is stored as images, in databases, or in some other format?
One option would be to extend tools like <code>grep</code> to handle those formats.
This hasn't happened, and probably won't, because there are too many
formats to support.</p>

  <p>The second option is to convert the data to text, or extract the
text-ish bits from the data. This is probably the most common approach,
since it only requires people to build one tool per data format (to
extract information). On the one hand, it makes simple things easy to
do. On the negative side, complex things are usually impossible. For
example, it's easy enough to write a program that will extract X and Y
dimensions from image files for <code>grep</code> to play with, but how would you
write something to find values in a spreadsheet whose cells contained
formulas?</p>

  <p>The third choice is to recognize that the shell and text processing have
their limits, and to use a programming language such as Python instead.
When the time comes to do this, don't be too hard on the shell: many
modern programming languages, Python included, have borrowed a lot of
ideas from it, and imitation is also the sincerest form of praise.</p>
</blockquote>

<div class="keypoints">
  <h3>Key Points</h3>
  <ul>
    <li>Everything is stored as bytes, but the bytes in binary files do not represent characters.</li>
    <li>Use nested loops to run commands for every combination of two lists of things.</li>
    <li>Use <code>\</code> to break one logical line into several physical lines.</li>
    <li>Use parentheses <code>()</code> to keep things combined.</li>
    <li>Use <code>$(command)</code> to insert a command's output in place.</li>
    <li><code>find</code> finds files with specific properties that match patterns.</li>
    <li><code>grep</code> selects lines in files that match patterns.</li>
    <li><code>man command</code> displays the manual page for a given command.</li>
  </ul>
</div>

<div class="challenges">
  <h3>Challenges</h3>

  <ol>
    <li>
      <p>Write a short explanatory comment for the following shell script:</p>

<pre>find . -name '*.dat' -print | wc -l | sort -n</pre>
    </li>
    <li>
      <p>The <code>-v</code> flag to <code>grep</code> inverts pattern matching, so that only lines
which do <em>not</em> match the pattern are printed. Given that, which of
the following commands will find all files in <code>/data</code> whose names
end in <code>ose.dat</code> (e.g., <code>sucrose.dat</code> or <code>maltose.dat</code>), but do
<em>not</em> contain the word <code>temp</code>?</p>

      <ol>
        <li>
          <p><code>find /data -name '*.dat' -print | grep ose | grep -v temp</code></p>
        </li>
        <li>
          <p><code>find /data -name ose.dat -print | grep -v temp</code></p>
        </li>
        <li>
          <p><code>grep -v temp $(find /data -name '*ose.dat' -print)</code></p>
        </li>
        <li>
          <p>None of the above.</p>
        </li>
      </ol>
    </li>
  </ol>
</div>
          <h1>Version Control with Git</h1>

          <p>Wolfman and Dracula have been hired by Universal Missions
(a space services spinoff from Euphoric State University)
to figure out where the company should send its next planetary lander.
They want to be able to work on the plans at the same time,
but they have run into problems doing this in the past.
If they take turns,
each one will spend a lot of time waiting for the other to finish,
but if they work on their own copies and email changes back and forth
things will be lost, overwritten, or duplicated.</p>

<p>The right solution is to use <a href="../gloss.html#version-control">version control</a>
to manage their work.
Version control is better than mailing files back and forth because:</p>

<ul>
  <li>Nothing that is committed to version control is ever lost.
This means it can be used like the "undo" feature in an editor,
and since all old versions of files are saved
it's always possible to go back in time to see exactly who wrote what on a particular day,
or what version of a program was used to generate a particular set of results.</li>
  <li>It keeps a record of who made what changes when,
so that if people have questions later on,
they know who to ask.</li>
  <li>It's hard (but not impossible) to accidentally overlook or overwrite someone's changes,
because the version control system highlights them automatically.</li>
</ul>

<p>This lesson shows how to use
a popular open source version control system called Git.
It is more complex than some alternatives,
but it is widely used,
primarily because of a hosting site called <a href="http://github.com">GitHub</a>.
No matter which version control system you use,
the most important thing to learn is not the details of their more obscure commands,
but the workflow that they encourage.</p>

          <p>Version control is the lab notebook of the digital world:
it's what professionals use to keep track of what they've done
and to collaborate with other people.
Every large software development project relies on it,
and most programmers use it for their small jobs as well.
And it isn't just for software:
books (like this one),
papers,
small data sets,
and anything that changes over time or needs to be shared
can and should be stored in a version control system.</p>

          <h2>A Better Kind of Backup</h2>

          <p>The first time we use Git on a new machine,
we need to configure a few things:</p>

<pre>$ git config --global user.name "Vlad Dracula"
$ git config --global user.email "vlad@tran.sylvan.ia"
$ git config --global color.ui "auto"
$ git config --global core.editor "nano"</pre>

<p>(Please use your own name and email address instead of Dracula's,
and please make sure you choose an editor that's actually on your system
rather than <code>nano</code>.)</p>

<p>Git commands are written <code>git verb</code>,
where <code>verb</code> is what we actually want it to do.
In this case,
we're telling Git:</p>

<ul>
  <li>our name and email address,</li>
  <li>to colorize output,</li>
  <li>what our favorite text editor is, and</li>
  <li>that we want to use these settings globally (i.e., for every project),</li>
</ul>

<p>The four commands above only need to be run once:
Git will remember the settings until we change them.
Once Git is configured,
we can start using Git.
Let's create a directory for our work:</p>

<pre>$ mkdir planets
$ cd planets</pre>

<p>and tell Git to make it a <a href="../gloss.html#repository">repository</a>:</p>

<pre>$ git init</pre>

<p>If we use <code>ls</code> to show the directory's contents,
it appears that nothing has changed:</p>

<pre>$ ls</pre>

<p>But if we add the <code>-a</code> flag to show everything,
we can see that Git has created a hidden directory called <code>.git</code>:</p>

<pre>$ ls -a
.	..	.git</pre>

<p>Git stores information about the project in this special sub-directory.
If we ever delete it,
we will lose the project's history.</p>

<p>We can ask Git for the status of our project at any time like this:</p>

<pre>$ git status
# On branch master
#
# Initial commit
#
nothing to commit (create/copy files and use "git add" to track)</pre>

<p>We'll explain what <code>branch master</code> means later.
For the moment,
let's add some notes about Mars's suitability as a base.
(We'll <code>cat</code> the text in the file after we edit it so that you can see what we're doing,
but in real life this isn't necessary.
We'll also insert blank lines between groups of shell commands to make them easier to read.)</p>

<pre>$ nano mars.txt
$ cat mars.txt
Cold and dry, but everything is my favorite color
$ ls
mars.txt
$ git status
# On branch master
#
# Initial commit
#
# Untracked files:
#   (use "git add &lt;file&gt;..." to include in what will be committed)
#
#	mars.txt
nothing added to commit but untracked files present (use "git add" to track)</pre>

<p>The "untracked files" message means that there's a file in the directory
that Git isn't keeping track of.
We can tell Git that it should do so like this:</p>

<pre>$ git add mars.txt</pre>

<p>and check that the right thing happened like this:</p>

<pre>$ git status
# On branch master
#
# Initial commit
#
# Changes to be committed:
#   (use "git rm --cached &lt;file&gt;..." to unstage)
#
#	new file:   mars.txt
#</pre>

<p>Git now knows that it's supposed to keep track of this file,
but it hasn't yet recorded any changes for posterity.
To get it to do that,
we need to run one more command:</p>

<pre>$ git commit -m "Starting to think about Mars"
[master (root-commit) f22b25e] Starting to think about Mars
 1 file changed, 1 insertion(+)
 create mode 100644 mars.txt</pre>

<p>When we run <code>git commit</code>,
Git takes everything we have told it to save using <code>git add</code>
and stores a copy permanently inside the special <code>.git</code> directory.
This permanent copy is called a <a href="#gloss:revision">revision</a>.
We use the <code>-m</code> flag (for "message")
to record a comment that will help us remember later on what we did and why.
If we just run <code>git commit</code> without the <code>-m</code> option,
Git will launch <code>nano</code> (or whatever other editor we configured at the start)
so that we can write a longer message.</p>

<p>If we run <code>git status</code> now:</p>

<pre>$ git status
# On branch master
nothing to commit, working directory clean</pre>

<p>it tells us everything is up to date.
If we want to know what we've done recently,
we can ask Git to show us the project's history:</p>

<pre>
$ git log
commit f22b25e3233b4645dabd0d81e651fe074bd8e73b
Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;
Date:   Thu Aug 22 09:51:46 2013 -0400

Starting to think about Mars</pre>

<p>Now suppose Dracula adds more information to the file:</p>

<pre>$ nano mars.txt
$ cat mars.txt
Cold and dry, but everything is my favorite color
The two moons may be a problem for Wolfman</pre>

<p>We don't need to run <code>git add</code> again,
because Git already knows this file is on the list of things it's managing.
If we run <code>git status</code>,
it tells us the file has been modified:</p>

<pre>$ git status
# On branch master
# Changes not staged for commit:
#   (use "git add &lt;file&gt;..." to update what will be committed)
#   (use "git checkout -- &lt;file&gt;..." to discard changes in working directory)
#
#	modified:   mars.txt
#
no changes added to commit (use "git add" and/or "git commit -a")</pre>

<p>The last line is the key phrase:
"no changes added to commit".
We have changed this file,
but we haven't committed to making those changes yet.
Let's double-check our work using <code>git diff</code>,
which shows us the differences between
the current state of the file
and the most recently saved version:</p>

<pre>$ git diff
diff --git a/mars.txt b/mars.txt
index df0654a..315bf3a 100644
--- a/mars.txt
+++ b/mars.txt
@@ -1 +1,2 @@
 Cold and dry, but everything is my favorite color
+The two moons may be a problem for Wolfman</pre>

<p>The output is cryptic because
it is actually a series of commands for tools like editors and <code>patch</code>
telling them how to reconstruct one file given the other.
If we can break it down into pieces:</p>

<ol>
  <li>The first line tells us that Git is using the Unix <code>diff</code> command
to compare the old and new versions of the file.</li>
  <li>The second line tells exactly which <a href="#gloss:revision">revisions</a> of the file
Git is comparing;
<code>df0654a</code> and <code>315bf3a</code> are unique computer-generated labels for those revisions.</li>
  <li>The remaining lines show us the actual differences
and the lines on which they occur.
The numbers between the <code>@@</code> markers indicate which lines we're changing;
the <code>+</code> on the lines below show that we are adding lines.</li>
</ol>

<p>Let's commit our change:</p>

<pre>$ git commit -m "Concerns about Mars's moons on my furry friend"
# On branch master
# Changes not staged for commit:
#   (use "git add &lt;file&gt;..." to update what will be committed)
#   (use "git checkout -- &lt;file&gt;..." to discard changes in working directory)
#
#	modified:   mars.txt
#
no changes added to commit (use "git add" and/or "git commit -a")</pre>

<p>Whoops:
Git won't commit because we didn't use <code>git add</code> first.
Let's do that:</p>

<pre>
$ git add mars.txt
$ git commit -m "Concerns about Mars's moons on my furry friend"
[master 34961b1] Concerns about Mars's moons on my furry friend
 1 file changed, 1 insertion(+)
</pre>

<p>Git insists that we add files to the set we want to commit
before actually committing anything
because we often won't commit everything at once.
For example,
suppose we're adding a few citations to our supervisor's work
to our thesis.
We might want to commit those additions,
and the corresponding addition to the bibliography,
but <em>not</em> commit the work we've been doing on the conclusion.
To allow for this,
Git has a special staging area
where it keeps track of things that have been added to
the current <a href="../gloss.html#change-set">change set</a>
but not yet committed.
<code>git add</code> puts things in this area,
and <code>git commit</code> then copies them to long-term storage:</p>

<p><img src="bash/novice/img/git-staging-area.svg" alt="The Git Staging Area" /></p>

<p>The following commands show this in action:</p>

<pre>$ nano mars.txt
$ cat mars.txt
Cold and dry, but everything is my favorite color
The two moons may be a problem for Wolfman
But the Mummy will appreciate the lack of humidity
$ git diff
diff -git a/mars.txt b/mars.txt
index 315bf3a..b36abfd 100644
--- a/mars.txt
+++ b/mars.txt
@@ -1,2 +1,3 @@
 Cold and dry, but everything is my favorite color
 The two moons may be a problem for Wolfman
+But the Mummy will appreciate the lack of humidity</pre>

<p>So far, so good:
we've made a change,
and <code>git diff</code> tells us what it is.
Now let's put that change in the staging area
and see what <code>git diff</code> reports:</p>

<pre>$ git add mars.txt
$ git diff</pre>

<p>There is no output:
as far as Git can tell,
there's no difference between what it's been asked to save permanently
and what's currently in the directory.
However,
if we do this:</p>

<pre>$ git diff --staged
diff --git a/mars.txt b/mars.txt
index 315bf3a..b36abfd 100644
--- a/mars.txt
+++ b/mars.txt
@@ -1,2 +1,3 @@
 Cold and dry, but everything is my favorite color
 The two moons may be a problem for Wolfman
+But the Mummy will appreciate the lack of humidity</pre>

<p>it shows us the difference between
the last committed change
and what's in the staging area.
Let's save our changes:</p>

<pre>$ git commit -m "Thoughts about the climate"
[master 005937f] Thoughts about the climate
 1 file changed, 1 insertion(+)</pre>

<p>check our status:</p>

<pre>$ git status
# On branch master
nothing to commit, working directory clean</pre>

<p>and look at the history of what we've done so far:</p>

<pre>$ git log
commit 005937fbe2a98fb83f0ade869025dc2636b4dad5
Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;
Date:   Thu Aug 22 10:14:07 2013 -0400

    Thoughts about the climate

commit 34961b159c27df3b475cfe4415d94a6d1fcd064d
Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;
Date:   Thu Aug 22 10:07:21 2013 -0400

    Concerns about Mars's moons on my furry friend

commit f22b25e3233b4645dabd0d81e651fe074bd8e73b
Author: Vlad Dracula &lt;vlad@tran.sylvan.ia&gt;
Date:   Thu Aug 22 09:51:46 2013 -0400

    Starting to think about Mars
</pre>

<p>If we want to see what we changed when,
we use <code>git diff</code> again,
but refer to old versions
using the notation <code>HEAD~1</code>, <code>HEAD~2</code>, and so on:</p>

<pre>$ git diff HEAD~1 mars.txt
diff -git a/mars.txt b/mars.txt
index 315bf3a..b36abfd 100644
--- a/mars.txt
+++ b/mars.txt
@@ -1,2 +1,3 @@
 Cold and dry, but everything is my favorite color
 The two moons may be a problem for Wolfman
+But the Mummy will appreciate the lack of humidity</pre>

<pre>$ git diff HEAD~2 mars.txt
diff -git a/mars.txt b/mars.txt
index df0654a..b36abfd 100644
--- a/mars.txt
+++ b/mars.txt
@@ -1 +1,3 @@
 Cold and dry, but everything is my favorite color
+The two moons may be a problem for Wolfman
+But the Mummy will appreciate the lack of humidity</pre>

<p><code>HEAD</code> means "the most recently saved version".
<code>HEAD~1</code> (pronounced "head minus one")
means "the previous revision".
We can also refer to revisions using
those long strings of digits and letters
that <code>git log</code> displays.
These are unique IDs for the changes,
and "unique" really does mean unique:
every change to any set of files on any machine
has a unique 40-character identifier.
Our first commit was given the ID
f22b25e3233b4645dabd0d81e651fe074bd8e73b,
so let's try this:</p>

<pre>$ git diff f22b25e3233b4645dabd0d81e651fe074bd8e73b mars.txt
diff --git a/mars.txt b/mars.txt
index df0654a..b36abfd 100644
--- a/mars.txt
+++ b/mars.txt
@@ -1 +1,3 @@
 Cold and dry, but everything is my favorite color
+The two moons may be a problem for Wolfman
+But the Mummy will appreciate the lack of humidity</pre>

<p>That's the right answer,
but typing random 40-character strings is annoying,
so Git lets us use just the first few:</p>

<pre>$ git diff f22b25e mars.txt
diff --git a/mars.txt b/mars.txt
index df0654a..b36abfd 100644
--- a/mars.txt
+++ b/mars.txt
@@ -1 +1,3 @@
 Cold and dry, but everything is my favorite color
+The two moons may be a problem for Wolfman
+But the Mummy will appreciate the lack of humidity</pre>

<p>All right:
we can save changes to files and see what we've changed&mdash;how
can we restore older versions of things?
Let's suppose we accidentally overwrite our file:</p>

<pre>$ nano mars.txt
$ cat mars.txt
We will need to manufacture our own oxygen</pre>

<p><code>git status</code> now tells us that the file has been changed,
but those changes haven't been staged:</p>

<pre>$ git status
# On branch master
# Changes not staged for commit:
#   (use "git add &lt;file&gt;..." to update what will be committed)
#   (use "git checkout -- &lt;file&gt;..." to discard changes in working directory)
#
#	modified:   mars.txt
#
no changes added to commit (use "git add" and/or "git commit -a")</pre>

<p>We can put things back the way they were like this:</p>

<pre>$ git reset -hard HEAD
HEAD is now at 005937f Thoughts about the climate

$ cat mars.txt
Cold and dry, but everything is my favorite color
The two moons may be a problem for Wolfman
But the Mummy will appreciate the lack of humidity</pre>

<p>The <code>--hard</code> argument to <code>git reset</code> tells it to throw away local changes:
without that,
<code>git reset</code> won't destroy our work.
<code>HEAD</code> tells <code>git reset</code> that we want to put things back to
the way they were recorded in the <code>HEAD</code> revision.
(Remember,
we haven't done a <code>git commit</code> with these changes yet,
so <code>HEAD</code> is still where it was.)
We can use <code>git reset --hard HEAD~55</code> and so on
to back up to earlier revisions,
<code>git reset --hard 34961b1</code> to back up to a particular revision,
and so on.</p>

<p>But what if we want to recover somes files without losing other work we've done since?
For example,
what if we have added some material to the conclusion of our paper that we'd like to keep,
but we want to get back an earlier version of the introduction?
In that case,
we want to check out an older revision of the file,
so we do something like this:</p>

<pre>$ git checkout 123456 mars.txt</pre>

<p>but use the first few digits of an actual revision number instead of 123456.
To get the right answer,
we must use the revision number that identifies the state of the repository
<em>before</em> the change we're trying to undo.
A common mistake is to use the revision number of
the commit in which we made the change we're trying to get rid of:</p>

<p><img src="bash/novice/img/git-when-revisions-updated.svg" alt="When Git Updates Revision Numbers" /></p>

<p>The fact that files can be reverted one by one
tends to change the way people organize their work.
If everything is in one large document,
it's hard (but not impossible) to undo changes to the introduction
without also undoing changes made later to the conclusion.
If the introduction and conclusion are stored in separate files,
on the other hand,
moving backward and forward in time becomes much easier.</p>

          <h2>Collaborating</h2>

          <p>Version control really comes into its own
when we begin to collaborate with other people.
We already have most of the machinery we need to do this;
the only thing missing is to copy changes from one repository to another.</p>

<p>Systems like Git and Mercurial allow us to move work between any two repositories.
In practice,
though,
it's easiest to use one copy as a central hub,
and to keep it on the web rather than on someone's laptop.
Most programmers use hosting services like <a href="http://github.com">GitHub</a> or <a href="http://bitbucket.org">BitBucket</a>
to hold those master copies;
we'll explore the pros and cons of this in the final section of this lesson.</p>

<p>Let's start by sharing the changes we've made to our current project with the world.
Log in to GitHub,
then create a new repository called <code>planets</code>
using their GUI:</p>

<p><img src="git/novice/img/github-create-repo-01.png" alt="Creating a Repository on GitHub (Step 1)" /></p>

<p><img src="git/novice/img/github-create-repo-02.png" alt="Creating a Repository on GitHub (Step 2)" /></p>

<p><img src="git/novice/img/github-create-repo-03.png" alt="Creating a Repository on GitHub (Step 3)" /></p>

<p>This effectively does the following on GitHub's servers:</p>

<pre>$ mkdir planets
$ cd planets
$ git init</pre>

<p>Our local repository still contains our earlier work on <code>mars.txt</code>,
but the remote repository on GitHub doesn't contain any files yet:</p>

<p><img src="git/novice/img/git-freshly-made-github-repo.svg" alt="Freshly-Made GitHub Repository" /></p>

<p>The next step is to connect the two repositories.
We do this by making the GitHub repository a <a href="../gloss.html#repository-remote">remote</a>
for the local repository.
The home page of the repository on GitHub includes
the string we need to identify it:</p>

<p><img src="git/novice/img/github-find-repo-string.png" alt="Where to Find Repository URL on GitHub" /></p>

<p>For now,
we'll use the 'http' <a href="#gloss:protocol">protocol</a>
(which is also used by web browsers)
since it requires the least setup.
Copy that URL from the browser,
go into the local <code>planets</code> repository,
and run this command:</p>

<pre>$ git remote add origin https://github.com/vlad/planets</pre>

<p>(using your GitHub ID instead of <code>vlad</code>).
We can check that the command has worked by running <code>git remote -v</code>:</p>

<pre>$ git remote -v
origin   https://github.com/vlad/planets.git (push)
origin   https://github.com/vlad/planets.git (fetch)</pre>

<p>There's nothing magic about the name <code>origin</code>,
but we'll see in a moment why it's a sensible choice.
Once this is set up,
this command will push the changes from our local repository
to the repository on GitHub:</p>

<pre>$ git push origin master
Counting objects: 9, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (6/6), done.
Writing objects: 100% (9/9), 821 bytes, done.
Total 9 (delta 2), reused 0 (delta 0)
To https://github.com/vlad/planets
 * [new branch]      master -&gt; master
Branch master set up to track remote branch master from origin.</pre>

<p>Our local and remote repositories are now in this state:</p>

<p><img src="git/novice/img/github-repo-after-first-push.svg" alt="GitHub Repository After First Push" /></p>

<blockquote>
  <h3>The '-u' Flag</h3>

  <p>You may see a <code>-u</code> option used with <code>git push</code>.
This tells Git what <a href="#gloss:branch">branch</a> to use
in the repository you're pushing to.
We discuss branches and branching in our intermediate-level lessons.</p>
</blockquote>

<p>We can pull changes from the remote repository to the local one as well:</p>

<pre>$ git pull origin master
From https://github.com/vlad/planets
 * branch            master     -&gt; FETCH_HEAD
Already up-to-date.</pre>

<p>Pulling has no effect in this case
because the two repositories are already synchronized.
If someone else had pushed some changes,
though,
this command would download them to our local repository.
We can simulate this by going to another directory&mdash;for example, <code>/tmp</code>&mdash;and
<a href="../gloss.html#repository-clone">cloning</a> our GitHub repository:</p>

<pre>$ cd /tmp
$ git clone https://github.com/vlad/planets.git</pre>

<p><code>git clone</code> creates a fresh local copy of a remote repository.
(We did it in <code>/tmp</code> or some other directory so that we don't overwrite our existing <code>planets</code> directory.)
Our computer now has two copies of the repository:</p>

<p><img src="git/novice/img/git-after-duplicate-clone.svg" alt="After Creating Duplicate Clone of Repository" /></p>

<p>Let's make a change in the copy in <code>/tmp/planets</code>:</p>

<pre>$ cd /tmp/planets
$ nano pluto.txt
$ cat pluto.txt
It is so a planet!
$ git add pluto.txt
$ git commit -m "Some notes about Pluto"
 1 file changed, 1 insertion(+)
 create mode 100644 pluto.txt</pre>

<p>then push the change to GitHub:</p>

<pre>$ git push origin master
Counting objects: 4, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (2/2), done.
Writing objects: 100% (3/3), 306 bytes, done.
Total 3 (delta 0), reused 0 (delta 0)
To https://github.com/vlad/planets.git
   9272da5..29aba7c  master -&gt; master</pre>

<p>Our three repositories now look like this:</p>

<p><img src="git/novice/img/git-after-change-to-duplicate-repo.svg" alt="After Pushing Change from Duplicate Repository" /></p>

<p>We can now download changes into the original repository on our machine:</p>

<pre>$ cd ~/planets
$ git pull origin master
remote: Counting objects: 4, done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 3 (delta 0), reused 3 (delta 0)
Unpacking objects: 100% (3/3), done.
From https://github.com/vlad/planets
 * branch            master     -&gt; FETCH_HEAD
Updating 9272da5..29aba7c
Fast-forward
 pluto.txt | 1 +
 1 file changed, 1 insertion(+)
 create mode 100644 pluto.txt</pre>

<p>In practice,
we would probably never have two copies of the same remote repository
on our laptop at once.
Instead,
one of those copies would be on our laptop,
and the other on a lab machine,
or on someone else's computer.
Pushing and pulling changes gives us a reliable way
to share work between different people and machines.</p>

          <h2>Conflicts</h2>

          <p>As soon as people can work in parallel,
someone's going to step on someone else's toes.
This will even happen with a single person:
if we are working on a piece of software on both our laptop and a server in the lab,
we could make different changes to each copy.
Version control helps us manage these <a href="../gloss.html#conflict">conflicts</a>
by giving us tools to <a href="../gloss.html#resolve">resolve</a> overlapping changes.</p>

<p>To see how we can resolve conflicts,
we must first create one.
The file <code>mars.txt</code> currently looks like this
in both local copies of our <code>planets</code> repository
(the one in our home directory and the one in <code>/tmp</code>):</p>

<pre>$ cat mars.txt
Cold and dry, but everything is my favorite color
The two moons may be a problem for Wolfman
But the Mummy will appreciate the lack of humidity</pre>

<p>Let's add a line to the copy under our home directory:</p>

<pre>$ nano mars.txt
$ cat mars.txt
Cold and dry, but everything is my favorite color
The two moons may be a problem for Wolfman
But the Mummy will appreciate the lack of humidity
This line added to our home copy</pre>

<p>and then push the change to GitHub:</p>

<pre>$ git add mars.txt
$ git commit -m "Adding a line in our home copy"
[master 5ae9631] Adding a line in our home copy
 1 file changed, 1 insertion(+)
$ git push origin master
Counting objects: 5, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 352 bytes, done.
Total 3 (delta 1), reused 0 (delta 0)
To https://github.com/vlad/planets
   29aba7c..dabb4c8  master -&gt; master</pre>

<p>Our repositories are now in this state:</p>

<p><img src="git/novice/img/git-after-first-conficting-change.svg" alt="After Making First Change" /></p>

<p>Now let's switch to the copy under <code>/tmp</code>
and make a different change there
<em>without</em> updating from GitHub:</p>

<pre>$ cd /tmp/planets
$ nano mars.txt
$ cat mars.txt
Cold and dry, but everything is my favorite color
The two moons may be a problem for Wolfman
But the Mummy will appreciate the lack of humidity
We added a different line in the temporary copy</pre>

<p>We can commit the change locally:</p>

<pre>$ git add mars.txt
$ git commit -m "Adding a line in the temporary copy"
[master 07ebc69] Adding a line in the temporary copy
 1 file changed, 1 insertion(+)</pre>

<p>but Git won't let us push it to GitHub:</p>

<pre>$ git push origin master
To https://github.com/vlad/planets.git
 ! [rejected]        master -&gt; master (non-fast-forward)
error: failed to push some refs to 'https://github.com/vlad/planets.git'
hint: Updates were rejected because the tip of your current branch is behind
hint: its remote counterpart. Merge the remote changes (e.g. 'git pull')
hint: before pushing again.
hint: See the 'Note about fast-forwards' in 'git push --help' for details.</pre>

<p>Git detects that the changes made in one copy overlap with those made in the other
and stops us from trampling on our previous work.
What we have to do is pull the changes from GitHub,
<a href="../gloss.html#repository-merge">merge</a> them into the copy we're currently working in,
and then push that.
Let's start by pulling:</p>

<pre>$ git pull origin master
remote: Counting objects: 5, done.
remote: Compressing objects: 100% (2/2), done.
remote: Total 3 (delta 1), reused 3 (delta 1)
Unpacking objects: 100% (3/3), done.
From https://github.com/vlad/planets
 * branch            master     -&gt; FETCH_HEAD
Auto-merging mars.txt
CONFLICT (content): Merge conflict in mars.txt
Automatic merge failed; fix conflicts and then commit the result.</pre>

<p><code>git pull</code> tells us there's a conflict,
and marks that conflict in the affected file:</p>

<pre>$ cat mars.txt
Cold and dry, but everything is my favorite color
The two moons may be a problem for Wolfman
But the Mummy will appreciate the lack of humidity
&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD
We added a different line in the temporary copy
=======
This line added to our home copy
&gt;&gt;&gt;&gt;&gt;&gt;&gt; dabb4c8c450e8475aee9b14b4383acc99f42af1d</pre>

<p>Our change&mdash;the one in <code>HEAD</code>&mdash;is preceded by <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt;</code>.
Git has then inserted <code>=======</code> as a separator between the conflicting changes
and marked the end of the content downloaded from GitHub with <code>&gt;&gt;&gt;&gt;&gt;&gt;&gt;</code>.
(The string of letters and digits after that marker
identifies the revision we've just downloaded.)</p>

<p>It is now up to us to edit this file to remove these markers
and reconcile the changes.
We can do anything we want:
keep the change in this branch,
keep the change made in the other,
write something new to replace both,
or get rid of the change entirely.
Let's replace both so that the file looks like this:</p>

<pre>$ cat mars.txt
Cold and dry, but everything is my favorite color
The two moons may be a problem for Wolfman
But the Mummy will appreciate the lack of humidity
We removed the conflict on this line</pre>

<p>To finish merging,
we add <code>mars.txt</code> to the changes being made by the merge
and then commit:</p>

<pre>$ git add mars.txt
$ git status
# On branch master
# All conflicts fixed but you are still merging.
#   (use "git commit" to conclude merge)
#
# Changes to be committed:
#
#	modified:   mars.txt
#
$ git commit -m "Merging changes from GitHub"
[master 2abf2b1] Merging changes from GitHub</pre>

<p>Our repositories now look like this:</p>

<p><img src="git/novice/img/git-after-second-conflicting-change.svg" alt="After Making Second (Conflicting) Change" /></p>

<p>so we push our changes to GitHub:</p>

<pre>$ git push origin master
Counting objects: 10, done.
Delta compression using up to 4 threads.
Compressing objects: 100% (6/6), done.
Writing objects: 100% (6/6), 697 bytes, done.
Total 6 (delta 2), reused 0 (delta 0)
To https://github.com/vlad/planets.git
   dabb4c8..2abf2b1  master -&gt; master</pre>

<p>to get this:</p>

<p><img src="git/novice/img/git-after-merging.svg" alt="After Merging Changes Locally" /></p>

<p>Git keeps track of what we've merged with what,
so we don't have to fix things by hand again
if we switch back to the repository in our home directory and pull from GitHub:</p>

<pre>$ cd ~/planets
$ git pull origin master
remote: Counting objects: 10, done.
remote: Compressing objects: 100% (4/4), done.
remote: Total 6 (delta 2), reused 6 (delta 2)
Unpacking objects: 100% (6/6), done.
From https://github.com/vlad/planets
 * branch            master     -&gt; FETCH_HEAD
Updating dabb4c8..2abf2b1
Fast-forward
 mars.txt | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)</pre>

<p>we get the merged file:</p>

<pre>$ cat mars.txt
Cold and dry, but everything is my favorite color
The two moons may be a problem for Wolfman
But the Mummy will appreciate the lack of humidity
We removed the conflict on this line</pre>

<p>We don't need to merge again because GitHub knows someone has already done that.</p>

<p>Version control's ability to merge conflicting changes
is another reason users tend to divide their programs and papers into multiple files
instead of storing everything in one large file.
There's another benefit too:
whenever there are repeated conflicts in a particular file,
the version control system is essentially trying to tell its users
that they ought to clarify who's responsible for what,
or find a way to divide the work up differently.</p>

          <h2>Open Science</h2>

          <blockquote>
The opposite of "open" isn't "closed".
The opposite of "open" is "broken".
<br />
&mdash; John Wilbanks
</blockquote>

<p>Free sharing of information might be the ideal in science,
but the reality is often more complicated.
Normal practice today looks something like this:</p>

<ul>
  <li>A scientist collects some data and stores it on a machine
that is occasionally backed up by her department.</li>
  <li>She then writes or modifies a few small programs
(which also reside on her machine)
to analyze that data.</li>
  <li>Once she has some results,
she writes them up and submits her paper.
She might include her data&mdash;a growing number of journals require this&mdash;but
she probably doesn't include her code.</li>
  <li>Time passes.</li>
  <li>The journal sends her reviews written anonymously by a handful of other people in her field.
She revises her paper to satisfy them,
during which time she might also modify the scripts she wrote earlier,
and resubmits.</li>
  <li>More time passes.</li>
  <li>The paper is eventually published.
It might include a link to an online copy of her data,
but the paper itself will be behind a paywall:
only people who have personal or institutional access
will be able to read it.</li>
</ul>

<p>For a growing number of scientists,
though,
the process looks like this:</p>

<ul>
  <li>The data that the scientist collects is stored in an open access repository
like <a href="http://figshare.com/">figshare</a> or <a href="http://datadryad.org/">Dryad</a>
as soon as it's collected,
and given its own DOI.</li>
  <li>The scientist creates a new repository on GitHub to hold her work.</li>
  <li>As she does her analysis,
she pushes changes to her scripts
(and possibly some output files)
to that repository.
She also uses the repository for her paper;
that repository is then the hub for collaboration with her colleagues.</li>
  <li>When she's happy with the state of her paper,
she posts a version to <a href="http://arxiv.org/">arXiv</a>
or some other preprint server
to invite feedback from peers.</li>
  <li>Based on that feedback,
she may post several revisions
before finally submitting her paper to a journal.</li>
  <li>The published paper includes links to her preprint
and to her code and data repositories,
which  makes it much easier for other scientists
to use her work as starting point for their own research.</li>
</ul>

<p>This open model accelerates discovery:
the more open work is,
the more widely it is cited and re-used.
However,
people who want to work this way need to make some decisions
about what exactly "open" means in practice.</p>

<h3>Licensing</h3>

<p>The first question is licensing.
Broadly speaking,
there are two kinds of open license for software,
and half a dozen for data and publications.
For software,
people can choose between the <a href="http://opensource.org/licenses/GPL-3.0">GNU Public License</a> (GPL) on the one hand,
and licenses like the <a href="http://opensource.org/licenses/MIT">MIT</a>
and <a href="http://opensource.org/licenses/BSD-2-Clause">BSD</a> licenses on the other.
All of these licenses allow unrestricted sharing and modification of programs,
but the GPL is <a href="../gloss.html#infective-license">infective</a>:
anyone who distributes a modified version of the code
(or anything that includes GPL'd code)
must make <em>their</em> code freely available as well.</p>

<p>Proponents of the GPL argue that this requirement is needed
to ensure that people who are benefiting from freely-available code
are also contributing back to the community.
Opponents counter that many open source projects have had long and successful lives
without this condition,
and that the GPL makes it more difficult to combine code from different sources.
At the end of the day,
what matters most is that:</p>

<ol>
  <li>every project have a file in its home directory
called something like <code>LICENSE</code> or <code>LICENSE.txt</code>
that clearly states what the license is, and</li>
  <li>people use existing licenses rather than writing new ones.</li>
</ol>

<p>The second point is as important as the first:
most scientists are not lawyers,
so wording that may seem sensible to a layperson
may have unintended gaps or consequences.
The <a href="http://opensource.org/">Open Source Initiative</a>
maintains a list of open source licenses,
and <a href="http://www.tldrlegal.com/">tl;drLegal</a> explains many of them in plain English.</p>

<p>When it comes to data, publications, and the like,
scientists have many more options to choose from.
The good news is that an organization called [Creative Commons(http://creativecommons.org/)
has prepared a set of licenses using combinations of four basic restrictions:</p>

<ul>
  <li>Attribution: derived works must give the original author credit for their work.</li>
  <li>No Derivatives: people may copy the work, but must pass it along unchanged.</li>
  <li>Share Alike: derivative works must license their work under the same terms as the original.</li>
  <li>Noncommercial: free use is allowed, but commercial use is not.</li>
</ul>

<p>These four restrictions are abbreviated "BY", "ND", "SA", and "NC" respectively,
so "CC-BY-ND" means,
"People can re-use the work both for free and commercially,
but cannot make changes and must cite the original."
These <a href="http://creativecommons.org/licenses/">short descriptions</a>
summarize the six CC licenses in plain language,
and include links to their full legal formulations.</p>

<p>There is one other important license that doesn't fit into this categorization.
Scientists (and other people) can choose to put material in the public domain,
which is often abbreviated "PD".
In this case,
anyone can do anything they want with it,
without needing to cite the original
or restrict further re-use.
The table below shows how the six Creative Commons licenses and PD relate to one another:</p>

<table border="1">
  <tr>
    <td></td>
    <td colspan="7" align="center">Licenses that can be used for derivative work or adaptation</td>
  </tr>
  <tr>
    <td>Original work</td> <td>by</td> <td>by-nc</td> <td>by-nc-nd</td> <td>by-nc-sa</td> <td>by-nd</td> <td>by-sa</td> <td>pd</td>
  </tr>
  <tr>
    <td>by</td>       <td>X</td> <td>X</td> <td>X</td> <td>X</td> <td>X</td> <td>X</td> <td> </td>
  </tr>
  <tr>
    <td>by-nc</td>    <td> </td> <td>X</td> <td>X</td> <td>X</td> <td> </td> <td> </td> <td> </td>
  </tr>
  <tr>
    <td>by-nc-nd</td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td>
  </tr>
  <tr>
    <td>by-nc-sa</td> <td> </td> <td> </td> <td> </td> <td>X</td> <td> </td> <td> </td> <td> </td>
  </tr>
  <tr>
    <td>by-nd</td>    <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td> </td>
  </tr>
  <tr>
    <td>by-sa</td>    <td> </td> <td> </td> <td> </td> <td> </td> <td> </td> <td>X</td> <td> </td>
  </tr>
  <tr>
    <td>pd</td>       <td>X</td> <td>X</td> <td>X</td> <td>X</td> <td>X</td> <td>X</td> <td>X</td>
  </tr>
</table>

<p><a href="http://software-carpentry.org/license.html">Software Carpentry</a>
uses CC-BY for its lessons and the MIT License for its code
in order to encourage the widest possible re-use.
Again,
the most important thing is for the <code>LICENSE</code> file in the root directory of your project
to state clearly what your license is.
You may also want to include a file called <code>CITATION</code> or <code>CITATION.txt</code>
that describes how to reference your project;
the one for Software Carpentry states:</p>

<pre>To reference Software Carpentry in publications, please cite both of the following:

Greg Wilson: "Software Carpentry: Lessons Learned". arXiv:1307.5448, July 2013.

@online{wilson-software-carpentry-2013,
  author      = {Greg Wilson},
  title       = {Software Carpentry: Lessons Learned},
  version     = {1},
  date        = {2013-07-20},
  eprinttype  = {arxiv},
  eprint      = {1307.5448}
}</pre>

<h3>Hosting</h3>

<p>The second big question for groups that want to open up their work
is where to host their code and data.
One option is for the lab, the department, or the university to provide a server,
manage accounts and backups,
and so on.
The main benefit of this is that it clarifies who owns what,
which is particularly important if any of the material is sensitive
(i.e.,
relates to experiments involving human subjects
or may be used in a patent application).
The main drawbacks are the cost of providing the service and its longevity:
a scientist who has spent ten years collecting data
would like to be sure that data will still be available ten years from now,
but that's well beyond the lifespan of most of the grants that fund academic infrastructure.</p>

<p>The alternative is to use a public hosting service like <a href="http://github.com">GitHub</a>,
<a href="http://bitbucket.org">BitBucket</a>,
<a href="http://code.google.com">Google Code</a>,
or <a href="http://sourceforge.net">SourceForge</a>.
All of these allow people to create repositories through a web interface,
and also provide mailing lists,
ways to keep track of who's doing what,
and so on.
They all benefit from economies of scale and network effects:
it's easier to run one large service well
than to run many smaller services to the same standard,
and it's also easier for people to collaborate if they're using the same service,
not least because it gives them fewer passwords to remember.</p>

<p>However,
all of these services place some constraints on people's work.
In particular,
most give users a choice:
if they're willing to share their work with others,
it will be hosted for free,
but if they want privacy,
they may have to pay.
Sharing might seem like the only valid choice for science,
but many institutions may not allow researchers to do this,
either because they want to protect future patent applications
or simply because what's new is often also frightening.</p>

          <h1>Programming with Python</h1>

<p>We are studying inflammation in patients who have been given a new treatment for
arthritis,
and need to analyze the first dozen data sets.
The data sets are stored in <a href="#gloss:csv">comma-separated values</a> (CSV)
format:
each row holds information for a single patient,
and the columns represent successive days.
The first few rows of our first file look like this:</p>

<pre>0,0,1,3,1,2,4,7,8,3,3,3,10,5,7,4,7,7,12,18,6,13,11,11,7,7,4,6,8,8,4,4,5,7,3, 4,2,3,0,0
0,1,2,1,2,1,3,2,2,6,10,11,5,9,4,4,7,16,8,6,18,4,12,5,12,7,11,5,11,3,3,5,4,4,5,5,1,1,0,1
0,1,1,3,3,2,6,2,5,9,5,7,4,5,4,15,5,11,9,10,19,14,12,17,7,12,11,7,4,2,10,5,4,2,2,3,2,2,1,1
0,0,2,0,4,2,2,1,6,7,10,7,9,13,8,8,15,10,10,7,17,4,4,7,6,15,6,4,9,11,3,5,6,3,3,4,2,3,2,1
0,1,1,3,3,1,3,5,2,4,4,7,6,5,3,10,8,10,6,17,9,14,9,7,13,9,12,6,7,7,9,6,3,2,2,4,2,0,1,1</pre>

<p>We want to:</p>

<ul>
  <li>load that data into memory,</li>
  <li>calculate the average inflammation per day across all patients, and</li>
  <li>plot the result.</li>
</ul>

<p>To do all that, we'll have to learn a little bit about programming.</p>

          <p>The best way to learn how to program is to do something useful,
so this introduction to Python is built around a common scientific task:
data analysis.</p>

<p>Our real goal isn't to teach you Python,
but to teach you the basic concepts that all programming depends on.
We use Python in our lessons because:</p>

<ol>
  <li>we have to use <em>something</em> for examples;</li>
  <li>it's free, well-documented, and runs almost everywhere;</li>
  <li>it has a large (and growing) user base among scientists; and</li>
  <li>experience shows that it's easier for novices to pick up than most other languages.</li>
</ol>

<div class="objectives">
<h3>Objectives</h3>

<ul>
  <li>Explain what a library is, and what libraries are used for.</li>
  <li>Load a Python library and use the things it contains.</li>
  <li>Read tabular data from a file into a program.</li>
  <li>Assign values to variables.</li>
  <li>Select individual values and subsections from data.</li>
  <li>Perform operations on arrays of data.</li>
  <li>Display simple graphs.</li>
</ul>
</div>

<h3>Loading Data</h3>

<p>In order to load the data,
we need to <a href="#gloss:import">import</a> a library called NumPy
that knows how to operate on matrices:</p>

<pre>import numpy</pre>

<p>We can now ask NumPy to read our data file:</p>

<pre>numpy.loadtxt(fname='inflammation-01.csv', delimiter=',')</pre>

<pre>array([[ 0.,  0.,  1., ...,  3.,  0.,  0.],
       [ 0.,  1.,  2., ...,  1.,  0.,  1.],
       [ 0.,  1.,  1., ...,  2.,  1.,  1.],
       ...,
       [ 0.,  1.,  1., ...,  1.,  1.,  1.],
       [ 0.,  0.,  0., ...,  0.,  2.,  0.],
       [ 0.,  0.,  1., ...,  1.,  1.,  0.]])</pre>

<p>The expression <code>numpy.loadtxt(...)</code> means,
"Run the function <code>loadtxt</code> that belongs to the <code>numpy</code> library."
This <a href="#gloss:dotted-notation">dotted notation</a> is used everywhere in
Python
to refer to the parts of larger things.</p>

<p><code>numpy.loadtxt</code> has two <a href="#gloss:parameter">parameters</a>:
the name of the file we want to read,
and the <a href="#gloss:delimiter">delimiter</a> that separates values on a line.
These both need to be character strings (or <a href="#gloss:string">strings</a>
for short),
so we put them in quotes.</p>

<p>When we are finished typing and press Shift+Enter,
the notebook runs our command and shows us its output.
In this case,
the output is the data we just loaded.</p>

<p>Our call to <code>numpy.loadtxt</code> read data into memory,
but didn't save it anywhere.
To do that,
we need to <a href="#gloss:assignment">assign</a> the array to a
<a href="#gloss:variable">variable</a>.
A variable is just a name for some data,
like <code>x</code>, <code>current_temperature</code>, or <code>subject_id</code>.
We assign a new value to a variable using <code>=</code> like this:</p>

<pre>weight_kg = 55</pre>

<p>Once a variable has a value, we can print it:</p>

<pre>print weight_kg</pre>

<pre>55</pre>

<p>and do arithmetic with it:</p>

<pre>print 'weight in pounds:', 2.2 * weight_kg</pre>

<pre>weight in pounds: 121.0</pre>

<p>We can also change a variable's value by assigning it a new one:</p>

<pre>weight_kg = 57.5
print 'weight in kilograms is now:', weight_kg</pre>

<pre>weight in kilograms is now: 57.5</pre>

<p>As the example above shows,
we can print several things at once by separating them with commas.</p>

<p>If we imagine the variable as a sticky note with a name written on it,
assignment is like putting the sticky note on a particular value:</p>

<p><img src="python/novice/img/python-sticky-note-variables-01.svg" alt="Variables as Sticky Notes" /></p>

<p>This means that assigning a value to one variable does <em>not</em> change the values
of other variables.
For example,
let's store the subject's weight in pounds in a variable:</p>

<pre>weight_lb = 2.2 * weight_kg
print 'weight in kilograms:', weight_kg, 'and in pounds:', weight_lb</pre>

<pre>weight in kilograms: 57.5 and in pounds: 126.5</pre>

<p><img src="python/novice/img/python-sticky-note-variables-02.svg" alt="Creating Another Variable" /></p>

<p>and then change <code>weight_kg</code>:</p>

<pre>weight_kg = 100.0
print 'weight in kilograms is now:', weight_kg, 'and weight in pounds is still:', weight_lb</pre>

<pre>weight in kilograms is now: 100.0 and weight in pounds is still: 126.5</pre>

<p><img src="python/novice/img/python-sticky-note-variables-03.svg" alt="Updating a Variable" /></p>

<p>Since <code>wieght_lb</code> doesn't "remember" where its value came from,
it isn't automatically updated when <code>weight_kg</code> changes.
This is different from the way spreadsheets work.</p>

<p>Now that we know how to assign things to variables,
let's re-run <code>numpy.loadtxt</code> and save its result:</p>

<pre>data = numpy.loadtxt(fname='inflammation-01.csv', delimiter=',')</pre>

<p>This statement doesn't produce any output because assignment doesn't display
anything.
If we want to check that our data has been loaded,
we can print the variable's value:</p>

<pre>print data</pre>

<pre>[[ 0.  0.  1. ...,  3.  0.  0.]
 [ 0.  1.  2. ...,  1.  0.  1.]
 [ 0.  1.  1. ...,  2.  1.  1.]
 ...,
 [ 0.  1.  1. ...,  1.  1.  1.]
 [ 0.  0.  0. ...,  0.  2.  0.]
 [ 0.  0.  1. ...,  1.  1.  0.]]</pre>

<h3>Manipulating Data</h3>

<p>Now that our data is in memory,
we can start doing things with it.
First,
let's ask what <a href="#gloss:data-type">type</a> of thing <code>data</code> refers to:</p>

<pre>print type(data)</pre>

<pre>&lt;type 'numpy.ndarray'&gt;</pre>

<p>The output tells us that <code>data</code> currently refers to an N-dimensional array
created by the NumPy library.
We can see what its <a href="#gloss:shape">shape</a> is like this:</p>

<pre>print data.shape</pre>

<pre>(60, 40)</pre>

<p>This tells us that <code>data</code> has 60 rows and 40 columns.
<code>data.shape</code> is a <a href="#gloss:member">member</a> of <code>data</code>,
i.e.,
a value that is stored as part of a larger value.
We use the same dotted notation for the members of values
that we use for the functions in libraries
because they have the same part-and-whole relationship.</p>

<p>If we want to get a single value from the matrix,
we must provide an <a href="#gloss:index">index</a>,
just as we do in math:</p>

<pre>print 'first value in data:', data[0, 0]</pre>

<pre>first value in data: 0.0</pre>

<pre>print 'middle value in data:', data[30, 20]</pre>

<pre>middle value in data: 13.0</pre>

<p>The expression <code>data[30, 20]</code> may not surprise you,
but <code>data[0, 0]</code> might.
Programming languages like Fortran and MATLAB start counting at 1,
because that's what human beings have done for thousands of years.
Languages in the C family (including C++, Java, Perl, and Python) count from 0
because that's simpler for computers to do.
As a result,
if we have an M&times;N array in Python,
its indices go from 0 to M-1 on the first axis
and 0 to N-1 on the second.
It takes a bit of getting used to,
but one way to remember the rule is that
the index is how many steps we have to take from the start to get the item we
want.</p>

<p>An index like <code>[30, 20]</code> selects a single element of an array,
but we can select whole sections as well.
For example,
we can select the first ten days (columns) of values
for the first four (rows) patients like this:</p>

<pre>print data[0:4, 0:10]</pre>

<pre>[[ 0.  0.  1.  3.  1.  2.  4.  7.  8.  3.]
 [ 0.  1.  2.  1.  2.  1.  3.  2.  2.  6.]
 [ 0.  1.  1.  3.  3.  2.  6.  2.  5.  9.]
 [ 0.  0.  2.  0.  4.  2.  2.  1.  6.  7.]]</pre>

<p>The <a href="#gloss:slice">slice</a> <code>0:4</code> means,
"Start at index 0 and go up to, but not including, index 4."
Again,
the up-to-but-not-including takes a bit of getting used to,
but the rule is that the difference between the upper and lower bounds is the
number of values in the slice.</p>

<p>We don't have to start slices at 0:</p>

<pre>print data[5:10, 0:10]</pre>

<pre>[[ 0.  0.  1.  2.  2.  4.  2.  1.  6.  4.]
 [ 0.  0.  2.  2.  4.  2.  2.  5.  5.  8.]
 [ 0.  0.  1.  2.  3.  1.  2.  3.  5.  3.]
 [ 0.  0.  0.  3.  1.  5.  6.  5.  5.  8.]
 [ 0.  1.  1.  2.  1.  3.  5.  3.  5.  8.]]</pre>

<p>and we don't have to take all the values in the slice&mdash;if we provide a
<a href="#gloss:stride">stride</a>,
Python takes values spaced that far apart:</p>

<pre>print data[0:10:3, 0:10:2]</pre>

<pre>[[ 0.  1.  1.  4.  8.]
 [ 0.  2.  4.  2.  6.]
 [ 0.  2.  4.  2.  5.]
 [ 0.  1.  1.  5.  5.]]</pre>

<p>Here,
we have taken rows 0, 3, 6, and 9,
and columns 0, 2, 4, 6, and 8.
(Again, we always include the lower bound,
but stop when we reach or cross the upper bound.)</p>

<p>We also don't have to include the upper and lower bound on the slice.
If we don't include the lower bound,
Python uses 0 by default;
if we don't include the upper,
the slice runs to the end of the axis,
and if we don't include either
(i.e., if we just use ':' on its own),
the slice includes everything:</p>

<pre>small = data[:3, 36:]
print 'small is:'
print small</pre>

<pre>small is:
[[ 2.  3.  0.  0.]
 [ 1.  1.  0.  1.]
 [ 2.  2.  1.  1.]]</pre>

<p>Arrays also know how to perform common mathematical operations on their values.
If we want to find the average inflammation for all patients on all days,
for example,
we can just ask the array for its mean value</p>

<pre>print data.mean()</pre>

<pre>6.14875</pre>

<p><code>mean</code> is a <a href="#gloss:method">method</a> of the array,
i.e.,
a function that belongs to it
in the same way that the member <code>shape</code> does.
If values are nouns, methods are verbs:
they are what the thing in question knows how to do.</p>

<p>NumPy arrays have lots of useful methods:</p>

<pre>print 'maximum inflammation:', data.max()
print 'minimum inflammation:', data.min()
print 'standard deviation:', data.std()</pre>

<pre>maximum inflammation: 20.0
minimum inflammation: 0.0
standard deviation: 4.61383319712</pre>

<p>When analyzing data,
though,
we often want to look at partial statistics,
such as the maximum value per patient
or the average value per day.
One way to do this is to select the data we want to create a new temporary
array,
then ask it to do the calculation:</p>

<pre>patient_0 = data[0, :] # 0 on the first axis, everything on the second
print 'maximum inflammation for patient 0:', patient_0.max()</pre>

<pre>maximum inflammation for patient 0: 18.0</pre>

<p>We don't actually need to store the row in a variable of its own.
Instead, we can combine the selection and the method call:</p>

<pre>print 'maximum inflammation for patient 2:', data[2, :].max()</pre>

<pre>maximum inflammation for patient 2: 19.0</pre>

<p>What if we need the maximum inflammation for <em>all</em> patients,
or the average for each day?
As the diagram below shows,
we want to perform the operation across an axis:</p>

<p><img src="python/novice/img/python-operations-across-axes.svg" alt="Operations Across Axes" /></p>

<p>To support this,
most array methods allow us to specify the axis we want to work on.
If we ask for the average across axis 0,
we get:</p>

<pre>print data.mean(axis=0)</pre>

<pre>[  0.           0.45         1.11666667   1.75         2.43333333   3.15
   3.8          3.88333333   5.23333333   5.51666667   5.95         5.9
   8.35         7.73333333   8.36666667   9.5          9.58333333
  10.63333333  11.56666667  12.35        13.25        11.96666667
  11.03333333  10.16666667  10.           8.66666667   9.15         7.25
   7.33333333   6.58333333   6.06666667   5.95         5.11666667   3.6
   3.3          3.56666667   2.48333333   1.5          1.13333333
   0.56666667]</pre>

<p>As a quick check,
we can ask this array what its shape is:</p>

<pre>print data.mean(axis=0).shape</pre>

<pre>(40,)</pre>

<p>The expression <code>(40,)</code> tells us we have an N&times;1 vector,
so this is the average inflammation per day for all patients.
If we average across axis 1, we get:</p>

<pre>print data.mean(axis=1)</pre>

<pre>[ 5.45   5.425  6.1    5.9    5.55   6.225  5.975  6.65   6.625  6.525
  6.775  5.8    6.225  5.75   5.225  6.3    6.55   5.7    5.85   6.55
  5.775  5.825  6.175  6.1    5.8    6.425  6.05   6.025  6.175  6.55
  6.175  6.35   6.725  6.125  7.075  5.725  5.925  6.15   6.075  5.75
  5.975  5.725  6.3    5.9    6.75   5.925  7.225  6.15   5.95   6.275  5.7
  6.1    6.825  5.975  6.725  5.7    6.25   6.4    7.05   5.9  ]</pre>

<p>which is the average inflammation per patient across all days.</p>

<h3>Plotting</h3>

<p>The mathematician Richard Hamming once said,
"The purpose of computing is insight, not numbers,"
and the best way to develop insight is often to visualize data.
Visualization deserves an entire lecture (or course) of its own,
but we can explore a few features of Python's <code>matplotlib</code> here.
First,
let's tell the IPython Notebook that we want our plots displayed inline,
rather than in a separate viewing window:</p>

<pre>%matplotlib inline</pre>

<p>The <code>%</code> at the start of the line signals that this is a command for the
notebook,
rather than a statement in Python.
Next,
we will import the <code>pyplot</code> module from <code>matplotlib</code>
and use two of its functions to create and display a heat map of our data:</p>

<pre>from matplotlib import pyplot
pyplot.imshow(data)
pyplot.show()</pre>

<p><img src="python/novice/img/initial-heat-map.png" alt="Initial Heat Map" /></p>

<p>Blue regions in this heat map are low values, while red shows high values.
As we can see,
inflammation rises and falls over a 40-day period.
Let's take a look at the average inflammation over time:</p>

<pre>ave_inflammation = data.mean(axis=0)
pyplot.plot(ave_inflammation)
pyplot.show()</pre>

<p><img src="python/novice/img/ave-inflammation-over-time.png" alt="Average Inflammation Over Time" /></p>

<p>Here,
we have put the average per day across all patients in the variable
<code>ave_inflammation</code>,
then asked <code>pyplot</code> to create and display a line graph of those values.
The result is roughly a linear rise and fall,
which is suspicious:
based on other studies,
we expect a sharper rise and slower fall.
Let's have a look at two other statistics:</p>

<pre>print 'maximum inflammation per day'
pyplot.plot(data.max(axis=0))
pyplot.show()

print 'minimum inflammation per day'
pyplot.plot(data.min(axis=0))
pyplot.show()</pre>

<p><img src="python/novice/img/max-inflammation-over-time.png" alt="Maximum Inflammation per Day" /></p>

<p><img src="python/novice/img/min-inflammation-over-time.png" alt="Minimum Inflammation per Day" /></p>

<p>The maximum value rises and falls perfectly smoothly,
while the minimum seems to be a step function.
Neither result seems particularly likely,
so either there's a mistake in our calculations
or something is wrong with our data.</p>

<h3>Wrapping Up</h3>

<p>It's very common to create an <a href="#gloss:alias-library">alias</a> for a
library when importing it
in order to reduce the amount of typing we have to do.
Here are our three plots side by side using aliases for <code>numpy</code> and <code>pyplot</code>:</p>

<pre>import numpy as np
from matplotlib import pyplot as plt

data = np.loadtxt(fname='inflammation-01.csv', delimiter=',')

plt.figure(figsize=(10.0, 3.0))

plt.subplot(1, 3, 1)
plt.ylabel('average')
plt.plot(data.mean(0))

plt.subplot(1, 3, 2)
plt.ylabel('max')
plt.plot(data.max(0))

plt.subplot(1, 3, 3)
plt.ylabel('min')
plt.plot(data.min(0))

plt.tight_layout()
plt.show()</pre>

<p><img src="python/novice/img/combined-inflammation-over-time.png" alt="Combined Inflammation per Day" /></p>

<p>The first two lines re-load our libraries as <code>np</code> and <code>plt</code>,
which are the aliases most Python programmers use.
The call to <code>loadtxt</code> reads our data,
and the rest of the program tells the plotting library
how large we want the figure to be,
that we're creating three sub-plots,
what to draw for each one,
and that we want a tight layout.
(Perversely,
if we leave out that call on line 20,
the layout will actually be squeezed more than with it.)</p>

<div class="keypoints">
<h3>Key Points</h3>

<ul>
  <li>Import a library into a program using <code>import libraryname</code>.</li>
  <li>Use the <code>numpy</code> library to work with arrays in Python.</li>
  <li>Use <code>variable = value</code> to assign a value to a variable.</li>
  <li>Variables are created on demand whenever a value is assigned to them.</li>
  <li>Use <code>print something</code> to display the value of <code>something</code>.</li>
  <li>The expression <code>array.shape</code> gives the shape of an array.</li>
  <li>Use <code>array[x, y]</code> to select a single element from an array.</li>
  <li>Array indices start at 0, not 1.</li>
  <li>Use <code>low:high</code> to specify a slice that includes the indices from <code>low</code> to
<code>high-1</code>.</li>
  <li>All the indexing and slicing that works on arrays also works on strings.</li>
  <li>Use <code># some kind of explanation</code> to add comments to programs.</li>
  <li>Use <code>array.mean()</code>, <code>array.max()</code>, and <code>array.min()</code> to calculate simple
statistics.</li>
  <li>Use <code>array.mean(axis=0)</code> or <code>array.mean(axis=1)</code> to calculate statistics
across the specified axis.</li>
  <li>Use the <code>pyplot</code> library from <code>matplotlib</code> for creating simple
visualizations.</li>
</ul>
</div>

<div class="challenges">
<h3>Challenges</h3>

<ol>
  <li>
    <p>Draw diagrams showing what variables refer to what values after each
statement in the following program:</p>
<pre>mass = 47.5
age = 122
mass = mass * 2.0
age = age - 20</pre>
  </li>
  <li>
    <p>What does the following program print out?</p>
<pre>
first, second = 'Grace', 'Hopper'
third, fourth = second, first
print third, fourth</pre>
  </li>
</ol>

<p>A subsection of an array is called a <a href="#gloss:slice">slice</a>.
We can take slices of character strings as well:</p>

<pre>element = 'oxygen'
print 'first three characters:', element[0:3]
print 'last three characters:', element[3:6]</pre>

<pre>first three characters: oxy
last three characters: gen</pre>

<ol>
  <li>
    <p>What is the value of <code>element[:4]</code>?
What about <code>element[4:]</code>?
Or <code>element[:]</code>?</p>
  </li>
  <li>
    <p>What is <code>element[-1]</code>?
What is <code>element[-2]</code>?
Given those answers,
explain what <code>element[1:-1]</code> does.</p>
  </li>
  <li>
    <p>The expression <code>element[3:3]</code> produces an <a href="../../gloss.html#empty-string">empty string</a>,
i.e., a string that contains no characters.
If <code>data</code> holds our array of patient data,
what does <code>data[3:3, 4:4]</code> produce?
What about <code>data[3:3, :]</code>?</p>
  </li>
  <li>
    <p>Why do all of our plots stop just short of the upper end of our graph?
Why are the vertical lines in our plot of the minimum inflammation per day
not vertical?</p>
  </li>
  <li>
    <p>Create a plot showing the standard deviation of the inflammation data for
each day across all patients.</p>
  </li>
</ol>

<ol>
  <li>Modify the program to display the three plots on top of one another instead
of side by side.</li>
</ol>
</div>

          <h2>Creating Functions</h2>

<p>If we only had one data set to analyze,
it would probably be faster to load the file into a spreadsheet
and use that to plot some simple statistics.
But we have twelve files to check,
and may have more in future.
In this lesson,
we'll learn how to write a function
so that we can repeat several operations with a single command.</p>

<h3>Objectives</h3>

<ul>
  <li>Define a function that takes parameters.</li>
  <li>Return a value from a function.</li>
  <li>Explain what a call stack is, and trace changes to the call stack as
functions are called.</li>
  <li>Set default values for function parameters.</li>
  <li>Explain why we should divide programs into small, single-purpose functions.</li>
</ul>

<h3>Defining a Function</h3>

<p>Let's start by definition a function <code>fahr_to_kelvin</code> that converts temperatures
from Fahrenheit to Kelvin:</p>

<pre>def fahr_to_kelvin(temp):
    return ((temp - 32.0) * (5.0/9.0)) + 273.15</pre>

<p>The definition opens with the word <code>def</code>,
which is followed by the name of the function
and a parenthesized list of parameter names.
When we call the function,
the values we pass to it are assigned to those variables
so that we can use them inside the function.
Inside the function,
we use a <a href="#gloss:return-statement">return statement</a> to send a result
back to whoever asked for it.</p>

<p>Let's try running our function:</p>

<pre>print 'freezing point of water:', fahr_to_kelvin(32)
print 'boiling point of water:', fahr_to_kelvin(212)</pre>

<pre>freezing point of water: 273.15
boiling point of water: 373.15</pre>

<p>That looks right, but why did we write <code>5.0/9.0</code> instead of <code>5/9</code>?
Let's try re-defining the function to use the simpler expression:</p>

<pre>def fahr_to_kelvin_2(temp):
    return ((temp - 32) * (5/9)) + 273.15

print 'freezing point of water:', fahr_to_kelvin_2(32)
print 'boiling point of water:', fahr_to_kelvin_2(212)</pre>

<pre>freezing point of water: 273.15
boiling point of water: 273.15</pre>

<p>The freezing point is right,
but the boiling point is wrong.
Here's the reason:</p>

<pre>print '5.0/9.0 is:', 5.0/9.0
print 'but 5/9 is:', 5/9</pre>

<pre>5.0/9.0 is: 0.555555555556
but 5/9 is: 0</pre>

<p>Computers store numbers in one of two ways:
as <a href="#gloss:integer">integers</a>
or as <a href="#gloss:float">floating-point numbers</a> (or floats).
The first are the numbers we usually count with;
the second have fractional parts.
Addition, subtraction and multiplication work on both as we'd expect,
but division works differently.
If we divide one integer by another,
we get the quotient without the remainder:</p>

<pre>print '10/3 is:', 10/3</pre>

<pre>10/3 is: 3</pre>

<p>If either part of the division is a float,
on the other hand,
the computer creates a floating-point answer:</p>

<pre>print '10.0/3 is:', 10.0/3</pre>

<pre>10.0/3 is: 3.33333333333</pre>

<p>The computer does this for historical reasons:
integer operations were much faster on early machines,
and this behavior is actually useful in a lot of situations.
It's still confusing,
though,
so Python 3 produces a floating-point answer when dividing integers if it needs
to.
We're still using Python 2.7 in this class,
though,
so if we want 5/9 to give us the right answer,
we have to write it as 5.0/9, 5/9.0, or some other variation.</p>

<p>Back to defining functions...
Now that we've seen how to turn Fahrenheit into Kelvin,
it's easy to turn Kelvin into Celsius:</p>

<pre>def kelvin_to_celsius(temp):
    return temp - 273.15

print 'absolute zero in Celsius:', kelvin_to_celsius(0.0)</pre>

<pre>absolute zero in Celsius: -273.15</pre>

<p>What about converting Fahrenheit to Celsius?
We could write out the formula,
but we don't need to.
Instead,
we can <a href="#gloss:function-composition">compose</a> the two functions we
have already created:</p>

<pre>def fahr_to_celsius(temp):
    temp_k = fahr_to_kelvin(temp)
    result = kelvin_to_celsius(temp_k)
    return result

print 'freezing point of water in Celsius:', fahr_to_celsius(32.0)</pre>

<pre>freezing point of water in Celsius: 0.0</pre>

<p>This is our first taste of how larger programs are built:
we define basic operations,
then combine them in ever-large chunks to get the effect we want.</p>

<h3>The Call Stack</h3>

<p>Let's take a closer look at what happens when we call <code>fahr_to_celsius(32.0)</code>.
To make things clearer,
we'll start by putting the initial value 32.0 in a variable
and store the final result in one as well:</p>

<pre>original = 32.0
final = fahr_to_celsius(original)</pre>

<p>The diagram below shows what memory looks like after the first line has been
executed:</p>

<p><img src="python/novice/img/python-call-stack-01.svg" alt="Call Stack (Initial State)" /></p>

<p>When we call <code>fahr_to_celsius</code>,
Python <em>doesn't</em> create the variable <code>temp</code> right away.
Instead,
it creates something called a <a href="#gloss:stack-frame">stack frame</a>
to keep track of the variables defined by <code>fahr_to_kelvin</code>.
Initially,
this stack frame only holds the value of <code>temp</code>:</p>

<p><img src="python/novice/img/python-call-stack-02.svg" alt="Call Stack Immediately After First Function Call" /></p>

<p>When we call <code>fahr_to_kelvin</code> inside <code>fahr_to_celsius</code>,
Python creates another stack frame to hold <code>fahr_to_kelvin</code>'s variables:</p>

<p><img src="python/novice/img/python-call-stack-03.svg" alt="Call Stack During First Nested Function Call" /></p>

<p>It does this because there are now two variables in play called <code>temp</code>:
the parameter to <code>fahr_to_celsius</code>,
and the parameter to <code>fahr_to_kelvin</code>.
Having two variables with the same name in the same part of the program would be
ambiguous,
so Python (and every other modern programming language) creates a new stack
frame for each function call
to keep that function's variables separate from those defined by other
functions.</p>

<p>When the call to <code>fahr_to_kelvin</code> returns a value,
Python throws away <code>fahr_to_kelvin</code>'s stack frame
and creates a new variable in the stack frame for <code>fahr_to_celsius</code> to hold the
temperature in Kelvin:</p>

<p><img src="python/novice/img/python-call-stack-04.svg" alt="Call Stack After Return From First Nested Function Call" /></p>

<p>It then calls <code>kelvin_to_celsius</code>,
which means it creates a stack frame to hold that function's variables:</p>

<p><img src="python/novice/img/python-call-stack-05.svg" alt="Call Stack During Call to Second Nested Function" /></p>

<p>Once again,
Python throws away that stack frame when <code>kelvin_to_celsius</code> is done
and creates the variable <code>result</code> in the stack frame for <code>fahr_to_celsius</code>:</p>

<p><img src="python/novice/img/python-call-stack-06.svg" alt="Call Stack After Second Nested Function Returns" /></p>

<p>Finally,
when <code>fahr_to_celsius</code> is done,
Python throws away <em>its</em> stack frame
and puts its result in a new variable called <code>final</code>
that lives in the stack frame we started with:</p>

<p><img src="python/novice/img/python-call-stack-07.svg" alt="Call Stack After All Functions Have Finished" /></p>

<p>This final stack frame is always there;
it holds the variables we defined outside the functions in our code.
What it <em>doesn't</em> hold is the variables that were in the various stack frames.
If we try to get the value of <code>temp</code> after our functions have finished running,
Python tells us that there's no such thing:</p>

<pre>print 'final value of temp after all function calls:', temp</pre>

<pre>---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)

&lt;ipython-input-10-ffd9b4dbd5f1&gt; in &lt;module&gt;()
----&gt; 1 print 'final value of temp after all function calls:', temp


NameError: name 'temp' is not defined


final value of temp after all function calls:</pre>

<p>Why go to all this trouble?
Well,
here's a function called <code>span</code> that calculates the difference between
the mininum and maximum values in an array:</p>

<pre>import numpy

def span(a):
    diff = a.max() - a.min()
    return diff

data = numpy.loadtxt(fname='inflammation-01.csv', delimiter=',')
print 'span of data', span(data)</pre>

<pre> span of data 20.0</pre>

<p>Notice that <code>span</code> assigns a value to a variable called <code>diff</code>.
We might very well use a variable with the same name to hold data:</p>

<pre>diff = numpy.loadtxt(fname='inflammation-01.csv', delimiter=',')
print 'span of data:', span(diff)</pre>

<pre>span of data: 20.0</pre>

<p>We don't expect <code>diff</code> to have the value 20.0 after this function call,
so the name <code>diff</code> cannot refer to the same thing inside <code>span</code> as it does in
the main body of our program.
And yes,
we could probably choose a different name than <code>diff</code> in our main program in
this case,
but we don't want to have to read every line of NumPy to see what variable names
its functions use
before calling any of those functions,
just in case they change the values of our variables.</p>

<p>The big idea here is <a href="#gloss:encapsulation">encapsulation</a>,
and it's the key to writing correct, comprehensible programs.
A function's job is to turns several operations into one
so that we can think about a single function call
instead of a dozen or a hundred statements
each time we want to do something.
That only works if functions don't interfere with each other;
if they do,
we have to pay attention to the details once again,
which quickly overloads our short-term memory.</p>

<h3>Testing and Documenting</h3>

<p>Once we start putting things in functions so that we can re-use them,
we need to start testing that those functions are working correctly.
To see how to do this,
let's write a function to center a dataset around a particular value:</p>

<pre>def center(data, desired):
    return (data - data.mean()) + desired</pre>

<p>We could test this on our actual data,
but since we don't know what the values ought to be,
it will be hard to tell if the result was correct.
Instead,
let's use NumPy to create a matrix of 0's
and then center that around 3:</p>

<pre>z = numpy.zeros((2,2))
print center(z, 3)</pre>

<pre>[[ 3.  3.]
 [ 3.  3.]]</pre>

<p>That looks right,
so let's try center our real data:</p>

<pre>data = numpy.loadtxt(fname='inflammation-01.csv', delimiter=',')
print center(data, 0)</pre>

<pre>[[-6.14875 -6.14875 -5.14875 ..., -3.14875 -6.14875 -6.14875]
 [-6.14875 -5.14875 -4.14875 ..., -5.14875 -6.14875 -5.14875]
 [-6.14875 -5.14875 -5.14875 ..., -4.14875 -5.14875 -5.14875]
 ...,
 [-6.14875 -5.14875 -5.14875 ..., -5.14875 -5.14875 -5.14875]
 [-6.14875 -6.14875 -6.14875 ..., -6.14875 -4.14875 -6.14875]
 [-6.14875 -6.14875 -5.14875 ..., -5.14875 -5.14875 -6.14875]]</pre>

<p>It's hard to tell from the default output whether the result is correct,
but there are a few simple tests that will reassure us:</p>

<pre>print 'original min, mean, and max are:', data.min(), data.mean(), data.max()
centered = center(data, 0)
print 'min, mean, and and max of centered data are:', centered.min(), centered.mean(), centered.max()</pre>

<pre>original min, mean, and max are: 0.0 6.14875 20.0
min, mean, and and max of centered data are: -6.14875 -3.49054118942e-15 13.85125</pre>

<p>That seems almost right:
the original mean was about 6.1,
so the lower bound from zero is how about -6.1.
The mean of the centered data isn't quite zero&mdash;we'll explore why not in
the challenges&mdash;but it's pretty close.
We can even go further and check that the standard deviation hasn't changed:</p>

<pre>print 'std dev before and after:', data.std(), centered.std()</pre>

<pre>std dev before and after: 4.61383319712 4.61383319712</pre>

<p>Those values look the same,
but we probably wouldn't notice if they were different in the sixth decimal
place.
Let's do this instead:</p>

<pre>print 'difference in standard deviations before and after:', data.std() - centered.std()</pre>

<pre>difference in standard deviations before and after: -3.5527136788e-15</pre>

<p>Again,
the difference is very small.
It's still possible that our function is wrong,
but it seems unlikely enough that we should probably get back to doing our
analysis.
We have one more task first, though:
we should write some <a href="#gloss:documentation">documentation</a> for our
function
to remind ourselves later what it's for and how to use it.</p>

<p>The usual way to put documentation in software is to add
<a href="#gloss:comment">comments</a> like this:</p>

<pre># center(data, desired): return a new array containing the original data centered around the desired value.
def center(data, desired):
    return (data - data.mean()) + desired</pre>

<p>There's a better way, though.
If the first thing in a function is a string that isn't assigned to a variable,
that string is attached to the function as its documentation:</p>

<pre>def center(data, desired):
    'Return a new array containing the original data centered around the desired value.'
    return (data - data.mean()) + desired</pre>

<p>This is better because we can now ask Python's built-in help system to show us
the documentation for the function:</p>

<pre>help(center)</pre>

<pre>Help on function center in module __main__:

center(data, desired)
    Return a new array containing the original data centered around the desired value.</pre>

<p>A string like this is called a <a href="#gloss:docstring">docstring</a>.
If we need to write it,
or any other string,
on multiple lines,
we can do so by starting and ending with three quote characters instead of one:</p>

<pre>def center(data, desired):
    '''Return a new array containing the original data centered around the desired value.
    Example: center([1, 2, 3], 0) =&gt; [-1, 0, 1]'''
    return (data - data.mean()) + desired

help(center)</pre>

<pre>Help on function center in module __main__:

center(data, desired)
    Return a new array containing the original data centered around the desired value.
    Example: center([1, 2, 3], 0) =&gt; [-1, 0, 1]</pre>

<h3>Defining Defaults</h3>

<p>We have passed parameters to functions in two ways:
directly, as in <code>span(data)</code>,
and by name, as in <code>numpy.loadtxt(fname='something.csv', delimiter=',')</code>.
In fact,
we can pass the filename to <code>loadtxt</code> without the <code>fname=</code>:</p>

<pre>numpy.loadtxt('inflammation-01.csv', delimiter=',')</pre>

<pre>array([[ 0.,  0.,  1., ...,  3.,  0.,  0.],
       [ 0.,  1.,  2., ...,  1.,  0.,  1.],
       [ 0.,  1.,  1., ...,  2.,  1.,  1.],
       ...,
       [ 0.,  1.,  1., ...,  1.,  1.,  1.],
       [ 0.,  0.,  0., ...,  0.,  2.,  0.],
       [ 0.,  0.,  1., ...,  1.,  1.,  0.]])</pre>

<p>but we still need to say <code>delimiter=</code>:</p>

<pre>numpy.loadtxt('inflammation-01.csv', ',')</pre>

<pre>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)

&lt;ipython-input-24-e3bc6cf4fd6a&gt; in &lt;module&gt;()
----&gt; 1 numpy.loadtxt('inflammation-01.csv', ',')


/Users/gwilson/anaconda/lib/python2.7/site-packages/numpy/lib/npyio.pyc in loadtxt(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)
    775     try:
    776         # Make sure we're dealing with a proper dtype
--&gt; 777         dtype = np.dtype(dtype)
    778         defconv = _getconv(dtype)
    779


TypeError: data type "," not understood</pre>

<p>To understand what's going on,
and make our own functions easier to use,
let's re-define our <code>center</code> function like this:</p>

<pre>def center(data, desired=0.0):
    '''Return a new array containing the original data centered around the desired value (0 by default).
    Example: center([1, 2, 3], 0) =&gt; [-1, 0, 1]'''
    return (data - data.mean()) + desired</pre>

<p>The key change is that the second parameter is now written <code>desired=0.0</code> instead
of just <code>desired</code>.
If we call the function with two arguments,
it works as it did before:</p>

<pre>test_data = numpy.zeros((2, 2))
print center(test_data, 3)</pre>

<pre>[[ 3.  3.]
 [ 3.  3.]]</pre>

<p>But we can also now call it with just one parameter,
in which case <code>desired</code> is automatically assigned the <a href="#gloss:default-parameter-value">default
value</a> of 0.0:</p>

<pre>more_data = 5 + numpy.zeros((2, 2))
print 'data before centering:', more_data
print 'centered data:', center(more_data)</pre>

<pre>data before centering: [[ 5.  5.]
 [ 5.  5.]]
centered data: [[ 0.  0.]
 [ 0.  0.]]</pre>

<p>This is handy:
if we usually want a function to work one way,
but occasionally need it to do something else,
we can allow people to pass a parameter when they need to
but provide a default to make the normal case easier.
The example below shows how Python matches values to parameters:</p>

<pre>def display(a=1, b=2, c=3):
    print 'a:', a, 'b:', b, 'c:', c

print 'no parameters:'
display()
print 'one parameter:'
display(55)
print 'two parameters:'
display(55, 66)</pre>

<pre>no parameters:
a: 1 b: 2 c: 3
one parameter:
a: 55 b: 2 c: 3
two parameters:
a: 55 b: 66 c: 3</pre>

<p>As this example shows,
parameters are matched up from left to right,
and any that haven't been given a value explicitly get their default value.
We can override this behavior by naming the value as we pass it in:</p>

<pre>print 'only setting the value of c'
display(c=77)</pre>

<pre>only setting the value of c
a: 1 b: 2 c: 77</pre>

<p>With that in hand,
let's look at the help for <code>numpy.loadtxt</code>:</p>

<pre>help(numpy.loadtxt)</pre>

<pre>Help on function loadtxt in module numpy.lib.npyio:

loadtxt(fname, dtype=&lt;type 'float'&gt;, comments='#', delimiter=None, converters=None, skiprows=0, usecols=None, unpack=False, ndmin=0)
    Load data from a text file.

    Each row in the text file must have the same number of values.

    Parameters
    ----------
    fname : file or str
        File, filename, or generator to read.  If the filename extension is
        <code>.gz</code> or <code>.bz2</code>, the file is first decompressed. Note that
        generators should return byte strings for Python 3k.
    dtype : data-type, optional
        Data-type of the resulting array; default: float.  If this is a
        record data-type, the resulting array will be 1-dimensional, and
        each row will be interpreted as an element of the array.  In this
        case, the number of columns used must match the number of fields in
        the data-type.
    comments : str, optional
        The character used to indicate the start of a comment;
        default: '#'.
    delimiter : str, optional
        The string used to separate values.  By default, this is any
        whitespace.
    converters : dict, optional
        A dictionary mapping column number to a function that will convert
        that column to a float.  E.g., if column 0 is a date string:
        <code>converters = {0: datestr2num}</code>.  Converters can also be used to
        provide a default value for missing data (but see also <code>genfromtxt</code>):
        <code>converters = {3: lambda s: float(s.strip() or 0)}</code>.  Default: None.
    skiprows : int, optional
        Skip the first <code>skiprows</code> lines; default: 0.
    usecols : sequence, optional
        Which columns to read, with 0 being the first.  For example,
        <code>usecols = (1,4,5)</code> will extract the 2nd, 5th and 6th columns.
        The default, None, results in all columns being read.
    unpack : bool, optional
        If True, the returned array is transposed, so that arguments may be
        unpacked using <code>x, y, z = loadtxt(...)</code>.  When used with a record
        data-type, arrays are returned for each field.  Default is False.
    ndmin : int, optional
        The returned array will have at least <code>ndmin</code> dimensions.
        Otherwise mono-dimensional axes will be squeezed.
        Legal values: 0 (default), 1 or 2.
        .. versionadded:: 1.6.0

    Returns
    -------
    out : ndarray
        Data read from the text file.

    See Also
    --------
    load, fromstring, fromregex
    genfromtxt : Load data with missing values handled as specified.
    scipy.io.loadmat : reads MATLAB data files

    Notes
    -----
    This function aims to be a fast reader for simply formatted files.  The
    <code>genfromtxt</code> function provides more sophisticated handling of, e.g.,
    lines with missing values.

    Examples
    --------
    &gt;&gt;&gt; from StringIO import StringIO   # StringIO behaves like a file object
    &gt;&gt;&gt; c = StringIO("0 1\n2 3")
    &gt;&gt;&gt; np.loadtxt(c)
    array([[ 0.,  1.],
           [ 2.,  3.]])

    &gt;&gt;&gt; d = StringIO("M 21 72\nF 35 58")
    &gt;&gt;&gt; np.loadtxt(d, dtype={'names': ('gender', 'age', 'weight'),
    ...                      'formats': ('S1', 'i4', 'f4')})
    array([('M', 21, 72.0), ('F', 35, 58.0)],
          dtype=[('gender', '|S1'), ('age', '&lt;i4'), ('weight', '&lt;f4')])

    &gt;&gt;&gt; c = StringIO("1,0,2\n3,0,4")
    &gt;&gt;&gt; x, y = np.loadtxt(c, delimiter=',', usecols=(0, 2), unpack=True)
    &gt;&gt;&gt; x
    array([ 1.,  3.])
    &gt;&gt;&gt; y
    array([ 2.,  4.])</pre>

<p>There's a lot of information here,
but the most important part is the first couple of lines:</p>

<pre>loadtxt(fname, dtype=&lt;type 'float'&gt;, comments='#', delimiter=None, converters=None, skiprows=0, usecols=None,
        unpack=False, ndmin=0)</pre>

<p>This tells us that <code>loadtxt</code> has one parameter called <code>fname</code> that doesn't have
a default value,
and eight others that do.
If we call the function like this:</p>

<pre>numpy.loadtxt('inflammation-01.csv', ',')</pre>

<p>then the filename is assigned to <code>fname</code> (which is what we want),
but the delimiter string <code>','</code> is assigned to <code>dtype</code> rather than <code>delimiter</code>,
because <code>dtype</code> is the second parameter in the list.
That's why we don't have to provide <code>fname=</code> for the filename,
but <em>do</em> have to provide <code>delimiter=</code> for the second parameter.</p>

<h3>Key Points</h3>

<ul>
  <li>Define a function using <code>def name(...params...)</code>.</li>
  <li>The body of a function must be indented.</li>
  <li>Call a function using <code>name(...values...)</code>.</li>
  <li>Numbers are stored as integers or floating-point numbers.</li>
  <li>Integer division produces the whole part of the answer (not the fractional
part).</li>
  <li>Each time a function is called, a new stack frame is created on the <a href="#gloss:call-stack">call
stack</a> to hold its parameters and local variables.</li>
  <li>Python looks for variables in the current stack frame before looking for
them at the top level.</li>
  <li>Use <code>help(thing)</code> to view help for something.</li>
  <li>Put docstrings in functions to provide help for that function.</li>
  <li>Specify default values for parameters when defining a function using
<code>name=value</code> in the parameter list.</li>
</ul>

<div class="challenges">
<ol>
  <li>
    <p>"Adding" two strings produces their concatention:
<code>'a' + 'b'</code> is <code>'ab'</code>.
Write a function called <code>fence</code> that takes two parameters called <code>original</code>
and <code>wrapper</code>
and returns a new string that has the wrapper character at the beginning and
end of the original:</p>
<pre>print fence('name', '*')
*name*</pre>
  </li>
  <li>
    <p>If the variable <code>s</code> refers to a string,
then <code>s[0]</code> is the string's first character
and <code>s[-1]</code> is its last.
Write a function called <code>outer</code>
that returns a string made up of just the first and last characters of its
input:</p>
<pre>print outer('helium')
hm</pre>
  </li>
  <li>We previously wrote functions called <code>fence</code> and <code>outer</code>.
Draw a diagram showing how the call stack changes when we run the following:
<code>
print outer(fence('carbon', '+'))
</code></li>
  <li>
    <p>Write a function called <code>analyze</code> that takes a filename as a parameter
and displays the three graphs produced in the <a href="01-numpy.ipynb">previous
lesson</a>,
i.e.,
<code>analyze('inflammation-01.csv')</code> should produce the graphs already shown,
while <code>analyze('inflammation-02.csv')</code> should produce corresponding graphs
for the second data set.</p>
  </li>
  <li>
    <p>Write a function <code>rescale</code> that takes an array as input
and returns a corresponding array of values scaled to lie in the range 0.0
to 1.0.
(If $L$ and $H$ are the lowest and highest values in the original array,
then the replacement for a value $v$ should be $(v-L) / (H-L)$.)
Be sure to give the function a docstring.</p>
  </li>
  <li>
    <p>Run the commands <code>help(numpy.arange)</code> and <code>help(numpy.linspace)</code>
to see how to use these functions to generate regularly-spaced values,
then use those values to test your <code>rescale</code> function.</p>
  </li>
  <li>Rewrite the <code>normalize</code> function so that it scales data to lie between 0.0
and 1.0 by default,
but will allow the caller to specify lower and upper bounds if they want.
Compare your implementation to your neighbor's:
do the two functions always behave the same way?</li>
</ol>

          <h2>Analyzing Multiple Data Sets</h2>

<p>We have created a function called <code>analyze</code> that creates graphs of the minimum,
average, and maximum daily inflammation rates
for a single data set:</p>

<pre>import numpy as np
from matplotlib import pyplot as plt

def analyze(filename):
    data = np.loadtxt(fname=filename, delimiter=',')

    plt.figure(figsize=(10.0, 3.0))

    plt.subplot(1, 3, 1)
    plt.ylabel('average')
    plt.plot(data.mean(0))

    plt.subplot(1, 3, 2)
    plt.ylabel('max')
    plt.plot(data.max(0))

    plt.subplot(1, 3, 3)
    plt.ylabel('min')
    plt.plot(data.min(0))

    plt.tight_layout()
    plt.show()

analyze('inflammation-01.csv')</pre>

<p><img src="python/novice/img/combined-inflammation-over-time.png" alt="Combined Inflammation per Day" /></p>

<p>We can use it to analyze other data sets one by one:</p>

<pre>analyze('inflammation-02.csv')</pre>

<p><img src="python/novice/img/combined-inflammation-2.png" alt="Combined Inflammation per Day (Second Data Set)" /></p>

<p>but we have a dozen data sets right now and more on the way.
We want to create plots for all our data sets with a single statement.
To do that,
we'll have to teach the computer how to repeat things.</p>

<h3>Objectives</h3>

<ul>
  <li>Explain what a for loop does.</li>
  <li>Correctly write for loops to repeat simple calculations.</li>
  <li>Trace changes to a loop variable as the loop runs.</li>
  <li>Trace changes to other variables as they are updated by a for loop.</li>
  <li>Explain what a list is.</li>
  <li>Create and index lists of simple values.</li>
  <li>Use a library function to get a list of filenames that match a simple
wildcard pattern.</li>
  <li>Use a for loop to process multiple files.</li>
</ul>

<h3>For Loops</h3>

<p>Suppose we want to print each character in the word "lead" on a line of its own.
One way is to use four <code>print</code> statements:</p>

<pre>def print_characters(element):
    print element[0]
    print element[1]
    print element[2]
    print element[3]

print_characters('lead')</pre>

<pre>l
e
a
d</pre>

<p>but that's a bad approach for two reasons:</p>

<ol>
  <li>
    <p>It doesn't scale:
if we want to print the characters in a string that's hundreds of letters
long,
we'd be better off just typing them in.</p>
  </li>
  <li>
    <p>It's fragile:
if we give it a longer string,
it only prints part of the data,
and if we give it a shorter one,
it produces an error because we're asking for characters that don't exist.</p>
  </li>
</ol>

<p>Here's a better approach:</p>

<pre>def print_characters(element):
    for char in element:
        print char

print_characters('lead')</pre>

<pre>l
e
a
d</pre>

<p>This is shorter&mdash;certainly shorter than something that prints every character
in a hundred-letter string&mdash;and
more robust as well:</p>

<pre>print_characters('oxygen')</pre>

<pre>o
x
y
g
e
n</pre>

<p>The improved version of <code>print_characters</code> uses a <a href="#gloss:for-loop">for loop</a>
to repeat an operation&mdash;in this case, printing&mdash;once for each thing in a
collection.
The general form of a loop is:</p>

<pre>
<strong>for</strong> <em>variable</em> <strong>in</strong>
<em>collection</em><strong>:</strong>
    <em>do things with variable</em></pre>

<p>We can call the <a href="#gloss:loop-variable">loop variable</a> anything we
like,
but there must be a colon at the end of the line starting the loop,
and we must indent the <a href="#gloss:loop-body">body</a> of the loop.</p>

<p>Here's another loop that repeatedly updates a variable:</p>

<pre>length = 0
for vowel in 'aeiou':
    length = length + 1
print 'There are', length, 'vowels'</pre>

<pre>There are 5 vowels</pre>

<p>It's worth tracing the execution of this little program step by step.
Since there are five characters in <code>'aeiou'</code>,
the statement on line 3 will be executed five times.
The first time around,
<code>length</code> is zero (the value assigned to it on line 1)
and <code>vowel</code> is <code>'a'</code>.
The statement adds 1 to the old value of <code>length</code>,
producing 1,
and updates <code>length</code> to refer to that new value.
The next time around,
<code>vowel</code> is <code>'e'</code> and <code>length</code> is 1,
so <code>length</code> is updated to be 2.
After three more updates,
<code>length</code> is 5;
since there is nothing left in <code>'aeiou'</code> for Python to process,
the loop finishes
and the <code>print</code> statement on line 4 tells us our final answer.</p>

<p>Note that finding the length of a string is such a common operation
that Python actually has a built-in function to do it called <code>len</code>:</p>

<pre>print len('aeiou')</pre>

<pre>5</pre>

<p><code>len</code> is much faster than any function we could write ourselves,
and much easier to read than a two-line loop;
it will also give us the length of many other things that we haven't met yet,
so we should always use it when we can.</p>

<h3>Lists</h3>

<p>Just as a <code>for</code> loop is a way to do operations many times,
a list is a way to store many values.
Unlike NumPy arrays,
there are built into the language.
We create a list by putting values inside square brackets:</p>

<pre>odds = [1, 3, 5, 7]
print 'odds are:', odds</pre>

<pre>odds are: [1, 3, 5, 7]</pre>

<p>We select individual elements from lists by indexing them:</p>

<pre>print 'first and last:', odds[0], odds[-1]</pre>

<pre>first and last: 1 7</pre>

<p>and if we loop over a list,
the loop variable is assigned elements one at a time:</p>

<pre>for number in odds:
    print number</pre>

<pre>1
3
5
7</pre>

<p>There is one important difference between lists and strings:
we can change the values in a list,
but we cannot change the characters in a string.
For example:</p>

<pre>names = ['Newton', 'Darwing', 'Turing'] # typo in Darwin's name
print 'names is originally:', names
names[1] = 'Darwin' # correct the name
print 'final value of names:', names</pre>

<pre>names is originally: ['Newton', 'Darwing', 'Turing']
final value of names: ['Newton', 'Darwin', 'Turing']</pre>

<p>works, but:</p>

<pre>name = 'Bell'
name[0] = 'b'</pre>

<pre>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)

&lt;ipython-input-12-220df48aeb2e&gt; in &lt;module&gt;()
      1 name = 'Bell'
----&gt; 2 name[0] = 'b'


TypeError: 'str' object does not support item assignment</pre>

<p>does not.
A value that can be changed is called <a href="#gloss:mutable">mutable</a>,
while one that cannot be is called <a href="#gloss:immutable">immutable</a>.
There are many ways to change the values in lists besides assigning to elements:</p>

<pre>odds.append(11)
print 'odds after adding a value:', odds</pre>

<pre>del odds[0]
print 'odds after removing the first element:', odds</pre>

<pre>odds.reverse()
print 'odds after reversing:', odds</pre>

<h3>Processing Multiple Files</h3>

<p>We now have almost everything we need to process all our data files.
The only thing that's missing is a library with a rather unpleasant name:</p>

<pre>import glob</pre>

<p>The <code>glob</code> library contains a single function, also called <code>glob</code>,
that finds files whose names match a pattern.
We provide those patterns as strings:
the character <code>*</code> matches zero or more characters,
while <code>?</code> matches any one character.
We can use this to get the names of all the IPython Notebooks we have created so
far:</p>

<pre>print glob.glob('*.ipynb')</pre>

<p>or to get the names of all our CSV data files:</p>

<pre>print glob.glob('*.csv')</pre>

<p>As these examples show,
<code>glob.glob</code>'s result is a list of strings,
which means we can loop over it
to do something with each filename in turn.
In our case,
the "something" we want is our <code>analyze</code> function.
Let's test it by analyzing the first three files in the list:</p>

<pre>filenames = glob.glob('*.csv')
filenames = filenames[0:3]
for f in filenames:
    print f
    analyze(f)</pre>

<p>Sure enough,
the maxima of these data sets show exactly the same ramp as the first,
and their minima show the same staircase structure.</p>

<div class="keypoints">
<h3>Key Points</h3>

<ul>
  <li>Use <code>for variable in collection</code> to process the elements of a collection one
at a time.</li>
  <li>The body of a for loop must be indented.</li>
  <li>Use <code>len(thing)</code> to determine the length of something that contains other
values.</li>
  <li><code>[value1, value2, value3, ...]</code> creates a list.</li>
  <li>Lists are indexed and sliced in the same way as strings and arrays.</li>
  <li>Lists are mutable (i.e., their values can be changed in place).</li>
  <li>Strings are immutable (i.e., the characters in them cannot be changed).</li>
  <li>Use <code>glob.glob(pattern)</code> to create a list of files whose names match a
pattern.</li>
  <li>Use <code>*</code> in a pattern to match zero or more characters, and <code>?</code> to match any
single character.</li>
</ul>
</div>

<div class="challenges">
<ol>
  <li>
    <p>Python has a built-in function called <code>range</code> that creates a list of
numbers:
<code>range(3)</code> produces <code>[0, 1, 2]</code>, <code>range(2, 5)</code> produces <code>[2, 3, 4]</code>, and
<code>range(2, 10, 3)</code> produces <code>[2, 5, 8]</code>.
Using <code>range</code>,
write a function that prints the <em>N</em> natural numbers:</p>
<pre>
print_N(3)
1
2
3</pre>
  </li>
  <li>
    <p>Exponentiation is built into Python:
<code>
print 2**4
16
</code>
It also has a function called <code>pow</code> that calculates the same value.
Write a function called <code>expo</code> that uses a loop to calculate the same
result.</p>
  </li>
  <li>
    <p>Python's strings have methods, just like NumPy's arrays.
One of these is called <code>reverse</code>:</p>
<pre>
print 'Newton'.reverse()
notweN
</pre>
<p>Write a function called <code>rev</code> that does the same thing:</p>
<pre>
print rev('Newton')
notweN</pre>
  </li>
  <li>Write a function called <code>total</code> that calculates the sum of the values in a
list.
(Python has a built-in function called <code>sum</code> that does this for you.
Please don't use it for this exercise.)</li>
  <li>Write a function called <code>analyze_all</code> that takes a filename pattern as its
sole argument
and runs <code>analyze</code> for each file whose name matches the pattern.</li>
</ol>
</div>

          <h2>Making Choices</h2>

<p>Our previous lessons have shown us how to manipulate data,
define our own functions,
and repeat things.
However,
the programs we have written so far always do the same things,
regardless of what data they're given.
We want programs to make choices based on the values they are manipulating.
To help us see what decisions they're making,
we'll start by looking at how computers manipulate images.</p>

<div class="objectives">
<h3>Objectives</h3>

<ul>
  <li>Create a simple "image" made out of colored blocks.</li>
  <li>Explain how the RGB model represents colors.</li>
  <li>Explain the similarities and differences between tuples and lists.</li>
  <li>Write conditional statements including <code>if</code>, <code>elif</code>, and <code>else</code> branches.</li>
  <li>Correctly evaluate expressions containing <code>and</code> and <code>or</code>.</li>
  <li>Correctly write and interpret code containing nested loops and conditionals.</li>
  <li>Explain the advantages of putting frequently-modified code in a function.</li>
</ul>
</div>

<h3>Image Grids</h3>

<p>Let's start by creating some simple heat maps of our own
using a library called <code>ipythonblocks</code>.
The first step is to create our own "image":</p>

<pre>from ipythonblocks import ImageGrid

grid = ImageGrid(5, 3)
grid.show()</pre>

<p>Just like a NumPy array,
an <code>ImageGrid</code> has some properties that hold information about it:</p>

<pre>print 'grid width:', grid.width
print 'grid height:', grid.height
print 'grid lines on:', grid.lines_on</pre>

<pre>grid width: 5
grid height: 3
grid lines on: True</pre>

<p>The obvious thing to do with a grid like this is color in its cells,
but in order to do that,
we need to know how computers represent color.
The most common schemes are <a href="#gloss:rgb">RGB</a>,
which is short for "red, green, blue".
RGB is an <a href="#gloss:additive-color-model">additive color model</a>:
every shade is some combination of red, green, and blue intensities.
We can think of these three values as being the axes in a cube:</p>

<p><img src="files/color-cube.png" alt="RGB Color Cube" /></p>

<p>An RGB color is an example of a multi-part value:
like a Cartesian coordinate,
it is one thing with several parts.
We can represent such a value in Python using a <a href="#gloss:tuple">tuple</a>,
which we write using parentheses instead of the square brackets used for a list:</p>

<pre>position = (12.3, 45.6)
print 'position is:', position
color = (10, 20, 30)
print 'color is:', color</pre>

<pre>position is: (12.3, 45.6)
color is: (10, 20, 30)</pre>

<p>We can select elements from tuples using indexing,
just as we do with lists and arrays:</p>

<pre>print 'first element of color is:', color[0]</pre>

<pre>first element of color is: 10</pre>

<p>Unlike lists and arrays,
though,
tuples cannot be changed after they are created&mdash;in technical terms,
they are <a href="#gloss:immutable">immutable</a>:</p>

<pre>color[0] = 40
print 'first element of color after change:', color[0]</pre>

<pre>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)

&lt;ipython-input-7-9c3dd30a4e52&gt; in &lt;module&gt;()
----&gt; 1 color[0] = 40
      2 print 'first element of color after change:', color[0]


TypeError: 'tuple' object does not support item assignment</pre>

<p>If a tuple represents an RGB color,
its red, green, and blue components can take on values between 0 and 255.
The upper bound may seem odd,
but it's the largest number that can be represented in an 8-bit byte
(i.e., 2<sup>8</sup>-1).
This makes it easy for computers to manipulate colors,
while providing fine enough gradations to fool most human eyes,
most of the time.</p>

<p>Let's see what a few RGB colors actually look like:</p>

<pre>row = ImageGrid(8, 1)
row[0, 0] = (0, 0, 0)   # no color =&gt; black
row[1, 0] = (255, 0, 0) # all red
row[2, 0] = (0, 255, 0) # all green
row[3, 0] = (0, 0, 255) # all blue
row[4, 0] = (255, 255, 0) # red and green
row[5, 0] = (255, 0, 255) # red and blue
row[6, 0] = (0, 255, 255) # green and blue
row[7, 0] = (255, 255, 255) # all colors =&gt; white
row.show()</pre>

<p>(It's hard to see the last cell because it's white on white,
but it's there.)</p>

<p>Simple color values like <code>(0,255,0)</code> are easy enough to decipher with a bit of
practice,
but what color is <code>(214,90,127)</code>?
To help us,
<code>ipythonblocks</code> provides a function called <code>show_color</code>:</p>

<pre>from ipythonblocks import show_color
show_color(214, 90, 127)</pre>

<p>It also provides a table of standard colors:</p>

<pre>from ipythonblocks import colors
c = ImageGrid(3, 2)
c[0, 0] = colors['Fuchsia']
c[0, 1] = colors['Salmon']
c[1, 0] = colors['Orchid']
c[1, 1] = colors['Lavender']
c[2, 0] = colors['LimeGreen']
c[2, 1] = colors['HotPink']
c.show()</pre>

<h3>Conditionals</h3>

<p>The other thing we need in order to create a heat map of our own
is a way to pick a color based on a data value.
The tool Python gives us for doing this is called a <a href="#gloss:conditional-statement">conditional
statement</a>,
and looks like this:</p>

<pre>num = 37
if num &gt; 100:
    print 'greater'
else:
    print 'not greater'
print 'done'</pre>

<pre>not greater
done</pre>

<p>The second line of this code uses the keyword <code>if</code> to tell Python that we want
to make a choice.
If the test that follows it is true,
the body of the <code>if</code>
(i.e., the lines indented underneath it) are executed.
If the test is false,
the body of the <code>else</code> is executed instead.
Only one or the other is ever executed:</p>

<p><img src="python/novice/img/python-flowchart-conditional.svg" alt="Executing a Conditional" /></p>

<p>Conditional statements don't have to include an <code>else</code>.
If there isn't one,
Python simply does nothing if the test is false:</p>

<pre>num = 53
print 'before conditional...'
if num &gt; 100:
    print '53 is greater than 100'
print '...after conditional'</pre>

<pre>before conditional...
...after conditional</pre>

<p>We can also chain several tests together using <code>elif</code>,
which is short for "else if".
This makes it simple to write a function that returns the sign of a number:</p>

<pre>def sign(num):
    if num &gt; 0:
        return 1
    elif num == 0:
        return 0
    else:
        return -1

print 'sign of -3:', sign(-3)</pre>

<pre>sign of -3: -1</pre>

<p>One important thing to notice the code above is that we use a double equals sign
<code>==</code> to test for equality
rather than a single equals sign
because the latter is used to mean assignment.
This convention was inherited from C,
and while many other programming languages work the same way,
it does take a bit of getting used to...</p>

<p>We can also combine tests using <code>and</code> and <code>or</code>.
<code>and</code> is only true if both parts are true:</p>

<pre>if (1 &gt; 0) and (-1 &gt; 0):
    print 'both parts are true'
else:
    print 'one part is not true'</pre>

<pre>one part is not true</pre>

<p>while <code>or</code> is true if either part is true:</p>

<pre>if (1 &lt; 0) or ('left' &lt; 'right'):
    print 'at least one test is true'</pre>

<pre>at least one test is true</pre>

<p>In this case,
"either" means "either or both", not "either one or the other but not both".</p>

<h3>Nesting</h3>

<p>Another thing to realize is that <code>if</code> statements can be combined with loops
just as easily as they can be combined with functions.
For example,
if we want to sum the positive numbers in a list,
we can write this:</p>

<pre>numbers = [-5, 3, 2, -1, 9, 6]
total = 0
for n in numbers:
    if n &gt;= 0:
        total = total + n
print 'sum of positive values:', total</pre>

<pre>sum of positive values: 20</pre>

<p>We could equally well calculate the positive and negative sums in a single loop:</p>

<pre>pos_total = 0
neg_total = 0
for n in numbers:
    if n &gt;= 0:
        pos_total = pos_total + n
    else:
        neg_total = neg_total + n
print 'negative and positive sums are:', neg_total, pos_total</pre>

<pre>negative and positive sums are: -6 20</pre>

<p>We can even put one loop inside another:</p>

<pre>for consonant in 'bcd':
    for vowel in 'ae':
        print consonant + vowel</pre>

<pre>ba
be
ca
ce
da
de</pre>

<p>As the diagram below shows,
the <a href="#gloss:inner-loop">inner loop</a> runs from start to finish
each time the <a href="#gloss:outer-loop">outer loop</a> runs once:</p>

<p><img src="python/novice/img/python-flowchart-nested-loops.svg" alt="Execution of Nested Loops" /></p>

<p>We can combine nesting and conditionals to create patterns in an image:</p>

<pre>square = ImageGrid(5, 5)
for x in range(square.width):
    for y in range(square.height):
        if x &lt; y:
            square[x, y] = colors['Fuchsia']
        elif x == y:
            square[x, y] = colors['Olive']
        else:
            square[x, y] = colors['SlateGray']
square.show()</pre>

<p>This is our first hand-made data visualization:
the colors show where <code>x</code> is less than, equal to, or greater than <code>y</code>.</p>

<h3>Creating a Heat Map</h3>

<p>The last step is to turn our data into something we can see.
As in previous lessons,
the first step is to get the data into memory:</p>

<pre>import numpy as np
data = np.loadtxt(fname='inflammation-01.csv', delimiter=',')
print 'data shape:', data.shape</pre>

<pre>data shape: (60, 40)</pre>

<p>The second is to create an image grid that is the same size as the data:</p>

<pre>width, height = data.shape
heatmap = ImageGrid(width, height)</pre>

<p>(The first line of the code above takes advantage of a neat trick:
we can unpack the values in a tuple by assigning it to
as many variables as it has entries.)</p>

<p>The third step is to decide <em>how</em> we are going to color the cells in the heat
map.
To keep things simple,
we will use red, green, and blue as our colors,
and compare data values to the data set's mean.
Here's the code:</p>

<pre>for x in range(width):
    for y in range(height):
        if data[x, y] &lt; data.mean():
            heatmap[x, y] = colors['Red']
        elif data[x, y] == data.mean():
            heatmap[x, y] = colors['Green']
        else:
            heatmap[x, y] = colors['Blue']
heatmap.show()</pre>

<p>This may be what we asked for,
but both the image and the code are hideous:</p>

<ol>
  <li>It's too large for us to view the whole thing at once on a small laptop
screen.</li>
  <li>Our first heatmap had time along the X axis; this seems to have time along
the Y axis.</li>
  <li>Red against blue is pretty hard on the eyes.</li>
  <li>The heatmap only shows two colors because none of the (integer)
measurements has exactly the same value as the (fractional) mean.</li>
  <li>We are calculating the mean of <code>data</code> either once or twice each time we go
through the loop.  That means that on a 40&times;60 data set, we are performing
the same calculation 2400 times.</li>
</ol>

<p>Here's how we can improve it:</p>

<ol>
  <li>We can give <code>ImageGrid</code> an optional parameter <code>block_size</code> to set the size
of each block.</li>
  <li>We can transpose our data before creating the grid.</li>
  <li>We can pick better colors (I'm personally fond of orchid, fuchsia, and hot
pink).</li>
  <li>Instead of checking if values are exactly equal to the mean, we can see if
they are close to it.</li>
  <li>We can calculate the mean once, before we start our loops, and use that
value over and over.</li>
</ol>

<p>Our modified code looks like this:</p>

<pre>flipped = data.transpose()
width, height = flipped.shape
heatmap = ImageGrid(width, height, block_size=5)
center = flipped.mean()
for x in range(width):
    for y in range(height):
        if flipped[x, y] &lt; (0.8 * center):
            heatmap[x, y] = colors['Orchid']
        elif flipped[x, y] &gt; (1.2 * center):
            heatmap[x, y] = colors['HotPink']
        else:
            heatmap[x, y] = colors['Fuchsia']
heatmap.show()</pre>

<p>That's a bit better&mdash;but now the contrast between the colors isn't great
enough.
And there still aren't very many fuchsia cells:
we may want to widen the band around the mean that gets that color.</p>

<p>We could rewrite our loop a third time,
but the right thing to do is to put our code in a function
so that we can experiment with bands and colors more easily.</p>

<pre>def make_heatmap(values, low_color, mid_color, high_color, low_band, high_band, block_size):
    width, height = values.shape
    result = ImageGrid(width, height, block_size=block_size)
    center = values.mean()
    for x in range(width):
        for y in range(height):
            if values[x, y] &lt; low_band * center:
                result[x, y] = low_color
            elif values[x, y] &gt; high_band * center:
                result[x, y] = high_color
            else:
                result[x, y] = mid_color
    return result</pre>

<p>To test this function,
we'll run it with the settings we just used:</p>

<pre>h = make_heatmap(flipped, colors['Orchid'], colors['Fuchsia'], colors['HotPink'], 0.8, 1.2, 5)
h.show()</pre>

<p>That seems right,
so let's widen the band and use more dramatic colors:</p>

<pre>h = make_heatmap(flipped, colors['Gray'], colors['YellowGreen'], colors['SpringGreen'], 0.5, 1.5, 5)
h.show()</pre>

<p>We'll probably want to experiment a bit more before publishing,
but writing a function has made experimenting easy.
We can make it even easier by re-defining our function one more time
to give the parameters default values.
While we're at it,
let's put the low and high bands at the front,
since they're more likely to change than our color choices:</p>

<pre>def make_heatmap(values,
                 low_band=0.5, high_band=1.5,
                 low_color=colors['Gray'], mid_color=colors['YellowGreen'], high_color=colors['SpringGreen'],
                 block_size=5):
    width, height = values.shape
    result = ImageGrid(width, height, block_size=block_size)
    center = values.mean()
    for x in range(width):
        for y in range(height):
            if values[x, y] &lt; low_band * center:
                result[x, y] = low_color
            elif values[x, y] &gt; high_band * center:
                result[x, y] = high_color
            else:
                result[x, y] = mid_color
    return result</pre>

<p>Once default values are added,
the function's first line is too long to fit comfortably on our screen.
Rather than breaking it wherever it hits the right edge of the screen,
we have divided the parameters into logical groups to make it more readable.</p>

<p>Again,
our first test is to re-run it with the same values as before
(which we give it in a different order,
since we've changed the order of parameters):</p>

<pre>h = make_heatmap(flipped, 0.5, 1.5, colors['Gray'], colors['YellowGreen'], colors['SpringGreen'], 5)
h.show()</pre>

<p>We can now leave out everything except the data being visualized,
or provide the data and the bands
and re-use the default colors and block size:</p>

<pre>h = make_heatmap(flipped, 0.4, 1.6)
h.show()</pre>

<p>We can now explore our data with just a few keystrokes,
which means we can concentrate on our science
and not on our programming.</p>

<div class="keypoints">
<h3>Key Points</h3>

<ul>
  <li>Use the <code>ImageGrid</code> class from the <code>ipythonblocks</code> library to create simple
"images" made of colored blocks.</li>
  <li>Specify colors use (red, green, blue) triples, each component of which is an
integer in the range 0..255.</li>
  <li>Use <code>if condition</code> to start a conditional statement, <code>elif condition</code> to
provide additional tests, and <code>else</code> to provide a default.</li>
  <li>The bodies of the branches of conditional statements must be indented.</li>
  <li>Use <code>==</code> to test for equality.</li>
  <li><code>X and Y</code> is only true if both X and Y are true.</li>
  <li><code>X or Y</code> is true if either X or Y, or both, are true.</li>
  <li>Zero, the empty string, and the empty list are considered false; all other
numbers, strings, and lists are considered true.</li>
  <li>Nest loops to operate on multi-dimensional data.</li>
  <li>Put code whose parameters change frequently in a function, then call it with
different parameter values to customize its behavior.</li>
</ul>
</div>

<div class="challenges">
<ol>
  <li>
    <p>Fill in the <code>____</code> in the code below to create a bar that changes color from
dark blue to black.</p>
<pre>bar = ImageGrid(10, 1)
for x in range(10):
    bar[x, 0] = (0, 0, ____)
bar.show()</pre>
  </li>
  <li>
    <p>Why do computers use red, green, and blue as their primary colors?</p>
  </li>
  <li>
    <p><code>True</code> and <code>False</code> aren't the only values in Python that are true and false.
In fact, <em>any</em> value can be used in an <code>if</code> or <code>elif</code>.
After reading and running the code below,
explain what the rule is for which values are considered true and which are
considered false.
(Note that if the body of a conditional is a single statement, we can write
it on the same line as the <code>if</code>.)</p>
<pre>if '': print 'empty string is true'
if 'word': print 'word is true'
if []: print 'empty list is true'
if [1, 2, 3]: print 'non-empty list is true'
if 0: print 'zero is true'
if 1: print 'one is true'</pre>
  </li>
  <li>
    <p>Write a function called <code>near</code> that returns <code>True</code> if its first parameter is
within 10% of its second
and <code>False</code> otherwise.
Compare your implementation with your partner's:
do you return the same answer for all possible pairs of numbers?</p>
  </li>
  <li>
    <p>Will changing the nesting of the loops in the code above&mdash;i.e.,
wrapping the Y-axis loop around the X-axis loop&mdash;change the final
image?
Why or why not?</p>
  </li>
  <li>
    <p>Python (and most other languages in the C family) provides <a href="#gloss:in-place-operator">in-place
operators</a>
that work like this:</p>

<pre>x = 1  # original value
x += 1 # add one to x, assigning result back to x
x *= 3 # multiply x by 3
print x
6</pre>

    <p>Rewrite the code that sums the positive and negative numbers in a list
using in-place operators.
Do you think the result is more or less readable than the original?</p>
  </li>
  <li>
    <p>Why did we transpose our data outside our heat map function?
Why not have the function perform the transpose?</p>
  </li>
  <li>
    <p>Why does the heat map function return the grid rather than displaying it
immediately?
Do you think this is a good or bad design choice?</p>
  </li>
  <li>
    <p>Explain what the overall effect of this code is:
<code>
temp = left
left = right
right = temp
</code>
Compare it to:
<code>
left, right = right, left
</code>
Do they always do the same thing?
Which do you find easier to read?</p>
  </li>
</ol>

</div>

          <h2>Defensive Programming</h2>

<p>Our previous lessons have introduced the basic tools of programming:
variables and lists,
file I/O,
loops,
conditionals,
and most importantly,
functions.
What they haven't done is show us how to tell if a program is getting the right
answer.
If (for example) each line we write has a 99% chance of being right,
then a 70-line program will be wrong more than half the time.
We need to do better than that,
which means we need to:</p>

<ul>
  <li>write programs that check their own operation,</li>
  <li>write and run tests for widely-used functions, and</li>
  <li>make sure we know what "correct" actually means.</li>
</ul>

<p>The good news is,
doing these things will actually speed up our programming,
not slow it down.</p>

<div class="objectives">
<h3>Objectives</h3>

<ul>
  <li>Explain what an assertion is.</li>
  <li>Add assertions to programs that correctly check the program's state.</li>
  <li>Correctly add precondition and postcondition assertions to functions.</li>
  <li>Explain what test-driven development is, and use it when creating new
functions.</li>
  <li>Explain why variables should be initialized using actual data values rather
than arbitrary constants.</li>
  <li>Debug code containing an error systematically.</li>
</ul>
</div>

<h3>Assertions</h3>

<p>The first step toward getting the right answers from our programs
is to assume that mistakes <em>will</em> happen
and to guard against them.
This is called <a href="#gloss:defensive-programming">defensive programming</a>,
and the most common way to do it is to add
<a href="#gloss:assertion">assertions</a> to our code
so that it checks itself as it runs.
An assertion is simply a statement that something must be true at a certain
point in a program.
When Python sees one,
it checks that the assertion's condition.
If it's true,
Python does nothing,
but if it's false,
Python halts the program immediately
and prints the error message provided.
For example,
this piece of code halts as soon as the loop encounters a value that isn't
positive:</p>

<pre>numbers = [1.5, 2.3, 0.7, -0.001, 4.4]
total = 0.0
for n in numbers:
    assert n &gt;= 0.0, 'Data should only contain positive values'
    total += n
print 'total is:', total</pre>

<pre>---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)

&lt;ipython-input-1-33d87ea29ae4&gt; in &lt;module&gt;()
      2 total = 0.0
      3 for n in numbers:
----&gt; 4     assert n &gt;= 0.0, 'Data should only contain positive values'
      5     total += n
      6 print 'total is:', total


AssertionError: Data should only contain positive values</pre>

<p>Programs like the Firefox browser are full of assertions:
10-20% of the code they contain
are there to check that the other 80-90% are working correctly.
Broadly speaking,
assertions fall into three categories:</p>

<ul>
  <li>A <a href="#gloss:precondition">precondition</a> is something that must be
true
at the start of a function in order for it to work correctly.</li>
  <li>A <a href="#gloss:postcondition">postcondition</a> is something that
the function guarantees is true when it finishes.</li>
  <li>An <a href="#gloss:invariant">invariant</a> is something that is always true
at a particular point inside a piece of code.</li>
</ul>

<p>For example,
suppose we are representing rectangles using a tuple of four coordinates <code>(x0,
y0, x1, y1)</code>.
In order to do some calculations,
we need to normalize the rectangle so that it is at the origin
and 1.0 units long on its longest axis.
This function does that,
but checks that its input is correctly formatted and that its result makes
sense:</p>

<pre>def normalize_rectangle(rect):
    assert len(rect) == 4, 'Rectangles must contain 4 coordinates'
    x0, y0, x1, y1 = rect
    assert x0 &lt; x1, 'Invalid X coordinates'
    assert y0 &lt; y1, 'Invalid Y coordinates'

    dx = x1 - x0
    dy = y1 - y0
    if dx &gt; dy:
        scaled = float(dx) / dy
        upper_x, upper_y = 1.0, scaled
    else:
        scaled = float(dx) / dy
        upper_x, upper_y = scaled, 1.0

    assert 0 &lt; upper_x &lt;= 1.0, 'Calculated upper X coordinate invalid'
    assert 0 &lt; upper_y &lt;= 1.0, 'Calculated upper Y coordinate invalid'

    return (0, 0, upper_x, upper_y)</pre>

<p>The preconditions on lines 2, 4, and 5 catch invalid inputs:</p>

<pre>print normalize_rectangle( (0.0, 1.0, 2.0) ) # missing the fourth coordinate</pre>

<pre>---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)

&lt;ipython-input-3-3a97b1dcab70&gt; in &lt;module&gt;()
----&gt; 1 print normalize_rectangle( (0.0, 1.0, 2.0) ) # missing the fourth coordinate


&lt;ipython-input-2-fdb49ef456c2&gt; in normalize_rectangle(rect)
      1 def normalize_rectangle(rect):
----&gt; 2     assert len(rect) == 4, 'Rectangles must contain 4 coordinates'
      3     x0, y0, x1, y1 = rect
      4     assert x0 &lt; x1, 'Invalid X coordinates'
      5     assert y0 &lt; y1, 'Invalid Y coordinates'


AssertionError: Rectangles must contain 4 coordinates</pre>

<pre>print normalize_rectangle( (4.0, 2.0, 1.0, 5.0) ) # X axis inverted</pre>

<pre>---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)

&lt;ipython-input-4-f05ae7878a45&gt; in &lt;module&gt;()
----&gt; 1 print normalize_rectangle( (4.0, 2.0, 1.0, 5.0) ) # X axis inverted


&lt;ipython-input-2-fdb49ef456c2&gt; in normalize_rectangle(rect)
      2     assert len(rect) == 4, 'Rectangles must contain 4 coordinates'
      3     x0, y0, x1, y1 = rect
----&gt; 4     assert x0 &lt; x1, 'Invalid X coordinates'
      5     assert y0 &lt; y1, 'Invalid Y coordinates'
      6


AssertionError: Invalid X coordinates</pre>

<p>The post-conditions help us catch bugs by telling us when our calculations
cannot have been correct.
For example,
if we normalize a rectangle that is taller than it is wide everything seems OK:</p>

<pre>print normalize_rectangle( (0.0, 0.0, 1.0, 5.0) )</pre>

<pre>(0, 0, 0.2, 1.0)</pre>

<p>but if we normalize one that's wider than it is tall,
the assertion is triggered:</p>

<pre>print normalize_rectangle( (0.0, 0.0, 5.0, 1.0) )</pre>

<pre>---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)

&lt;ipython-input-6-5f0ef7954aeb&gt; in &lt;module&gt;()
----&gt; 1 print normalize_rectangle( (0.0, 0.0, 5.0, 1.0) )


&lt;ipython-input-2-fdb49ef456c2&gt; in normalize_rectangle(rect)
     15
     16     assert 0 &lt; upper_x &lt;= 1.0, 'Calculated upper X coordinate invalid'
---&gt; 17     assert 0 &lt; upper_y &lt;= 1.0, 'Calculated upper Y coordinate invalid'
     18
     19     return (0, 0, upper_x, upper_y)


AssertionError: Calculated upper Y coordinate invalid</pre>

<p>Re-reading our function,
we realize that line 10 should divide <code>dy</code> by <code>dx</code> rather than <code>dx</code> by <code>dy</code>.
(You can display line numbers by typing Ctrl-M, then L.)
If we had left out the assertion at the end of the function,
we would have created and returned something that had the right shape as a valid
answer,
but wasn't.
Detecting and debugging that would almost certainly have taken more time in the
long run
than writing the assertion.</p>

<p>But assertions aren't just about catching errors:
they also help people understand programs.
Each assertion gives the person reading the program
a chance to check (consciously or otherwise)
that their understanding matches what the code is doing.</p>

<p>Most good programmers follow two rules when adding assertions to their code.
The first is, "<a href="../../rules.html#fail-early-fail-often">fail early, fail often</a>".
The greater the distance between when and where an error occurs and when it's
noticed,
the harder the error will be to debug,
so good code catches mistakes as early as possible.</p>

<p>The second rule is, "<a href="../../rules.html#turn-bugs-into-assertions-or-tests">turn bugs into assertions or tests</a>".
If you made a mistake in a piece of code,
the odds are good that you have made other mistakes nearby,
or will make the same mistake (or a related one)
the next time you change it.
Writing assertions to check that you haven't
<a href="#gloss:regression">regressed</a>
(i.e., haven't re-introduced an old problem)
can save a lot of time in the long run,
and helps to warn people who are reading the code
(including your future self)
that this bit is tricky.</p>

<h3>Test-Driven Development</h3>

<p>An assertion checks that something is true at a particular point in the program.
The next step is to check the overall behavior of a piece of code,
i.e.,
to make sure that it produces the right output when it's given a particular
input.
For example,
suppose we need to find where two or more time series overlap.
The range of each time series is represented as a pair of numbers,
which are the time the interval started and ended.
The output is the largest range that they all include:</p>

<p><img src="python/novice/img/python-overlapping-ranges.svg" alt="Overlapping Ranges" /></p>

<p>Most novice programmers would solve this problem like this:</p>

<ol>
  <li>Write a function <code>range_overlap</code>.</li>
  <li>Call it interactively on two or three different inputs.</li>
  <li>If it produces the wrong answer, fix the function and re-run that test.</li>
</ol>

<p>This clearly works&mdash;after all, thousands of scientists are doing it right
now&mdash;but
there's a better way:</p>

<ol>
  <li>Write a short function for each test.</li>
  <li>Write a <code>range_overlap</code> function that should pass those tests.</li>
  <li>If <code>range_overlap</code> produces any wrong answers, fix it and re-run the test
functions.</li>
</ol>

<p>Writing the tests <em>before</em> writing the function they exercise
is called <a href="#gloss:test-driven-development">test-driven development</a>
(TDD).
Its advocates believe it produces better code faster because:</p>

<ol>
  <li>If people write tests after writing the thing to be tested,
they are subject to confirmation bias,
i.e.,
they subconsciously write tests to show that their code is correct,
rather than to find errors.</li>
  <li>Writing tests helps programmers figure out what the function is actually
supposed to do.</li>
</ol>

<p>Here are three test functions for <code>range_overlap</code>:</p>

<pre>assert range_overlap([ (0.0, 1.0) ]) == (0.0, 1.0)
assert range_overlap([ (0.0, 1.0), (0.0, 2.0) ]) == (0.0, 1.0)
assert range_overlap([ (0.0, 1.0), (0.0, 2.0), (-1.0, 1.0) ]) == (0.0, 1.0)</pre>

<pre>---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)

&lt;ipython-input-7-8d5443158f7e&gt; in &lt;module&gt;()
----&gt; 1 assert range_overlap([ (0.0, 1.0) ]) == (0.0, 1.0)
      2 assert range_overlap([ (0.0, 1.0), (0.0, 2.0) ]) == (0.0, 1.0)
      3 assert range_overlap([ (0.0, 1.0), (0.0, 2.0), (-1.0, 1.0) ]) == (0.0, 1.0)


NameError: name 'range_overlap' is not defined</pre>

<p>The error is actually reassuring:
we haven't written <code>range_overlap</code> yet,
so if the tests passed,
it would be a sign that someone else had
and that we were accidentally using their function.</p>

<p>And as a bonus of writing these tests,
we've implicitly defined what our input and output look like:
we expect a list of pairs as input,
and produce a single pair as output.</p>

<p>Something important is missing, though.
We don't have any tests for the case where the ranges don't overlap at all:</p>

<pre>assert range_overlap([ (0.0, 1.0), (5.0, 6.0) ]) == ???</pre>

<p>What should <code>range_overlap</code> do in this case:
fail with an error message,
produce a special value like <code>(0.0, 0.0)</code> to signal that there's no overlap,
or something else?
Any actual implementation of the function will do one of these things;
writing the tests first helps us figure out which is best
<em>before</em> we're emotionally invested in whatever we happened to write
before we realized there was an issue.</p>

<p>And what about this case?</p>

<pre>assert range_overlap([ (0.0, 1.0), (1.0, 2.0) ]) == ???</pre>

<p>Do two segments that touch at their endpoints overlap or not?
Mathematicians usually say "yes",
but engineers usually say "no".
The best answer is "whatever is most useful in the rest of our program",
but again,
any actual implementation of <code>range_overlap</code> is going to do <em>something</em>,
and whatever it is ought to be consistent with what it does when there's no
overlap at all.</p>

<p>Since we're planning to use the range this function returns
as the X axis in a time series chart,
we decide that:</p>

<ol>
  <li>every overlap has to have non-zero width, and</li>
  <li>we will return the special value <code>None</code> when there's no overlap.</li>
</ol>

<p><code>None</code> is built into Python,
and means "nothing here".
(Other languages often call the equivalent value <code>null</code> or <code>nil</code>).
With that decision made,
we can finish writing our last two tests:</p>

<pre>assert range_overlap([ (0.0, 1.0), (5.0, 6.0) ]) == None
assert range_overlap([ (0.0, 1.0), (1.0, 2.0) ]) == None</pre>

<pre>---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)

&lt;ipython-input-8-d877ef460ba2&gt; in &lt;module&gt;()
----&gt; 1 assert range_overlap([ (0.0, 1.0), (5.0, 6.0) ]) == None
      2 assert range_overlap([ (0.0, 1.0), (1.0, 2.0) ]) == None


NameError: name 'range_overlap' is not defined</pre>

<p>Again,
we get an error because we haven't written our function,
but we're now ready to do so:</p>

<pre>def range_overlap(ranges):
    lowest = 0.0
    highest = 1.0
    for (low, high) in ranges:
        lowest = max(lowest, low)
        highest = min(highest, high)
    return (lowest, highest)</pre>

<p>(Take a moment to think about why we use <code>max</code> to raise <code>lowest</code>
and <code>min</code> to lower <code>highest</code>.)
We'd now like to re-run our tests,
but they're scattered across three different cells.
To make running them easier,
let's put them all in a function:</p>

<pre>def test_range_overlap():
    assert range_overlap([ (0.0, 1.0) ]) == (0.0, 1.0)
    assert range_overlap([ (0.0, 1.0), (0.0, 2.0) ]) == (0.0, 1.0)
    assert range_overlap([ (0.0, 1.0), (0.0, 2.0), (-1.0, 1.0) ]) == (0.0, 1.0)
    assert range_overlap([ (0.0, 1.0), (5.0, 6.0) ]) == None
    assert range_overlap([ (0.0, 1.0), (1.0, 2.0) ]) == None</pre>

<p>We can now test <code>range_overlap</code> with a single function call:</p>

<pre>test_range_overlap()</pre>

<pre>---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)

&lt;ipython-input-11-cf9215c96457&gt; in &lt;module&gt;()
----&gt; 1 test_range_overlap()


&lt;ipython-input-10-34c3659163fc&gt; in test_range_overlap()
      3     assert range_overlap([ (0.0, 1.0), (0.0, 2.0) ]) == (0.0, 1.0)
      4     assert range_overlap([ (0.0, 1.0), (0.0, 2.0), (-1.0, 1.0) ]) == (0.0, 1.0)
----&gt; 5     assert range_overlap([ (0.0, 1.0), (5.0, 6.0) ]) == None
      6     assert range_overlap([ (0.0, 1.0), (1.0, 2.0) ]) == None


AssertionError:</pre>

<p>The first of the tests that was supposed to produce <code>None</code> fails,
so we know there's something wrong with our function.
What we <em>don't</em> know,
though,
is whether the last of our five tests passed or failed,
because Python halted the program as soon as it spotted the first error.
Still,
some information is better than none,
and if we trace the behavior of the function with that input,
we realize that we're initializing <code>lowest</code> and <code>highest</code> to 0.0 and 1.0
respectively,
regardless of the input values.
This violates another important rule of programming:
"<a href="../../rules.html#always-initialize-from-data">always initialize from data</a>".
We'll leave it as an exercise to fix <code>range_overlap</code>.</p>

<h3>Debugging</h3>

<p>Once testing has uncovered problems,
the next step is to fix them.
Many novices do this by making more-or-less random changes to their code
until it seems to produce the right answer,
but that's very inefficient
(and the result is usually only correct for the one case they're testing).
The more experienced a programmer is,
the more systematically they debug,
and most follow some variation on the rules explained below.</p>

<h4 id="know-what-its-supposed-to-do">Know What It's Supposed to Do</h4>

<p>The first step in debugging something is to
<a href="../../rules.html#know-what-its-supposed-to-do">know what it's supposed to do</a>.
"My program doesn't work" isn't good enough:
in order to diagnose and fix problems,
we need to be able to tell correct output from incorrect.
If we can write a test case for the failing case&mdash;i.e.,
if we can assert that with <em>these</em> inputs,
the function should produce <em>that</em> result&mdash;
then we're ready to start debugging.
If we can't,
then we need to figure out how we're going to know when we've fixed things.</p>

<p>But writing test cases for scientific software is frequently harder than
writing test cases for commercial applications,
because if we knew what the output of the scientific code was supposed to be,
we wouldn't be running the software:
we'd be writing up our results and moving on to the next program.
In practice,
scientists tend to do the following:</p>

<ol>
  <li>
    <p><em>Test with simplified data.</em>
Before doing statistics on a real data set,
we should try calculating statistics for a single record,
for two identical records,
for two records whose values are one step apart,
or for some other case where we can calculate the right answer by hand.</p>
  </li>
  <li>
    <p><em>Test a simplified case.</em>
If our program is supposed to simulate
magnetic eddies in rapidly-rotating blobs of supercooled helium,
our first test should be a blob of helium that isn't rotating,
and isn't being subjected to any external electromagnetic fields.
Similarly,
if we're looking at the effects of climate change on speciation,
our first test should hold temperature, precipitation, and other factors
constant.</p>
  </li>
  <li>
    <p><em>Compare to an oracle.</em>
A <a href="#gloss:test-oracle">test oracle</a> is
something&mdash;experimental data,
an older program whose results are trusted,
or even a human expert&mdash;against which we can compare the results of our
new program.
If we have a test oracle,
we should store its output for particular cases
so that we can compare it with our new results as often as we like
without re-running that program.</p>
  </li>
  <li>
    <p><em>Check conservation laws.</em>
Mass, energy, and other quantitites are conserved in physical systems,
so they should be in programs as well.
Similarly,
if we are analyzing patient data,
the number of records should either stay the same or decrease
as we move from one analysis to the next
(since we might throw away outliers or records with missing values).
If "new" patients start appearing out of nowhere as we move through our
pipeline,
it's probably a sign that something is wrong.</p>
  </li>
  <li>
    <p><em>Visualize.</em>
Data analysts frequently use simple visualizations to check both
the science they're doing
and the correctness of their code
(just as we did in the <a href="01-numpy.html">opening lesson</a> of this tutorial).
This should only be used for debugging as a last resort,
though,
since it's very hard to compare two visualizations automatically.</p>
  </li>
</ol>

<h4 id="make-it-fail-every-time">Make It Fail Every Time</h4>

<p>We can only debug something when it fails,
so the second step is always to find a test case that
<a href="../../rules.html#make-it-fail-every-time">makes it fail every time</a>.
The "every time" part is important because
few things are more frustrating than debugging an intermittent problem:
if we have to call a function a dozen times to get a single failure,
the odds are good that we'll scroll past the failure when it actually occurs.</p>

<p>As part of this,
it's always important to check that our code is "plugged in",
i.e.,
that we're actually exercising the problem that we think we are.
Every programmer has spent hours chasing a bug,
only to realize that they were actually calling their code on the wrong data set
or with the wrong configuration parameters,
or are using the wrong version of the software entirely.
Mistakes like these are particularly likely to happen when we're tired,
frustrated,
and up against a deadline,
which is one of the reasons late-night (or overnight) coding sessions
are almost never worthwhile.</p>

<h4 id="make-it-fail-fast">Make It Fail Fast</h4>

<p>If it takes 20 minutes for the bug to surface,
we can only do three experiments an hour.
That doesn't must mean we'll get less data in more time:
we're also more likely to be distracted by other things as we wait for our
program to fail,
which means the time we <em>are</em> spending on the problem is less focused.
It's therefore critical to <a href="../../rules.html#make-it-fail-fast">make it fail fast</a>.</p>

<p>As well as making the program fail fast in time,
we want to make it fail fast in space,
i.e.,
we want to localize the failure to the smallest possible region of code:</p>

<ol>
  <li>
    <p>The smaller the gap between cause and effect,
the easier the connection is to find.
Many programmers therefore use a divide and conquer strategy to find bugs,
i.e.,
if the output of a function is wrong,
they check whether things are OK in the middle,
then concentrate on either the first or second half,
and so on.</p>
  </li>
  <li>
    <p>N things can interact in N<sup>2/2</sup> different ways,
so every line of code that <em>isn't</em> run as part of a test
means more than one thing we don't need to worry about.</p>
  </li>
</ol>

<h4 id="change-one-thing-at-a-time-for-a-reason">Change One Thing at a Time, For a Reason</h4>

<p>Replacing random chunks of code unlikely to do much good.
(After all,
if you got it wrong the first time,
you'll probably get it wrong the second and third as well.)
Good programmers therefore
<a href="../../rules.html#change-one-thing-at-a-time">change one thing at a time, for a reason</a>
They are either trying to gather more information
("is the bug still there if we change the order of the loops?")
or test a fix
("can we make the bug go away by sorting our data before processing it?").</p>

<p>Every time we make a change,
however small,
we should re-run our tests immediately,
because the more things we change at once,
the harder it is to know what's responsible for what
(those N<sup>2</sup> interactions again).
And we should re-run <em>all</em> of our tests:
more than half of fixes made to code introduce (or re-introduce) bugs,
so re-running all of our tests tells us whether we have
<a href="#gloss:regression">regressed</a>.</p>

<h4 id="keep-track-of-what-youve-done">Keep Track of What You've Done</h4>

<p>Good scientists keep track of what they've done
so that they can reproduce their work,
and so that they don't waste time repeating the same experiments
or running ones whose results won't be interesting.
Similarly,
debugging works best when we
<a href="../../rules.html#keep-track-of-what-youve-done">keep track of what we've done</a>
and how well it worked.
If we find ourselves asking,
"Did left followed by right with an odd number of lines cause the crash?
Or was it right followed by left?
Or was I using an even number of lines?"
then it's time to step away from the computer,
take a deep breath,
and start working more systematically.</p>

<p>Records are particularly useful when the time comes to ask for help.
People are more likely to listen to us
when we can explain clearly what we did,
and we're better able to give them the information they need to be useful.</p>

<h4 id="be-humble">Be Humble</h4>

<p>And speaking of help:
if we can't find a bug in 10 minutes,
we should <a href="../../rules.html#be-humble">be humble</a> and ask for help.
Just explaining the problem aloud is often useful,
since hearing what we're thinking helps us spot inconsistencies and hidden
assumptions.</p>

<p>Asking for help also helps alleviate confirmation bias.
If we have just spent an hour writing a complicated program,
we want it to work,
so we're likely to keep telling ourselves why it should,
rather than searching for the reason it doesn't.
People who aren't emotionally invested in the code can be more objective,
which is why they're often able to spot the simple mistakes we have overlooked.</p>

<p>Part of being humble is learning from our mistakes.
Programmers tend to get the same things wrong over and over:
either they don't understand the language and libraries they're working with,
or their model of how things work is wrong.
In either case,
taking note of why the error occurred
and checking for it next time
quickly turns into not making the mistake at all.</p>

<p>And that is what makes us most productive in the long run.
As the saying goes,
"<a href="../../rules.html#week-hard-work-hour-thought">A week of hard work can sometimes save you an hour of
thought</a>."
If we train ourselves to avoid making some kinds of mistakes,
to break our code into modular, testable chunks,
and to turn every assumption (or mistake) into an assertion,
it will actually take us <em>less</em> time to produce working programs,
not more.</p>

<div class="keypoints">
<h3>Key Points</h3>

<ul>
  <li>Program defensively, i.e., assume that errors are going to arise, and write
code to detect them when they do.</li>
  <li>Put assertions in programs to check their state as they run, and to help
readers understand how those programs are supposed to work.</li>
  <li>Use preconditions to check that the inputs to a function are safe to use.</li>
  <li>Use postconditions to check that the output from a function is safe to use.</li>
  <li>Write tests before writing code in order to help determine exactly what that
code is supposed to do.</li>
  <li>Know what code is supposed to do <em>before</em> trying to debug it.</li>
  <li>Make it fail every time.</li>
  <li>Make it fail fast.</li>
  <li>Change one thing at a time, and for a reason.</li>
  <li>Keep track of what you've done.</li>
  <li>Be humble.</li>
</ul>
</div>

<div class="challenges">
<ol>
  <li>
    <p>Suppose you are writing a function called <code>average</code> that calculates the
average of the numbers in a list.
What pre-conditions and post-conditions would you write for it?
Compare your answer to your neighbor's:
can you think of a function that will past your tests but not hers or vice
versa?</p>
  </li>
  <li>
    <p>Explain in words what the assertions in this code check,
and for each one,
give an example of input that will make that assertion fail.</p>

<pre>def running(values):
assert len(values) &gt; 0
result = [values[0]]
for v in values[1:]:
    assert result[-1] &gt;= 0
    result.append(result[-1] + v)
assert result[-1] &gt;= result[0]
return result</pre>
  </li>
  <li>Fix <code>range_overlap</code>. Re-run <code>test_range_overlap</code> after each change you make.</li>
</ol>
</div>

          <h2>Command-Line Programs</h2>

<p>The IPython Notebook and other interactive tools are great for prototyping code
and exploring data,
but sooner or later we will want to use our program in a pipeline
or run it in a shell script to process thousands of data files.
In order to do that,
we need to make our programs work like other Unix command-line tools.
For example,
we may want a program that reads a data set
and prints the average inflammation per patient:</p>

<pre>$ python readings.py --mean inflammation-01.csv
5.45
5.425
6.1
...
6.4
7.05
5.9</pre>

<p>but we might also want to look at the minimum of the first four lines</p>

<pre>$ head -4 inflammation-01.csv | python readings.py --min</pre>

<p>or the maximum inflammations in several files one after another:</p>

<pre>$ python readings.py --max inflammation-*.csv</pre>

<p>Our overall requirements are:</p>

<ol>
  <li>If no filename is given on the command line, read data from <a href="#gloss:standard-input">standard
input</a>.</li>
  <li>If one or more filenames are given, read data from them and report statistics
for each file separately.</li>
  <li>Use the <code>--min</code>, <code>--mean</code>, or <code>--max</code> flag to determine what statistic to
print.</li>
</ol>

<p>To make this work,
we need to know how to handle command-line arguments in a program,
and how to get at standard input.
We'll tackle these questions in turn below.</p>

<div class="objectives">
<h3>Objectives</h3>

<ul>
  <li>Use the values of command-line arguments in a program.</li>
  <li>Handle flags and files separately in a command-line program.</li>
  <li>Read data from standard input in a program so that it can be used in a
pipeline.</li>
</ul>
</div>

<h3>Command-Line Arguments</h3>

<p>Using the text editor of your choice,
save the following in a text file:</p>

<pre>!cat sys-version.py</pre>

<pre>import sys
print 'version is', sys.version</pre>

<p>The first line imports a library called <code>sys</code>,
which is short for "system".
It defines values such as <code>sys.version</code>,
which describes which version of Python we are running.
We can run this script from within the IPython Notebook like this:</p>

<pre>%run sys-version.py</pre>

<pre>version is 2.7.5 |Anaconda 1.6.1 (x86_64)| (default, Jun 28 2013, 22:20:13)
[GCC 4.0.1 (Apple Inc. build 5493)]</pre>

<p>or like this:</p>

<pre>!ipython sys-version.py</pre>

<pre>version is 2.7.5 |Anaconda 1.6.1 (x86_64)| (default, Jun 28 2013, 22:20:13)
[GCC 4.0.1 (Apple Inc. build 5493)]</pre>

<p>The first method, <code>%run</code>,
uses a special command in the IPython Notebook to run a program in a <code>.py</code> file.
The second method is more general:
the exclamation mark <code>!</code> tells the Notebook to run a shell command,
and it just so happens that the command we run is <code>ipython</code> with the name of the
script.</p>

<p>Here's another script that does something more interesting:</p>

<pre>!cat argv-list.py</pre>

<pre>import sys
print 'sys.argv is', sys.argv</pre>

<p>The strange name <code>argv</code> stands for "argument values".
Whenever Python runs a program,
it takes all of the values given on the command line
and puts them in the list <code>sys.argv</code>
so that the program can determine what they were.
If we run this program with no arguments:</p>

<pre>!ipython argv-list.py</pre>

<pre>sys.argv is ['/Users/gwilson/bc/python/novice/argv-list.py']</pre>

<p>the only thing in the list is the full path to our script,
which is always <code>sys.argv[0]</code>.
If we run it with a few arguments, however:</p>

<pre>!ipython argv-list.py first second third</pre>

<pre>sys.argv is ['/Users/gwilson/bc/python/novice/argv-list.py', 'first', 'second', 'third']</pre>

<p>then Python adds each of those arguments to that magic list.</p>

<p>With this in hand,
let's build a version of <code>readings.py</code> that always prints the per-patient mean
of a single data file.
The first step is to write a <code>main</code> function that outlines our implementation,
and a placeholder for the function that does the actual work:</p>

<pre>!cat readings-01.py</pre>

<pre>import sys
import numpy as np

def main():
    script = sys.argv[0]
    filename = sys.argv[1]
    data = np.loadtxt(filename, delimiter=',')
    for m in data.mean(axis=1):
        print m</pre>

<p>This function gets the name of the script from <code>sys.argv[0]</code>,
because that's where it's always put,
and the name of the file to process from <code>sys.argv[1]</code>.
Here's a simple test:</p>

<pre>%run readings-01.py inflammation-01.csv</pre>

<p>There is no output because we have defined a function,
but haven't actually called it.
Let's add a call to <code>main</code>:</p>

<pre>!cat readings-02.py</pre>

<pre>import sys
import numpy as np

def main():
    script = sys.argv[0]
    filename = sys.argv[1]
    data = np.loadtxt(filename, delimiter=',')
    for m in data.mean(axis=1):
        print m

main()</pre>

<p>and run that:</p>

<pre>%run readings-02.py inflammation-01.csv</pre>

<pre>5.45
5.425
6.1
5.9
5.55
6.225
5.975
6.65
6.625
6.525
6.775
5.8
6.225
5.75
5.225
6.3
6.55
5.7
5.85
6.55
5.775
5.825
6.175
6.1
5.8
6.425
6.05
6.025
6.175
6.55
6.175
6.35
6.725
6.125
7.075
5.725
5.925
6.15
6.075
5.75
5.975
5.725
6.3
5.9
6.75
5.925
7.225
6.15
5.95
6.275
5.7
6.1
6.825
5.975
6.725
5.7
6.25
6.4
7.05
5.9</pre>

<h3>Handling Multiple Files</h3>

<p>The next step is to teach our program how to handle multiple files.
Since 60 lines of output per file is a lot to page through,
we'll start by creating three smaller files,
each of which has three days of data for two patients:</p>

<pre>!ls small-*.csv</pre>

<pre>small-01.csv small-02.csv small-03.csv</pre>

<pre>!cat small-01.csv</pre>

<pre>0,0,1
0,1,2</pre>

<pre>%run readings-02.py small-01.csv</pre>

<pre>0.333333333333
1.0</pre>

<p>Using small data files as input also allows us to check our results more easily:
here,
for example,
we can see that our program is calculating the mean correctly for each line,
whereas we were really taking it on faith before.
This is yet another rule of programming:
"<a href="../../rules.html#test-simple-first">test the simple things first</a>".</p>

<p>We want our program to process each file separately,
so we need a looop that executes once for each filename.
If we specify the files on the command line,
the filenames will be in <code>sys.argv</code>,
but we need to be careful:
<code>sys.argv[0]</code> will always be the name of our script,
rather than the name of a file.
We also need to handle an unknown number of filenames,
since our program could be run for any number of files.</p>

<p>The solution to both problems is to loop over the contents of <code>sys.argv[1:]</code>.
The '1' tells Python to start the slice at location 1,
so the program's name isn't included;
since we've left off the upper bound,
the slice runs to the end of the list,
and includes all the filenames.
Here's our changed program:</p>

<pre>!cat readings-03.py</pre>

<pre>import sys
import numpy as np

def main():
    script = sys.argv[0]
    for filename in sys.argv[1:]:
       data = np.loadtxt(filename, delimiter=',')
       for m in data.mean(axis=1):
           print m

main()</pre>

<p>and here it is in action:</p>

<pre>%run readings-03.py small-01.csv small-02.csv</pre>

<pre>0.333333333333
1.0
13.6666666667
11.0</pre>

<p>Note:
at this point,
we have created three versions of our script called <code>readings-01.py</code>,
<code>readings-02.py</code>, and <code>readings-03.py</code>.
We wouldn't do this in real life:
instead,
we would have one file called <code>readings.py</code> that we committed to version control
every time we got an enhancement working.
For teaching,
though,
we need all the successive versions side by side.</p>

<h3>Handling Command-Line Flags</h3>

<p>The next step is to teach our program to pay attention to the <code>--min</code>, <code>--mean</code>,
and <code>--max</code> flags.
These always appear before the names of the files,
so we could just do this:</p>

<pre>!cat readings-04.py</pre>

<pre>import sys
import numpy as np

def main():
    script = sys.argv[0]
    action = sys.argv[1]
    filenames = sys.argv[2:]

    for f in filenames:
        data = np.loadtxt(f, delimiter=',')

        if action == '--min':
            values = data.min(axis=1)
        elif action == '--mean':
            values = data.mean(axis=1)
        elif action == '--max':
            values = data.max(axis=1)

        for m in values:
            print m

main()</pre>

<p>This works:</p>

<pre>%run readings-04.py --max small-01.csv</pre>

<pre>1.0
2.0</pre>

<p>but there are seveal things wrong with it:</p>

<ol>
  <li>
    <p><code>main</code> is too large to read comfortably.</p>
  </li>
  <li>
    <p>If <code>action</code> isn't one of the three recognized flags,
the program loads each file but does nothing with it
(because none of the branches in the conditional match).
<a href="#gloss:silent-failure">Silent failures</a> like this
are always hard to debug.</p>
  </li>
</ol>

<p>This version pulls the processing of each file out of the loop into a function
of its own.
It also checks that <code>action</code> is one of the allowed flags
before doing any processing,
so that the program fails fast:</p>

<pre>!cat readings-05.py</pre>

<pre>import sys
import numpy as np

def main():
    script = sys.argv[0]
    action = sys.argv[1]
    filenames = sys.argv[2:]
    assert action in ['--min', '--mean', '--max'], \
           'Action is not one of --min, --mean, or --max: ' + action
    for f in filenames:
        process(f, action)

def process(filename, action):
    data = np.loadtxt(filename, delimiter=',')

    if action == '--min':
        values = data.min(axis=1)
    elif action == '--mean':
        values = data.mean(axis=1)
    elif action == '--max':
        values = data.max(axis=1)

    for m in values:
        print m

main()</pre>

<p>This is four lines longer than its predecessor,
but broken into more digestible chunks of 8 and 12 lines.</p>

<h3>Handling Standard Input</h3>

<p>The next thing our program has to do is read data from standard input if no
filenames are given
so that we can put it in a pipeline,
redirect input to it,
and so on.
Let's experiment in another script:</p>

<pre>!cat count-stdin.py</pre>

<pre>import sys

count = 0
for line in sys.stdin:
    count += 1

print '{0} lines in standard input'.format(count)</pre>

<p>This little program reads lines from a special "file" called <code>sys.stdin</code>,
which is automatically connected to the program's standard input.
We don't have to open it&mdash;Python and the operating system
take care of that when the program starts up&mdash;
but we can do almost anything with it that we could do to a regular file.
Let's try running it as if it were a regular command-line program:</p>

<pre>!ipython count-stdin.py &lt; small-01.csv</pre>

<pre>2 lines in standard input</pre>

<p>What if we run it using <code>%run</code>?</p>

<pre>%run count-stdin.py &lt; fractal_1.txt</pre>

<pre>0 lines in standard input</pre>

<p>As you can see,
<code>%run</code> doesn't understand file redirection:
that's a shell thing.</p>

<p>A common mistake is to try to run something that reads from standard input like
this:</p>

<pre>!ipython count_stdin.py fractal_1.txt</pre>

<p>i.e., to forget the <code>&lt;</code> character that redirect the file to standard input.
In this case,
there's nothing in standard input,
so the program waits at the start of the loop for someone to type something on
the keyboard.
Since there's no way for us to do this,
our program is stuck,
and we have to halt it using the <code>Interrupt</code> option from the <code>Kernel</code> menu in
the Notebook.</p>

<p>We now need to rewrite the program so that it loads data from <code>sys.stdin</code> if no
filenames are provided.
Luckily,
<code>numpy.loadtxt</code> can handle either a filename or an open file as its first
parameter,
so we don't actually need to change <code>process</code>.
That leaves <code>main</code>:</p>

<pre>def main():
    script = sys.argv[0]
    action = sys.argv[1]
    filenames = sys.argv[2:]
    assert action in ['--min', '--mean', '--max'], \
           'Action is not one of --min, --mean, or --max: ' + action
    if len(filenames) == 0:
        process(sys.stdin, action)
    else:
        for f in filenames:
            process(f, action)</pre>

<p>Let's try it out
(we'll see in a moment why we send the output through <code>head</code>):</p>

<pre>!ipython readings-06.py --mean &lt; small-01.csv | head -10</pre>

<pre>[TerminalIPythonApp] CRITICAL | Bad config encountered during initialization:
[TerminalIPythonApp] CRITICAL | Unrecognized flag: '--mean'
=========
 IPython
=========

Tools for Interactive Computing in Python
=========================================

    A Python shell with automatic history (input and output), dynamic object
    introspection, easier configuration, command completion, access to the
    system shell and more.  IPython can also be embedded in running programs.</pre>

<p>Whoops:
why are we getting IPython's help rather than the line-by-line average of our
data?
The answer is that IPython has a hard time telling
which command-line arguments are meant for it,
and which are meant for the program it's running.
To make our meaning clear,
we have to use <code>--</code> (a double dash)
to separate the two:</p>

<pre>!ipython readings-06.py -- --mean &lt; small-01.csv</pre>

<pre>0.333333333333
1.0</pre>

<p>That's better.
In fact,
that's done:
the program now does everything we set out to do.</p>

<div class="keypoints">
<h3>Key Points</h3>

<ul>
  <li>The <code>sys</code> library connects a Python program to the system it is running on.</li>
  <li>The list <code>sys.argv</code> contains the command-line arguments that a program was
run with.</li>
  <li>Avoid silent failures.</li>
  <li>The "file" <code>sys.stdin</code> connects to a program's standard input.</li>
  <li>The "file" <code>sys.stdout</code> connects to a program's standard output.</li>
</ul>
</div>

<div class="challenges">
<ol>
  <li>
    <p>Write a command-line program that does addition and subtraction:</p>
<pre>
python arith.py 1 + 2
3
python arith.py 3 - 4
-1</pre>
    <p>What goes wrong if you try to add multiplication using '*' to the program?</p>
  </li>
  <li>
    <p>Using the <code>glob</code> module introduced <a href="earlier">03-loop.ipynb</a>,
write a simple version of <code>ls</code> that shows files in the current directory
with a particular suffix:</p>
<pre>
python my_ls.py py
left.py
right.py
zero.py</pre>
  </li>
  <li>Write a program called <code>check.py</code> that takes the names of one or more
inflammation data files as arguments
and checks that all the files have the same number of rows and columns.
What is the best way to test your program?</li>
  <li>
    <p>Rewrite this program so that it uses <code>-n</code>, <code>-m</code>, and <code>-x</code> instead of
<code>--min</code>, <code>--mean</code>, and <code>--max</code> respectively.
Is the code easier to read?
Is the program easier to understand?</p>
  </li>
  <li>
    <p>Separately,
modify the program so that if no parameters are given
(i.e., no action is specified and no filenames are given),
it prints a message explaining how it should be used.</p>
  </li>
  <li>
    <p>Separately,
modify the program so that if no action is given
it displays the means of the data.</p>
  </li>
  <li>Write a program called <code>line-count.py</code> that works like the Unix <code>wc</code>
command:
    <ul>
      <li>If no filenames are given, it reports the number of lines in standard
input.</li>
      <li>If one or more filenames are given, it reports the number of lines in
each, followed by the total number of lines.</li>
    </ul>
  </li>
</ol>
</div>

          <h1>Using Databases and SQL</h1>

          <p>Almost everyone has used spreadsheets,
and almost everyone has eventually run up against their limitations.
The more complicated a data set is,
the harder it is to filter data,
express relationships between different rows and columns,
or handle missing values.</p>

<p>Databases pick up where spreadsheets leave off.
While they are not as simple to use if all we want is the sum of a dozen numbers,
they can do a lot of things that spreadsheets can't,
on much larger data sets,
faster.
And even if we never need to create a database ourselves,
knowing how they work will help us understand why so many of the systems we use
behave the way we do,
and why they insist on structuring data in certain ways.</p>

<p>In the late 1920s and early 1930s,
William Dyer,
Frank Pabodie,
and Valentina Roerich led expeditions to the
<a href="http://en.wikipedia.org/wiki/Pole_of_inaccessibility">Pole of Inaccessibility</a>
in the South Pacific,
and then onward to Antarctica.
Two years ago,
their expeditions were found in a storage locker at Miskatonic University.
We have scanned and OCR'd the data they contain,
and we now want to store that information
in a way that will make search and analysis easy.</p>

<p>We basically have three options:
text files,
a spreadsheet,
or a database.
Text files are easiest to create,
and work well with version control,
but then we would then have to build search and analysis tools ourselves.
Spreadsheets are good for doing simple analysis,
they don't handle large or complex data sets very well.
We would therefore like to put this data in a database,
and these lessons will show how to do that.</p>

          <h2>Selecting Data</h2>

<p>A <a href="#gloss:relational-database">relational database</a>
is a way to store and manipulate information
that is arranged as <a href="#gloss:table-database">tables</a>.
Each table has columns (also known as <a href="#gloss:field-database">fields</a>)
which describe the data,
and rows (also known as <a href="#gloss:record-database">records</a>) which
contain the data.</p>

<p>When we are using a spreadsheet,
we put formulas into cells to calculate new values based on old ones.
When we are using a database,
we send commands
(usually called <a href="#gloss:query">queries</a>)
to a <a href="#gloss:database-manager">database manager</a>:
a program that manipulates the database for us.
The database manager does whatever lookups and calculations the query specifies,
returning the results in a tabular form
that we can then use as a starting point for further queries.</p>

<blockquote>
  <p>Every database manager&mdash;Oracle,
IBM DB2, PostgreSQL, MySQL, Microsoft Access, and SQLite&mdash;stores
data in a different way,
so a database created with one cannot be used directly by another.
However,
every database manager can import and export data in a variety of formats,
so it <em>is</em> possible to move information from one to another.</p>
</blockquote>

<p>Queries are written in a language called <a href="#gloss:sql">SQL</a>,
which stands for "Structured Query Language".
SQL provides hundreds of different ways to analyze and recombine data;
we will only look at a handful,
but that handful accounts for most of what scientists do.</p>

<p>The tables below show the database we will use in our examples:</p>

<table>
<tr>
<td valign="top">
<strong>Person</strong>: people who took readings.

<table>
  <tr> <th>ident</th> <th>personal</th> <th>family</th> </tr>
  <tr> <td>dyer</td> <td>William</td> <td>Dyer</td> </tr>
  <tr> <td>pb</td> <td>Frank</td> <td>Pabodie</td> </tr>
  <tr> <td>lake</td> <td>Anderson</td> <td>Lake</td> </tr>
  <tr> <td>roe</td> <td>Valentina</td> <td>Roerich</td> </tr>
  <tr> <td>danforth</td> <td>Frank</td> <td>Danforth</td> </tr>
</table>

<strong>Site</strong>: locations where readings were taken.

<table>
  <tr> <th>name</th> <th>lat</th> <th>long</th> </tr>
  <tr> <td>DR-1</td> <td>-49.85</td> <td>-128.57</td> </tr>
  <tr> <td>DR-3</td> <td>-47.15</td> <td>-126.72</td> </tr>
  <tr> <td>MSK-4</td> <td>-48.87</td> <td>-123.4</td> </tr>
</table>

<strong>Visited</strong>: when readings were taken at specific sites.

<table>
  <tr> <th>ident</th> <th>site</th> <th>dated</th> </tr>
  <tr> <td>619</td> <td>DR-1</td> <td>1927-02-08</td> </tr>
  <tr> <td>622</td> <td>DR-1</td> <td>1927-02-10</td> </tr>
  <tr> <td>734</td> <td>DR-3</td> <td>1939-01-07</td> </tr>
  <tr> <td>735</td> <td>DR-3</td> <td>1930-01-12</td> </tr>
  <tr> <td>751</td> <td>DR-3</td> <td>1930-02-26</td> </tr>
  <tr> <td>752</td> <td>DR-3</td> <td>NULL</td> </tr>
  <tr> <td>837</td> <td>MSK-4</td> <td>1932-01-14</td> </tr>
  <tr> <td>844</td> <td>DR-1</td> <td>1932-03-22</td> </tr>
</table>
</td>
<td valign="top">
<strong>Survey</strong>: the actual readings.

<table>
  <tr> <th>taken</th> <th>person</th> <th>quant</th> <th>reading</th> </tr>
  <tr> <td>619</td> <td>dyer</td> <td>rad</td> <td>9.82</td> </tr>
  <tr> <td>619</td> <td>dyer</td> <td>sal</td> <td>0.13</td> </tr>
  <tr> <td>622</td> <td>dyer</td> <td>rad</td> <td>7.8</td> </tr>
  <tr> <td>622</td> <td>dyer</td> <td>sal</td> <td>0.09</td> </tr>
  <tr> <td>734</td> <td>pb</td> <td>rad</td> <td>8.41</td> </tr>
  <tr> <td>734</td> <td>lake</td> <td>sal</td> <td>0.05</td> </tr>
  <tr> <td>734</td> <td>pb</td> <td>temp</td> <td>-21.5</td> </tr>
  <tr> <td>735</td> <td>pb</td> <td>rad</td> <td>7.22</td> </tr>
  <tr> <td>735</td> <td>NULL</td> <td>sal</td> <td>0.06</td> </tr>
  <tr> <td>735</td> <td>NULL</td> <td>temp</td> <td>-26.0</td> </tr>
  <tr> <td>751</td> <td>pb</td> <td>rad</td> <td>4.35</td> </tr>
  <tr> <td>751</td> <td>pb</td> <td>temp</td> <td>-18.5</td> </tr>
  <tr> <td>751</td> <td>lake</td> <td>sal</td> <td>0.1</td> </tr>
  <tr> <td>752</td> <td>lake</td> <td>rad</td> <td>2.19</td> </tr>
  <tr> <td>752</td> <td>lake</td> <td>sal</td> <td>0.09</td> </tr>
  <tr> <td>752</td> <td>lake</td> <td>temp</td> <td>-16.0</td> </tr>
  <tr> <td>752</td> <td>roe</td> <td>sal</td> <td>41.6</td> </tr>
  <tr> <td>837</td> <td>lake</td> <td>rad</td> <td>1.46</td> </tr>
  <tr> <td>837</td> <td>lake</td> <td>sal</td> <td>0.21</td> </tr>
  <tr> <td>837</td> <td>roe</td> <td>sal</td> <td>22.5</td> </tr>
  <tr> <td>844</td> <td>roe</td> <td>rad</td> <td>11.25</td> </tr>
</table>
</td>
</tr>
</table>

<p>Notice that three entries&mdash;one in the <code>Visited</code> table,
and two in the <code>Survey</code> table&mdash;are shown as <code>NULL</code>.
We'll return to these values <a href="#s:null">later</a>.
For now,
let's write an SQL query that displays scientists' names.
We do this using the SQL command <code>select</code>,
giving it the names of the columns we want and the table we want them from.
Our query and its output look like this:</p>

<pre>select family, personal from Person;</pre>
<table>
<tr><td>Dyer</td><td>William</td></tr>
<tr><td>Pabodie</td><td>Frank</td></tr>
<tr><td>Lake</td><td>Anderson</td></tr>
<tr><td>Roerich</td><td>Valentina</td></tr>
<tr><td>Danforth</td><td>Frank</td></tr>
</table>

<p>The semi-colon at the end of the query
tells the database manager that the query is complete and ready to run.
We have written our commands and column names in lower case,
and the table name in Title Case,
but we don't have to:
as the example below shows,
SQL is <a href="#gloss:case-insensitive">case insensitive</a>.</p>

<pre>SeLeCt FaMiLy, PeRsOnAl FrOm PeRsOn;</pre>

<p>Whatever casing convention you choose,
please be consistent:
complex queries are hard enough to read without the extra cognitive load of
random capitalization.</p>

<p>Going back to our query,
it's important to understand that
the rows and columns in a database table aren't actually stored in any
particular order.
They will always be <em>displayed</em> in some order,
but we can control that in various ways.
For example,
we could swap the columns in the output by writing our query as:</p>

<pre>select personal, family from Person;</pre>
<table>
<tr><td>William</td><td>Dyer</td></tr>
<tr><td>Frank</td><td>Pabodie</td></tr>
<tr><td>Anderson</td><td>Lake</td></tr>
<tr><td>Valentina</td><td>Roerich</td></tr>
<tr><td>Frank</td><td>Danforth</td></tr>
</table>

<p>or even repeat columns:</p>

<pre>select ident, ident, ident from Person;</pre>
<table>
<tr><td>dyer</td><td>dyer</td><td>dyer</td></tr>
<tr><td>pb</td><td>pb</td><td>pb</td></tr>
<tr><td>lake</td><td>lake</td><td>lake</td></tr>
<tr><td>roe</td><td>roe</td><td>roe</td></tr>
<tr><td>danforth</td><td>danforth</td><td>danforth</td></tr>
</table>

<p>As a shortcut,
we can select all of the columns in a table using <code>*</code>:</p>

<pre>select * from Person;</pre>
<table>
<tr><td>dyer</td><td>William</td><td>Dyer</td></tr>
<tr><td>pb</td><td>Frank</td><td>Pabodie</td></tr>
<tr><td>lake</td><td>Anderson</td><td>Lake</td></tr>
<tr><td>roe</td><td>Valentina</td><td>Roerich</td></tr>
<tr><td>danforth</td><td>Frank</td><td>Danforth</td></tr>
</table>

<div class="challenges">
<h3>Challenges</h3>
<ol>
  <li>
    <p>Write a query that selects only site names from the <code>Site</code> table.</p>
  </li>
  <li>
    <p>Many people format queries as:</p>

<pre>SELECT personal, family FROM person;</pre>

    <p>or as:</p>

<pre>select Personal, Family from PERSON;</pre>

    <p>What style do you find easiest to read, and why?</p>
  </li>
</ol>
</div>

          <h2>Sorting and Removing Duplicates</h2>

<p>Data is often redundant,
so queries often return redundant information.
For example,
if we select the quantitites that have been measured
from the <code>survey</code> table,
we get this:</p>

<pre>select quant from Survey;</pre>
<table>
<tr><td>rad</td></tr>
<tr><td>sal</td></tr>
<tr><td>rad</td></tr>
<tr><td>sal</td></tr>
<tr><td>rad</td></tr>
<tr><td>sal</td></tr>
<tr><td>temp</td></tr>
<tr><td>rad</td></tr>
<tr><td>sal</td></tr>
<tr><td>temp</td></tr>
<tr><td>rad</td></tr>
<tr><td>temp</td></tr>
<tr><td>sal</td></tr>
<tr><td>rad</td></tr>
<tr><td>sal</td></tr>
<tr><td>temp</td></tr>
<tr><td>sal</td></tr>
<tr><td>rad</td></tr>
<tr><td>sal</td></tr>
<tr><td>sal</td></tr>
<tr><td>rad</td></tr>
</table>

<p>We can eliminate the redundant output
to make the result more readable
by adding the <code>distinct</code> keyword
to our query:</p>

<pre>select distinct quant from Survey;</pre>
<table>
<tr><td>rad</td></tr>
<tr><td>sal</td></tr>
<tr><td>temp</td></tr>
</table>

<p>If we select more than one column&mdash;for example,
both the survey site ID and the quantity measured&mdash;then
the distinct pairs of values are returned:</p>

<pre>select distinct taken, quant from Survey;</pre>
<table>
<tr><td>619</td><td>rad</td></tr>
<tr><td>619</td><td>sal</td></tr>
<tr><td>622</td><td>rad</td></tr>
<tr><td>622</td><td>sal</td></tr>
<tr><td>734</td><td>rad</td></tr>
<tr><td>734</td><td>sal</td></tr>
<tr><td>734</td><td>temp</td></tr>
<tr><td>735</td><td>rad</td></tr>
<tr><td>735</td><td>sal</td></tr>
<tr><td>735</td><td>temp</td></tr>
<tr><td>751</td><td>rad</td></tr>
<tr><td>751</td><td>temp</td></tr>
<tr><td>751</td><td>sal</td></tr>
<tr><td>752</td><td>rad</td></tr>
<tr><td>752</td><td>sal</td></tr>
<tr><td>752</td><td>temp</td></tr>
<tr><td>837</td><td>rad</td></tr>
<tr><td>837</td><td>sal</td></tr>
<tr><td>844</td><td>rad</td></tr>
</table>

<p>Notice in both cases that duplicates are removed
even if they didn't appear to be adjacent in the database.
Again,
it's important to remember that rows aren't actually ordered:
they're just displayed that way.</p>

<p>As we mentioned earlier,
database records are not stored in any particular order.
This means that query results aren't necessarily sorted,
and even if they are,
we often want to sort them in a different way,
e.g., by the name of the project instead of by the name of the scientist.
We can do this in SQL by adding an <code>order by</code> clause to our query:</p>

<pre>select * from Person order by ident;</pre>
<table>
<tr><td>danforth</td><td>Frank</td><td>Danforth</td></tr>
<tr><td>dyer</td><td>William</td><td>Dyer</td></tr>
<tr><td>lake</td><td>Anderson</td><td>Lake</td></tr>
<tr><td>pb</td><td>Frank</td><td>Pabodie</td></tr>
<tr><td>roe</td><td>Valentina</td><td>Roerich</td></tr>
</table>

<p>By default,
results are sorted in ascending order
(i.e.,
from least to greatest).
We can sort in the opposite order using <code>desc</code> (for "descending"):</p>

<pre>select * from person order by ident desc;</pre>
<table>
<tr><td>roe</td><td>Valentina</td><td>Roerich</td></tr>
<tr><td>pb</td><td>Frank</td><td>Pabodie</td></tr>
<tr><td>lake</td><td>Anderson</td><td>Lake</td></tr>
<tr><td>dyer</td><td>William</td><td>Dyer</td></tr>
<tr><td>danforth</td><td>Frank</td><td>Danforth</td></tr>
</table>

<p>(And if we want to make it clear that we're sorting in ascending order,
we can use <code>asc</code> instead of <code>desc</code>.)</p>

<p>We can also sort on several fields at once.
For example,
this query sorts results first in ascending order by <code>taken</code>,
and then in descending order by <code>person</code>
within each group of equal <code>taken</code> values:</p>

<pre>select taken, person from Survey order by taken asc, person desc;</pre>
<table>
<tr><td>619</td><td>dyer</td></tr>
<tr><td>619</td><td>dyer</td></tr>
<tr><td>622</td><td>dyer</td></tr>
<tr><td>622</td><td>dyer</td></tr>
<tr><td>734</td><td>pb</td></tr>
<tr><td>734</td><td>pb</td></tr>
<tr><td>734</td><td>lake</td></tr>
<tr><td>735</td><td>pb</td></tr>
<tr><td>735</td><td></td></tr>
<tr><td>735</td><td></td></tr>
<tr><td>751</td><td>pb</td></tr>
<tr><td>751</td><td>pb</td></tr>
<tr><td>751</td><td>lake</td></tr>
<tr><td>752</td><td>roe</td></tr>
<tr><td>752</td><td>lake</td></tr>
<tr><td>752</td><td>lake</td></tr>
<tr><td>752</td><td>lake</td></tr>
<tr><td>837</td><td>roe</td></tr>
<tr><td>837</td><td>lake</td></tr>
<tr><td>837</td><td>lake</td></tr>
<tr><td>844</td><td>roe</td></tr>
</table>

<p>This is easier to understand if we also remove duplicates:</p>

<pre>select distinct taken, person from Survey order by taken asc, person desc;</pre>
<table>
<tr><td>619</td><td>dyer</td></tr>
<tr><td>622</td><td>dyer</td></tr>
<tr><td>734</td><td>pb</td></tr>
<tr><td>734</td><td>lake</td></tr>
<tr><td>735</td><td>pb</td></tr>
<tr><td>735</td><td></td></tr>
<tr><td>751</td><td>pb</td></tr>
<tr><td>751</td><td>lake</td></tr>
<tr><td>752</td><td>roe</td></tr>
<tr><td>752</td><td>lake</td></tr>
<tr><td>837</td><td>roe</td></tr>
<tr><td>837</td><td>lake</td></tr>
<tr><td>844</td><td>roe</td></tr>
</table>

<div class="challenges">
<h3>Challenges</h3>
<ol>
  <li>Write a query that selects distinct dates from the <code>Site</code> table.</li>
  <li>Write a query that displays scientists' full names, but orders them by
surname.</li>
</ol>
</div>

          <h2>Filtering</h2>

<p>One of the most powerful features of a database is
the ability to <a href="#gloss:filter">filter</a> data,
i.e.,
to select only those records that match certain criteria.
For example,
suppose we want to see when a particular site was visited.
We can select these records from the <code>Visited</code> table
by using a <code>where</code> clause in our query:</p>

<pre>select * from Visited where site='DR-1';</pre>
<table>
<tr><td>619</td><td>DR-1</td><td>1927-02-08</td></tr>
<tr><td>622</td><td>DR-1</td><td>1927-02-10</td></tr>
<tr><td>844</td><td>DR-1</td><td>1932-03-22</td></tr>
</table>

<p>The database manager executes this query in two stages.
First,
it checks at each row in the <code>Visited</code> table
to see which ones satisfy the <code>where</code>.
It then uses the column names following the <code>select</code> keyword
to determine what columns to display.</p>

<p>This processing order means that
we can filter records using <code>where</code>
based on values in columns that aren't then displayed:</p>

<pre>select ident from Visited where site='DR-1';</pre>
<table>
<tr><td>619</td></tr>
<tr><td>622</td></tr>
<tr><td>844</td></tr>
</table>

<p><img src="sql/novice/img/sql-filter.svg" alt="SQL Filtering in Action" /></p>

<p>We can use many other Boolean operators to filter our data.
For example,
we can ask for all information from the DR-1 site collected since 1930:</p>

<pre>select * from Visited where (site='DR-1') and (dated&gt;='1930-00-00');</pre>
<table>
<tr><td>844</td><td>DR-1</td><td>1932-03-22</td></tr>
</table>

<p>(The parentheses around the individual tests aren't strictly required,
but they help make the query easier to read.)</p>

<blockquote>
  <p>Most database managers have a special data type for dates.
In fact, many have two:
one for dates,
such as "May 31, 1971",
and one for durations,
such as "31 days".
SQLite doesn't:
instead,
it stores dates as either text
(in the ISO-8601 standard format "YYYY-MM-DD HH:MM:SS.SSSS"),
real numbers
(the number of days since November 24, 4714 BCE),
or integers
(the number of seconds since midnight, January 1, 1970).
If this sounds complicated,
it is,
but not nearly as complicated as figuring out
<a href="http://en.wikipedia.org/wiki/Swedish_calendar">historical dates in Sweden</a>.</p>
</blockquote>

<p>If we want to find out what measurements were taken by either Lake or Roerich,
we can combine the tests on their names using <code>or</code>:</p>

<pre>select * from Survey where person='lake' or person='roe';</pre>
<table>
<tr><td>734</td><td>lake</td><td>sal</td><td>0.05</td></tr>
<tr><td>751</td><td>lake</td><td>sal</td><td>0.1</td></tr>
<tr><td>752</td><td>lake</td><td>rad</td><td>2.19</td></tr>
<tr><td>752</td><td>lake</td><td>sal</td><td>0.09</td></tr>
<tr><td>752</td><td>lake</td><td>temp</td><td>-16.0</td></tr>
<tr><td>752</td><td>roe</td><td>sal</td><td>41.6</td></tr>
<tr><td>837</td><td>lake</td><td>rad</td><td>1.46</td></tr>
<tr><td>837</td><td>lake</td><td>sal</td><td>0.21</td></tr>
<tr><td>837</td><td>roe</td><td>sal</td><td>22.5</td></tr>
<tr><td>844</td><td>roe</td><td>rad</td><td>11.25</td></tr>
</table>

<p>Alternatively,
we can use <code>in</code> to see if a value is in a specific set:</p>

<pre>select * from Survey where person in ('lake', 'roe');</pre>
<table>
<tr><td>734</td><td>lake</td><td>sal</td><td>0.05</td></tr>
<tr><td>751</td><td>lake</td><td>sal</td><td>0.1</td></tr>
<tr><td>752</td><td>lake</td><td>rad</td><td>2.19</td></tr>
<tr><td>752</td><td>lake</td><td>sal</td><td>0.09</td></tr>
<tr><td>752</td><td>lake</td><td>temp</td><td>-16.0</td></tr>
<tr><td>752</td><td>roe</td><td>sal</td><td>41.6</td></tr>
<tr><td>837</td><td>lake</td><td>rad</td><td>1.46</td></tr>
<tr><td>837</td><td>lake</td><td>sal</td><td>0.21</td></tr>
<tr><td>837</td><td>roe</td><td>sal</td><td>22.5</td></tr>
<tr><td>844</td><td>roe</td><td>rad</td><td>11.25</td></tr>
</table>

<p>We can combine <code>and</code> with <code>or</code>,
but we need to be careful about which operator is executed first.
If we <em>don't</em> use parentheses,
we get this:</p>

<pre>select * from Survey where quant='sal' and person='lake' or person='roe';</pre>
<table>
<tr><td>734</td><td>lake</td><td>sal</td><td>0.05</td></tr>
<tr><td>751</td><td>lake</td><td>sal</td><td>0.1</td></tr>
<tr><td>752</td><td>lake</td><td>sal</td><td>0.09</td></tr>
<tr><td>752</td><td>roe</td><td>sal</td><td>41.6</td></tr>
<tr><td>837</td><td>lake</td><td>sal</td><td>0.21</td></tr>
<tr><td>837</td><td>roe</td><td>sal</td><td>22.5</td></tr>
<tr><td>844</td><td>roe</td><td>rad</td><td>11.25</td></tr>
</table>

<p>which is salinity measurements by Lake,
and <em>any</em> measurement by Roerich.
We probably want this instead:</p>

<pre>select * from Survey where quant='sal' and (person='lake' or person='roe');</pre>
<table>
<tr><td>734</td><td>lake</td><td>sal</td><td>0.05</td></tr>
<tr><td>751</td><td>lake</td><td>sal</td><td>0.1</td></tr>
<tr><td>752</td><td>lake</td><td>sal</td><td>0.09</td></tr>
<tr><td>752</td><td>roe</td><td>sal</td><td>41.6</td></tr>
<tr><td>837</td><td>lake</td><td>sal</td><td>0.21</td></tr>
<tr><td>837</td><td>roe</td><td>sal</td><td>22.5</td></tr>
</table>

<p>Finally,
we can use <code>distinct</code> with <code>where</code>
to give a second level of filtering:</p>

<pre>select distinct person, quant from Survey where person='lake' or person='roe';</pre>
<table>
<tr><td>lake</td><td>sal</td></tr>
<tr><td>lake</td><td>rad</td></tr>
<tr><td>lake</td><td>temp</td></tr>
<tr><td>roe</td><td>sal</td></tr>
<tr><td>roe</td><td>rad</td></tr>
</table>

<p>But remember:
<code>distinct</code> is applied to the values displayed in the chosen columns,
not to the entire rows as they are being processed.</p>

<blockquote>
  <p>What we have just done is how most people "grow" their SQL queries.
We started with something simple that did part of what we wanted,
then added more clauses one by one,
testing their effects as we went.
This is a good strategy&mdash;in fact,
for complex queries it's often the <em>only</em> strategy&mdash;but
it depends on quick turnaround,
and on us recognizing the right answer when we get it.</p>

  <p>The best way to achieve quick turnaround is often
to put a subset of data in a temporary database
and run our queries against that,
or to fill a small database with synthesized records.
For example,
instead of trying our queries against an actual database of 20 million
Australians,
we could run it against a sample of ten thousand,
or write a small program to generate ten thousand random (but plausible)
records
and use that.</p>
</blockquote>

<div class="challenges">
<h3>Challenges</h3>
<ol>
  <li>
    <p>Suppose we want to select all sites that lie within 30&deg; of the equator.
Our first query is:</p>

<pre>select * from Site where (lat &gt; -30) or (lat &lt; 30);</pre>

    <p>Explain why this is wrong,
and rewrite the query so that it is correct.</p>
  </li>
  <li>
    <p>Normalized salinity readings are supposed to be between 0.0 and 1.0.
Write a query that selects all records from <code>Survey</code>
with salinity values outside this range.</p>
  </li>
  <li>
    <p>The SQL test <code><em>column-name</em> like <em>pattern</em></code>
is true if the value in the named column
matches the pattern given;
the character '%' can be used any number of times in the pattern
to mean "match zero or more characters".</p>

    <table>
  <tr> <th>Expression</th> <th>Value</th> </tr>
  <tr> <td><code>'a' like 'a'</code></td> <td>True</td> </tr>
  <tr> <td><code>'a' like '%a'</code></td> <td>True</td> </tr>
  <tr> <td><code>'b' like '%a'</code></td> <td>False</td> </tr>
  <tr> <td><code>'alpha' like 'a%'</code></td> <td>True</td> </tr>
  <tr> <td><code>'alpha' like 'a%p%'</code> <td>True</td>

The expression <code><em>column-name</em> not like <em>pattern</em></code>
inverts the test.
Using <code>like</code>,
write a query that finds all the records in `Visited`
that <em>aren't</em> from sites labelled 'DR-something'.
</td></tr></table>
  </li>
</ol>
</div>

          <h2>Calculating New Values</h2>

<p>After carefully re-reading the expedition logs,
we realize that the radiation measurements they report
may need to be corrected upward by 5%.
Rather than modifying the stored data,
we can do this calculation on the fly
as part of our query:</p>

<pre>select 1.05 * reading from Survey where quant='rad';</pre>
<table>
<tr><td>10.311</td></tr>
<tr><td>8.19</td></tr>
<tr><td>8.8305</td></tr>
<tr><td>7.581</td></tr>
<tr><td>4.5675</td></tr>
<tr><td>2.2995</td></tr>
<tr><td>1.533</td></tr>
<tr><td>11.8125</td></tr>
</table>

<p>When we run the query,
the expression <code>1.05 * reading</code> is evaluated for each row.
Expressions can use any of the fields,
all of usual arithmetic operators,
and a variety of common functions.
(Exactly which ones depends on which database manager is being used.)
For example,
we can convert temperature readings from Fahrenheit to Celsius
and round to two decimal places:</p>

<pre>select taken, round(5*(reading-32)/9, 2) from Survey where quant='temp';</pre>

<p>We can also combine values from different fields,
for example by using the string concatenation operator <code>||</code>:</p>

<pre>select personal || ' ' || family from Person;</pre>
<table>
<tr><td>William Dyer</td></tr>
<tr><td>Frank Pabodie</td></tr>
<tr><td>Anderson Lake</td></tr>
<tr><td>Valentina Roerich</td></tr>
<tr><td>Frank Danforth</td></tr>
</table>

<blockquote>
  <p>It may seem strange to use <code>personal</code> and <code>family</code> as field names
instead of <code>first</code> and <code>last</code>,
but it's a necessary first step toward handling cultural differences.
For example,
consider the following rules:</p>
</blockquote>

<table>
  <tr> <th>Full Name</th> <th>Alphabetized Under</th> <th>Reason</th> </tr>
  <tr> <td>Liu Xiaobo</td> <td>Liu</td> <td>Chinese family names come first</td>
</tr>
  <tr> <td> Leonardo da Vinci</td> <td>Leonardo</td> <td>"da Vinci" just means "from Vinci"</td> </tr>
  <tr> <td> Catherine de Medici</td> <td>Medici</td> <td>family name</td> </tr>
  <tr> <td> Jean de La Fontaine</td> <td>La Fontaine</td> <td>family name is "La Fontaine"</td> </tr>
  <tr> <td> Juan Ponce de Leon</td> <td>Ponce de Leon</td> <td>full family name is "Ponce de Leon"</td> </tr>
  <tr> <td> Gabriel Garcia Marquez</td> <td>Garcia Marquez</td> <td>double-barrelled Spanish surnames</td> </tr>
  <tr> <td> Wernher von Braun</td> <td>von <em>or</em> Braun</td> <td>depending on whether he was in Germany or the US</td> </tr>
  <tr> <td> Elizabeth Alexandra May Windsor</td> <td>Elizabeth</td> <td>monarchs alphabetize by the name under which they reigned</td> </tr>
  <tr> <td> Thomas a Beckett</td> <td>Thomas</td> <td>and saints according to the names by which they were canonized</td> </tr>
</table>

<blockquote>
  <p>Clearly,
even a two-part division into "personal" and "family"
isn't enough...</p>
</blockquote>

<div class="challenges">
<h3>Challenges</h3>

<ol>
  <li>
    <p>After further reading,
we realize that Valentina Roerich
was reporting salinity as percentages.
Write a query that returns all of her salinity measurements
from the <code>Survey</code> table
with the values divided by 100.</p>
  </li>
  <li>
    <p>The <code>union</code> operator combines the results of two queries:</p>

<pre>select * from Person where ident='dyer' union select * from Person where ident='roe';</pre>

<p>Use <code>union</code> to create a consolidated list of salinity measurements
in which Roerich's, and only Roerich's,
have been corrected as described in the previous challenge.
The output should be something like:</p>

<table>
  <tr> <td>619</td> <td>0.13</td> </tr>
  <tr> <td>622</td> <td>0.09</td> </tr>
  <tr> <td>734</td> <td>0.05</td> </tr>
  <tr> <td>751</td> <td>0.1</td> </tr>
  <tr> <td>752</td> <td>0.09</td> </tr>
  <tr> <td>752</td> <td>0.416</td> </tr>
  <tr> <td>837</td> <td>0.21</td> </tr>
  <tr> <td>837</td> <td>0.225</td> </tr>
</table>
</li>
  <li>
    <p>The site identifiers in the <code>Visited</code> table have two parts
separated by a '-':</p>

<pre>select distinct site from Visited;</pre>

<p>Some major site identifiers are two letters long and some are three.
The "in string" function <code>instr(X, Y)</code>
returns the 1-based index of the first occurrence of string Y in string X,
or 0 if Y does not exist in X.
The substring function <code>substr(X, I)</code>
returns the substring of X starting at index I.
Use these two functions to produce a list of unique major site identifiers.
(For this data,
the list should contain only "DR" and "MSK").</p>
</li>
</ol>
</div>

          <h2>Missing Data</h2>

<p>Real-world data is never complete&mdash;there are always holes.
Databases represent these holes using special value called <code>null</code>.
<code>null</code> is not zero, <code>False</code>, or the empty string;
it is a one-of-a-kind value that means "nothing here".
Dealing with <code>null</code> requires a few special tricks
and some careful thinking.</p>

<p>To start,
let's have a look at the <code>Visited</code> table.
There are eight records,
but #752 doesn't have a date&mdash;or rather,
its date is null:</p>

<pre>select * from Visited;</pre>
<table>
<tr><td>619</td><td>DR-1</td><td>1927-02-08</td></tr>
<tr><td>622</td><td>DR-1</td><td>1927-02-10</td></tr>
<tr><td>734</td><td>DR-3</td><td>1939-01-07</td></tr>
<tr><td>735</td><td>DR-3</td><td>1930-01-12</td></tr>
<tr><td>751</td><td>DR-3</td><td>1930-02-26</td></tr>
<tr><td>752</td><td>DR-3</td><td></td></tr>
<tr><td>837</td><td>MSK-4</td><td>1932-01-14</td></tr>
<tr><td>844</td><td>DR-1</td><td>1932-03-22</td></tr>
</table>

<p>Null doesn't behave like other values.
If we select the records that come before 1930:</p>

<pre>select * from Visited where dated&lt;'1930-00-00';</pre>
<table>
<tr><td>619</td><td>DR-1</td><td>1927-02-08</td></tr>
<tr><td>622</td><td>DR-1</td><td>1927-02-10</td></tr>
</table>

<p>we get two results,
and if we select the ones that come during or after 1930:</p>

<pre>select * from Visited where dated&gt;='1930-00-00';</pre>
<table>
<tr><td>734</td><td>DR-3</td><td>1939-01-07</td></tr>
<tr><td>735</td><td>DR-3</td><td>1930-01-12</td></tr>
<tr><td>751</td><td>DR-3</td><td>1930-02-26</td></tr>
<tr><td>837</td><td>MSK-4</td><td>1932-01-14</td></tr>
<tr><td>844</td><td>DR-1</td><td>1932-03-22</td></tr>
</table>

<p>we get five,
but record #752 isn't in either set of results.
The reason is that
<code>null&lt;'1930-00-00'</code>
is neither true nor false:
null means, "We don't know,"
and if we don't know the value on the left side of a comparison,
we don't know whether the comparison is true or false.
Since databases represent "don't know" as null,
the value of <code>null&lt;'1930-00-00'</code>
is actually <code>null</code>.
<code>null&gt;='1930-00-00'</code> is also null
because we can't answer to that question either.
And since the only records kept by a <code>where</code>
are those for which the test is true,
record #752 isn't included in either set of results.</p>

<p>Comparisons aren't the only operations that behave this way with nulls.
<code>1+null</code> is <code>null</code>,
<code>5*null</code> is <code>null</code>,
<code>log(null)</code> is <code>null</code>,
and so on.
In particular,
comparing things to null with = and != produces null,
so both of these commands have no output:</p>

<pre>select * from Visited where dated=NULL;
select * from Visited where dated!=NULL;</pre>

<p>To check whether a value is <code>null</code> or not,
we must use a special test <code>is null</code>:</p>

<pre>select * from Visited where dated is NULL;</pre>
<table>
<tr><td>752</td><td>DR-3</td><td></td></tr>
</table>

<p>or its inverse <code>is not null</code>:</p>

<pre>select * from Visited where dated is not NULL;</pre>
<table>
<tr><td>619</td><td>DR-1</td><td>1927-02-08</td></tr>
<tr><td>622</td><td>DR-1</td><td>1927-02-10</td></tr>
<tr><td>734</td><td>DR-3</td><td>1939-01-07</td></tr>
<tr><td>735</td><td>DR-3</td><td>1930-01-12</td></tr>
<tr><td>751</td><td>DR-3</td><td>1930-02-26</td></tr>
<tr><td>837</td><td>MSK-4</td><td>1932-01-14</td></tr>
<tr><td>844</td><td>DR-1</td><td>1932-03-22</td></tr>
</table>

<p>Null values cause headaches wherever they appear.
For example,
suppose we want to find the all of salinity measurements
that weren't taken by Dyer.
It's natural to write the query like this:</p>

<pre>select * from Survey where quant='sal' and person!='lake';</pre>
<table>
<tr><td>619</td><td>dyer</td><td>sal</td><td>0.13</td></tr>
<tr><td>622</td><td>dyer</td><td>sal</td><td>0.09</td></tr>
<tr><td>752</td><td>roe</td><td>sal</td><td>41.6</td></tr>
<tr><td>837</td><td>roe</td><td>sal</td><td>22.5</td></tr>
</table>

<p>but this query filters omits the records
where we don't know who took the measurement.
Once again,
the reason is that when <code>person</code> is <code>null</code>,
the <code>!=</code> comparison produces <code>null</code>,
so the record isn't kept in our results.
If we want to keep these records
we need to add an explicit check:</p>

<pre>select * from Survey where quant='sal' and (person!='lake' or person is null);</pre>
<table>
<tr><td>619</td><td>dyer</td><td>sal</td><td>0.13</td></tr>
<tr><td>622</td><td>dyer</td><td>sal</td><td>0.09</td></tr>
<tr><td>735</td><td></td><td>sal</td><td>0.06</td></tr>
<tr><td>752</td><td>roe</td><td>sal</td><td>41.6</td></tr>
<tr><td>837</td><td>roe</td><td>sal</td><td>22.5</td></tr>
</table>

<p>We still have to decide whether this is the right thing to do or not.
If we want to be absolutely sure that
we aren't including any measurements by Lake in our results,
we need to exclude all the records for which we don't know who did the work.</p>

<div class="challenges">
<h3>Challenges</h3>
<ol>
  <li>
    <p>Write a query that sorts the records in <code>Visited</code> by date,
omitting entries for which the date is not known
(i.e., is null).</p>
  </li>
  <li>
    <p>What do you expect the query:</p>

<pre>select * from Visited where dated in ('1927-02-08', null);</pre>

    <p>to produce?
What does it actually produce?</p>
  </li>
  <li>
    <p>Some database designers prefer to use
a <a href="#gloss:sentinel-value">sentinel value</a>
to mark missing data rather than <code>null</code>.
For example,
they will use the date "0000-00-00" to mark a missing date,
or -1.0 to mark a missing salinity or radiation reading
(since actual readings cannot be negative).
What does this simplify?
What burdens or risks does it introduce?</p>
  </li>
</ol>
</div>

          <h2>Aggregation</h2>

<p>We now want to calculate ranges and averages for our data.
We know how to select all of the dates from the <code>Visited</code> table:</p>

<pre>select dated from Visited;</pre>
<table>
<tr><td>1927-02-08</td></tr>
<tr><td>1927-02-10</td></tr>
<tr><td>1939-01-07</td></tr>
<tr><td>1930-01-12</td></tr>
<tr><td>1930-02-26</td></tr>
<tr><td></td></tr>
<tr><td>1932-01-14</td></tr>
<tr><td>1932-03-22</td></tr>
</table>

<p>but to combine them,
wee must use an <a href="#gloss:aggregation-function">aggregation function</a>
such as <code>min</code> or <code>max</code>.
Each of these functions takes a set of records as input,
and produces a single record as output:</p>

<pre>select min(dated) from Visited;</pre>
<table>
<tr><td>1927-02-08</td></tr>
</table>

<p><img src="sql/novice/img/sql-aggregation.svg" alt="SQL Aggregation" /></p>

<pre>select max(dated) from Visited;</pre>
<table>
<tr><td>1939-01-07</td></tr>
</table>

<p><code>min</code> and <code>max</code> are just two of
the aggregation functions built into SQL.
Three others are <code>avg</code>,
<code>count</code>,
and <code>sum</code>:</p>

<pre>select avg(reading) from Survey where quant='sal';</pre>
<table>
<tr><td>7.20333333333333</td></tr>
</table>

<pre>select count(reading) from Survey where quant='sal';</pre>
<table>
<tr><td>9</td></tr>
</table>

<pre>select sum(reading) from Survey where quant='sal';</pre>
<table>
<tr><td>64.83</td></tr>
</table>

<p>We used <code>count(reading)</code> here,
but we could just as easily have counted <code>quant</code>
or any other field in the table,
or even used <code>count(*)</code>,
since the function doesn't care about the values themselves,
just how many values there are.</p>

<p>SQL lets us do several aggregations at once.
We can,
for example,
find the range of sensible salinity measurements:</p>

<pre>select min(reading), max(reading) from Survey where quant='sal' and reading&lt;=1.0;</pre>
<table>
<tr><td>0.05</td><td>0.21</td></tr>
</table>

<p>We can also combine aggregated results with raw results,
although the output might surprise you:</p>

<pre>select person, count(*) from Survey where quant='sal' and reading&lt;=1.0;</pre>
<table>
<tr><td>lake</td><td>7</td></tr>
</table>

<p>Why does Lake's name appear rather than Roerich's or Dyer's?
The answer is that when it has to aggregate a field,
but isn't told how to,
the database manager chooses an actual value from the input set.
It might use the first one processed,
the last one,
or something else entirely.</p>

<p>Another important fact is that when there are no values to aggregate,
aggregation's result is "don't know" (i.e., NULL)
rather than zero or some other arbitrary value:</p>

<pre>select person, max(reading), sum(reading) from Survey where quant='missing';</pre>
<table>
<tr><td></td><td></td><td></td></tr>
</table>

<p>One final important feature of aggregation functions is that
they are inconsistent with the rest of SQL in a very useful way.
If we add two values,
and one of them is null,
the result is null.
By extension,
if we use <code>sum</code> to add all the values in a set,
and any of those values are null,
the result should also be null.
It's much more useful,
though,
for aggregation functions to ignore null values
and only combine those that are non-null.
This behavior lets us write our queries as:</p>

<pre>select min(dated) from Visited;</pre>
<table>
<tr><td>1927-02-08</td></tr>
</table>

<p>instead of always having to filter explicitly:</p>

<pre>select min(dated) from Visited where dated is not null;</pre>
<table>
<tr><td>1927-02-08</td></tr>
</table>

<p>Aggregating all records at once doesn't always make sense.
For example,
suppose Gina suspects that there is a systematic bias in her data,
and that some scientists' radiation readings are higher than others.
We know that this doesn't work:</p>

<pre>select person, count(reading), round(avg(reading), 2)
from  Survey
where quant='rad';</pre>
<table>
<tr><td>roe</td><td>8</td><td>6.56</td></tr>
</table>

<p>because the database manager selects a single arbitrary scientist's name
rather than aggregating separately for each scientist.
Since there are only five scientists,
she could write five queries of the form:</p>

<pre>select person, count(reading), round(avg(reading), 2)
from  Survey
where quant='rad'
and   person='dyer';</pre>
<table>
<tr><td>dyer</td><td>2</td><td>8.81</td></tr>
</table>

<p>but this would be tedious,
and if she ever had a data set with fifty or five hundred scientists,
the chances of her getting all of those queries right is small.</p>

<p>What we need to do is
tell the database manager to aggregate the hours for each scientist separately
using a <code>group by</code> clause:</p>

<pre>select   person, count(reading), round(avg(reading), 2)
from     Survey
where    quant='rad'
group by person;</pre>
<table>
<tr><td>dyer</td><td>2</td><td>8.81</td></tr>
<tr><td>lake</td><td>2</td><td>1.82</td></tr>
<tr><td>pb</td><td>3</td><td>6.66</td></tr>
<tr><td>roe</td><td>1</td><td>11.25</td></tr>
</table>

<p><code>group by</code> does exactly what its name implies:
groups all the records with the same value for the specified field together
so that aggregation can process each batch separately.
Since all the records in each batch have the same value for <code>person</code>,
it no longer matters that the database manager
is picking an arbitrary one to display
alongside the aggregated <code>reading</code> values.</p>

<p>Just as we can sort by multiple criteria at once,
we can also group by multiple criteria.
To get the average reading by scientist and quantity measured,
for example,
we just add another field to the <code>group by</code> clause:</p>

<pre>select   person, quant, count(reading), round(avg(reading), 2)
from     Survey
group by person, quant;</pre>
<table>
<tr><td></td><td>sal</td><td>1</td><td>0.06</td></tr>
<tr><td></td><td>temp</td><td>1</td><td>-26.0</td></tr>
<tr><td>dyer</td><td>rad</td><td>2</td><td>8.81</td></tr>
<tr><td>dyer</td><td>sal</td><td>2</td><td>0.11</td></tr>
<tr><td>lake</td><td>rad</td><td>2</td><td>1.82</td></tr>
<tr><td>lake</td><td>sal</td><td>4</td><td>0.11</td></tr>
<tr><td>lake</td><td>temp</td><td>1</td><td>-16.0</td></tr>
<tr><td>pb</td><td>rad</td><td>3</td><td>6.66</td></tr>
<tr><td>pb</td><td>temp</td><td>2</td><td>-20.0</td></tr>
<tr><td>roe</td><td>rad</td><td>1</td><td>11.25</td></tr>
<tr><td>roe</td><td>sal</td><td>2</td><td>32.05</td></tr>
</table>

<p>Note that we have added <code>person</code> to the list of fields displayed,
since the results wouldn't make much sense otherwise.</p>

<p>Let's go one step further and remove all the entries
where we don't know who took the measurement:</p>

<pre>select   person, quant, count(reading), round(avg(reading), 2)
from     Survey
where    person is not null
group by person, quant
order by person, quant;</pre>
<table>
<tr><td>dyer</td><td>rad</td><td>2</td><td>8.81</td></tr>
<tr><td>dyer</td><td>sal</td><td>2</td><td>0.11</td></tr>
<tr><td>lake</td><td>rad</td><td>2</td><td>1.82</td></tr>
<tr><td>lake</td><td>sal</td><td>4</td><td>0.11</td></tr>
<tr><td>lake</td><td>temp</td><td>1</td><td>-16.0</td></tr>
<tr><td>pb</td><td>rad</td><td>3</td><td>6.66</td></tr>
<tr><td>pb</td><td>temp</td><td>2</td><td>-20.0</td></tr>
<tr><td>roe</td><td>rad</td><td>1</td><td>11.25</td></tr>
<tr><td>roe</td><td>sal</td><td>2</td><td>32.05</td></tr>
</table>

<p>Looking more closely,
this query:</p>

<ol>
  <li>
    <p>selected records from the <code>Survey</code> table
where the <code>person</code> field was not null;</p>
  </li>
  <li>
    <p>grouped those records into subsets
so that the <code>person</code> and <code>quant</code> values in each subset
were the same;</p>
  </li>
  <li>
    <p>ordered those subsets first by <code>person</code>,
and then within each sub-group by <code>quant</code>;
and</p>
  </li>
  <li>
    <p>counted the number of records in each subset,
calculated the average <code>reading</code> in each,
and chose a <code>person</code> and <code>quant</code> value from each
(it doesn't matter which ones,
since they're all equal).</p>
  </li>
</ol>

<div class="challenges">
<h3>Challenges</h3>
<ol>
  <li>
    <p>How many temperature readings did Frank Pabodie record,
and what was their average value?</p>
  </li>
  <li>
    <p>The average of a set of values is the sum of the values
divided by the number of values.
Does this mean that the <code>avg</code> function returns 2.0 or 3.0
when given the values 1.0, <code>null</code>, and 5.0?</p>
  </li>
  <li>
    <p>We want to calculate the difference between
each individual radiation reading
and the average of all the radiation readings.
We write the query:</p>

<pre>select reading-avg(reading) from Survey where quant='rad';</pre>

    <p>What does this actually produce, and why?</p>
  </li>
  <li>
    <p>The function <code>group_concat(field, separator)</code>
concatenates all the values in a field
using the specified separator character
(or ',' if the separator isn't specified).
Use this to produce a one-line list of scientists' names,
such as:</p>

<pre>William Dyer, Frank Pabodie, Anderson Lake, Valentina Roerich, Frank
Danforth</pre>

    <p>Can you find a way to order the list by surname?</p>
  </li>
</ol>
</div>

          <h2>Combining Data</h2>

<p>In order to submit her data to a web site
that aggregates historical meteorological data,
Gina needs to format it as
latitude, longitude, date, quantity, and reading.
However,
her latitudes and longitudes are in the <code>Site</code> table,
while the dates of measurements are in the <code>Visited</code> table
and the readings themselves are in the <code>Survey</code> table.
She needs to combine these tables somehow.</p>

<p>The SQL command to do this is <code>join</code>.
To see how it works,
let's start by joining the <code>Site</code> and <code>Visited</code> tables:</p>

<pre>select * from Site join Visited;</pre>
<table>
<tr><td>DR-1</td><td>-49.85</td><td>-128.57</td><td>619</td><td>DR-1</td><td>1927-02-08</td></tr>
<tr><td>DR-1</td><td>-49.85</td><td>-128.57</td><td>622</td><td>DR-1</td><td>1927-02-10</td></tr>
<tr><td>DR-1</td><td>-49.85</td><td>-128.57</td><td>734</td><td>DR-3</td><td>1939-01-07</td></tr>
<tr><td>DR-1</td><td>-49.85</td><td>-128.57</td><td>735</td><td>DR-3</td><td>1930-01-12</td></tr>
<tr><td>DR-1</td><td>-49.85</td><td>-128.57</td><td>751</td><td>DR-3</td><td>1930-02-26</td></tr>
<tr><td>DR-1</td><td>-49.85</td><td>-128.57</td><td>752</td><td>DR-3</td><td></td></tr>
<tr><td>DR-1</td><td>-49.85</td><td>-128.57</td><td>837</td><td>MSK-4</td><td>1932-01-14</td></tr>
<tr><td>DR-1</td><td>-49.85</td><td>-128.57</td><td>844</td><td>DR-1</td><td>1932-03-22</td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>619</td><td>DR-1</td><td>1927-02-08</td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>622</td><td>DR-1</td><td>1927-02-10</td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>734</td><td>DR-3</td><td>1939-01-07</td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>735</td><td>DR-3</td><td>1930-01-12</td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>751</td><td>DR-3</td><td>1930-02-26</td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>752</td><td>DR-3</td><td></td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>837</td><td>MSK-4</td><td>1932-01-14</td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>844</td><td>DR-1</td><td>1932-03-22</td></tr>
<tr><td>MSK-4</td><td>-48.87</td><td>-123.4</td><td>619</td><td>DR-1</td><td>1927-02-08</td></tr>
<tr><td>MSK-4</td><td>-48.87</td><td>-123.4</td><td>622</td><td>DR-1</td><td>1927-02-10</td></tr>
<tr><td>MSK-4</td><td>-48.87</td><td>-123.4</td><td>734</td><td>DR-3</td><td>1939-01-07</td></tr>
<tr><td>MSK-4</td><td>-48.87</td><td>-123.4</td><td>735</td><td>DR-3</td><td>1930-01-12</td></tr>
<tr><td>MSK-4</td><td>-48.87</td><td>-123.4</td><td>751</td><td>DR-3</td><td>1930-02-26</td></tr>
<tr><td>MSK-4</td><td>-48.87</td><td>-123.4</td><td>752</td><td>DR-3</td><td></td></tr>
<tr><td>MSK-4</td><td>-48.87</td><td>-123.4</td><td>837</td><td>MSK-4</td><td>1932-01-14</td></tr>
<tr><td>MSK-4</td><td>-48.87</td><td>-123.4</td><td>844</td><td>DR-1</td><td>1932-03-22</td></tr>
</table>

<p><code>join</code> creates
the <a href="#gloss:cross-product">cross product</a>
of two tables,
i.e.,
it joins each record of one with each record of the other
to give all possible combinations.
Since there are three records in <code>Site</code>
and eight in <code>Visited</code>,
the join's output has 24 records.
And since each table has three fields,
the output has six fields.</p>

<p>What the join <em>hasn't</em> done is
figure out if the records being joined have anything to do with each other.
It has no way of knowing whether they do or not until we tell it how.
To do that,
we add a clause specifying that
we're only interested in combinations that have the same site name:</p>

<pre>select * from Site join Visited on Site.name=Visited.site;</pre>
<table>
<tr><td>DR-1</td><td>-49.85</td><td>-128.57</td><td>619</td><td>DR-1</td><td>1927-02-08</td></tr>
<tr><td>DR-1</td><td>-49.85</td><td>-128.57</td><td>622</td><td>DR-1</td><td>1927-02-10</td></tr>
<tr><td>DR-1</td><td>-49.85</td><td>-128.57</td><td>844</td><td>DR-1</td><td>1932-03-22</td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>734</td><td>DR-3</td><td>1939-01-07</td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>735</td><td>DR-3</td><td>1930-01-12</td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>751</td><td>DR-3</td><td>1930-02-26</td></tr>
<tr><td>DR-3</td><td>-47.15</td><td>-126.72</td><td>752</td><td>DR-3</td><td></td></tr>
<tr><td>MSK-4</td><td>-48.87</td><td>-123.4</td><td>837</td><td>MSK-4</td><td>1932-01-14</td></tr>
</table>

<p><code>on</code> does the same job as <code>where</code>:
it only keeps records that pass some test.
(The difference between the two is that <code>on</code> filters records
as they're being created,
while <code>where</code> waits until the join is done
and then does the filtering.)
Once we add this to our query,
the database manager throws away records
that combined information about two different sites,
leaving us with just the ones we want.</p>

<p>Notice that we used <code>table.field</code> to specify field names
in the output of the join.
We do this because tables can have fields with the same name,
and we need to be specific which ones we're talking about.
For example,
if we joined the <code>person</code> and <code>visited</code> tables,
the result would inherit a field called <code>ident</code>
from each of the original tables.</p>

<p>We can now use the same dotted notation
to select the three columns we actually want
out of our join:</p>

<pre>select Site.lat, Site.long, Visited.dated
from   Site join Visited
on     Site.name=Visited.site;</pre>
<table>
<tr><td>-49.85</td><td>-128.57</td><td>1927-02-08</td></tr>
<tr><td>-49.85</td><td>-128.57</td><td>1927-02-10</td></tr>
<tr><td>-49.85</td><td>-128.57</td><td>1932-03-22</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td></td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1930-01-12</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1930-02-26</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1939-01-07</td></tr>
<tr><td>-48.87</td><td>-123.4</td><td>1932-01-14</td></tr>
</table>

<p>If joining two tables is good,
joining many tables must be better.
In fact,
we can join any number of tables
simply by adding more <code>join</code> clauses to our query,
and more <code>on</code> tests to filter out combinations of records
that don't make sense:</p>

<pre>select Site.lat, Site.long, Visited.dated, Survey.quant, Survey.reading
from   Site join Visited join Survey
on     Site.name=Visited.site
and    Visited.ident=Survey.taken
and    Visited.dated is not null;</pre>
<table>
<tr><td>-49.85</td><td>-128.57</td><td>1927-02-08</td><td>rad</td><td>9.82</td></tr>
<tr><td>-49.85</td><td>-128.57</td><td>1927-02-08</td><td>sal</td><td>0.13</td></tr>
<tr><td>-49.85</td><td>-128.57</td><td>1927-02-10</td><td>rad</td><td>7.8</td></tr>
<tr><td>-49.85</td><td>-128.57</td><td>1927-02-10</td><td>sal</td><td>0.09</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1939-01-07</td><td>rad</td><td>8.41</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1939-01-07</td><td>sal</td><td>0.05</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1939-01-07</td><td>temp</td><td>-21.5</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1930-01-12</td><td>rad</td><td>7.22</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1930-01-12</td><td>sal</td><td>0.06</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1930-01-12</td><td>temp</td><td>-26.0</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1930-02-26</td><td>rad</td><td>4.35</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1930-02-26</td><td>sal</td><td>0.1</td></tr>
<tr><td>-47.15</td><td>-126.72</td><td>1930-02-26</td><td>temp</td><td>-18.5</td></tr>
<tr><td>-48.87</td><td>-123.4</td><td>1932-01-14</td><td>rad</td><td>1.46</td></tr>
<tr><td>-48.87</td><td>-123.4</td><td>1932-01-14</td><td>sal</td><td>0.21</td></tr>
<tr><td>-48.87</td><td>-123.4</td><td>1932-01-14</td><td>sal</td><td>22.5</td></tr>
<tr><td>-49.85</td><td>-128.57</td><td>1932-03-22</td><td>rad</td><td>11.25</td></tr>
</table>

<p>We can tell which records from <code>Site</code>, <code>Visited</code>, and <code>Survey</code>
correspond with each other
because those tables contain
<a href="#gloss:primary-key">primary keys</a>
and <a href="#gloss:foreign-key">foreign keys</a>.
A primary key is a value,
or combination of values,
that uniquely identifies each record in a table.
A foreign key is a value (or combination of values) from one table
that identifies a unique record in another table.
Another way of saying this is that
a foreign key is the primary key of one table
that appears in some other table.
In our database,
<code>Person.ident</code> is the primary key in the <code>Person</code> table,
while <code>Survey.person</code> is a foreign key
relating the <code>Survey</code> table's entries
to entries in <code>Person</code>.</p>

<p>Most database designers believe that
every table should have a well-defined primary key.
They also believe that this key should be separate from the data itself,
so that if we ever need to change the data,
we only need to make one change in one place.
One easy way to do this is
to create an arbitrary, unique ID for each record
as we add it to the database.
This is actually very common:
those IDs have names like "student numbers" and "patient numbers",
and they almost always turn out to have originally been
a unique record identifier in some database system or other.
As the query below demonstrates,
SQLite automatically numbers records as they're added to tables,
and we can use those record numbers in queries:</p>

<pre>select rowid, * from Person;</pre>
<table>
<tr><td>1</td><td>dyer</td><td>William</td><td>Dyer</td></tr>
<tr><td>2</td><td>pb</td><td>Frank</td><td>Pabodie</td></tr>
<tr><td>3</td><td>lake</td><td>Anderson</td><td>Lake</td></tr>
<tr><td>4</td><td>roe</td><td>Valentina</td><td>Roerich</td></tr>
<tr><td>5</td><td>danforth</td><td>Frank</td><td>Danforth</td></tr>
</table>

<h3>Data Hygiene</h3>

<p>Now that we have seen how joins work,
we can see why the relational model is so useful
and how best to use it.
The first rule is that every value should be <a href="#gloss:atomic-value">atomic</a>,
i.e.,
not contain parts that we might want to work with separately.
We store personal and family names in separate columns instead of putting the
entire name in one column
so that we don't have to use substring operations to get the name's components.
More importantly,
we store the two parts of the name separately because splitting on spaces is
unreliable:
just think of a name like "Eloise St. Cyr" or "Jan Mikkel Steubart".</p>

<p>The second rule is that every record should have a unique primary key.
This can be a serial number that has no intrinsic meaning,
one of the values in the record (like the <code>ident</code> field in the <code>Person</code> table),
or even a combination of values:
the triple <code>(taken, person, quant)</code> from the <code>Survey</code> table uniquely identifies
every measurement.</p>

<p>The third rule is that there should be no redundant information.
For example,
we could get rid of the <code>Site</code> table and rewrite the <code>Visited</code> table like this:</p>

<table>
  <tr> <td>619</td> <td>-49.85</td> <td>-128.57</td> <td>1927-02-08</td> </tr>
  <tr> <td>622</td> <td>-49.85</td> <td>-128.57</td> <td>1927-02-10</td> </tr>
  <tr> <td>734</td> <td>-47.15</td> <td>-126.72</td> <td>1939-01-07</td> </tr>
  <tr> <td>735</td> <td>-47.15</td> <td>-126.72</td> <td>1930-01-12</td> </tr>
  <tr> <td>751</td> <td>-47.15</td> <td>-126.72</td> <td>1930-02-26</td> </tr>
  <tr> <td>752</td> <td>-47.15</td> <td>-126.72</td> <td>null</td> </tr>
  <tr> <td>837</td> <td>-48.87</td> <td>-123.40</td> <td>1932-01-14</td> </tr>
  <tr> <td>844</td> <td>-49.85</td> <td>-128.57</td> <td>1932-03-22</td> </tr>
</table>

<p>In fact,
we could use a single table that recorded all the information about each reading
in each row,
just as a spreadsheet would.
The problem is that it's very hard to keep data organized this way consistent:
if we realize that the date of a particular visit to a particular site is wrong,
we have to change multiple records in the database.
What's worse,
we may have to guess which records to change,
since some other sites may actually have been visited on that date.</p>

<p>The fourth rule is that the units for every value should be stored explicitly.
Our database doesn't do this,
and that's a problem:
Roerich's salinity measurements are several orders of magnitude larger than
anyone else's,
but we don't know if that means she was using parts per million instead of parts
per thousand,
or whether there actually was a saline anomaly at that site in 1932.</p>

<div class="challenges">
<h3>Challenges</h3>
<ol>
  <li>
    <p>Write a query that lists all radiation readings from the DR-1 site.</p>
  </li>
  <li>
    <p>Write a query that lists all sites visited by people named "Frank".</p>
  </li>
  <li>
    <p>Describe in your own words what the following query produces:</p>

<pre>select Site.name from Site join Visited
on Site.lat&lt;-49.0 and Site.name=Visited.site and
Visited.dated&gt;='1932-00-00';</pre>
  </li>
</ol>
</div>

          <h2>Creating and Modifying Data</h2>

<p>So far we have only looked at how to get information out of a database,
both because that is more frequent than adding information,
and because most other operations only make sense
once queries are understood.
If we want to create and modify data,
we need to know two other pairs of commands.</p>

<p>The first pair are <code>create table</code> and <code>drop table</code>.
While they are written as two words,
they are actually single commands.
The first one creates a new table;
its arguments are the names and types of the table's columns.
For example,
the following statements create the four tables in our survey database:</p>

<pre>create table Person(ident text, personal text, family text);
create table Site(name text, lat real, long real);
create table Visited(ident integer, site text, dated text);
create table Survey(taken integer, person text, quant real, reading real);</pre>

<p>We can get rid of one of our tables using:</p>

<pre>drop table Survey;</pre>

<p>Be very careful when doing this:
most databases have some support for undoing changes,
but it's better not to have to rely on it.</p>

<p>Different database systems support different data types for table columns,
but most provide the following:</p>

<table>
  <tr> <td>integer</td> <td>a signed integer</td> </tr>
  <tr> <td>real</td> <td>a floating point number</td> </tr>
  <tr> <td>text</td> <td>a character string</td> </tr>
  <tr> <td>blob</td> <td>a "binary large object", such as an image</td> </tr>
</table>

<p>Most databases also support Booleans and date/time values;
SQLite uses the integers 0 and 1 for the former,
and represents the latter as discussed <a href="#a:dates">earlier</a>.
An increasing number of databases also support geographic data types,
such as latitude and longitude.
Keeping track of what particular systems do or do not offer,
and what names they give different data types,
is an unending portability headache.</p>

<p>When we create a table,
we can specify several kinds of constraints on its columns.
For example,
a better definition for the <code>Survey</code> table would be:</p>

<pre>create table Survey(
    taken   integer not null, -- where reading taken
    person  text,             -- may not know who took it
    quant   real not null,    -- the quantity measured
    reading real not null,    -- the actual reading
    primary key(taken, quant),
    foreign key(taken) references Visited(ident),
    foreign key(person) references Person(ident)
);</pre>

<p>Once again,
exactly what constraints are avialable
and what they're called
depends on which database manager we are using.</p>

<p>Once tables have been created,
we can add and remove records using our other pair of commands,
<code>insert</code> and <code>delete</code>.
The simplest form of <code>insert</code> statement lists values in order:</p>

<pre>insert into Site values('DR-1', -49.85, -128.57);
insert into Site values('DR-3', -47.15, -126.72);
insert into Site values('MSK-4', -48.87, -123.40);</pre>

<p>We can also insert values into one table directly from another:</p>

<pre>create table JustLatLong(lat text, long TEXT);
insert into JustLatLong select lat, long from site;</pre>

<p>Deleting records can be a bit trickier,
because we have to ensure that the database remains internally consistent.
If all we care about is a single table,
we can use the <code>delete</code> command with a <code>where</code> clause
that matches the records we want to discard.
For example,
once we realize that Frank Danforth didn't take any measurements,
we can remove him from the <code>Person</code> table like this:</p>

<pre>delete from Person where ident = "danforth";</pre>

<p>But what if we removed Anderson Lake instead?
Our <code>Survey</code> table would still contain seven records
of measurements he'd taken,
but that's never supposed to happen:
<code>Survey.person</code> is a foreign key into the <code>Person</code> table,
and all our queries assume there will be a row in the latter
matching every value in the former.</p>

<p>This problem is called <a href="#gloss:referential-integrity">referential integrity</a>:
we need to ensure that all references between tables can always be resolved
correctly.
One way to do this is to delete all the records
that use <code>'lake'</code> as a foreign key
before deleting the record that uses it as a primary key.
If our database manager supports it,
we can automate this
using <a href="#gloss:cascading-delete">cascading delete</a>.
However,
this technique is outside the scope of this chapter.</p>

<blockquote>
  <p>Many applications use a hybrid storage model
instead of putting everything into a database:
the actual data (such as astronomical images) is stored in files,
while the database stores the files' names,
their modification dates,
the region of the sky they cover,
their spectral characteristics,
and so on.
This is also how most music player software is built:
the database inside the application keeps track of the MP3 files,
but the files themselves live on disk.</p>
</blockquote>

<div class="challenges">
<h3>Challenges</h3>
<ol>
  <li>
    <p>Write an SQL statement to replace all uses of <code>null</code>
in <code>Survey.person</code>
with the string <code>'unknown'</code>.</p>
  </li>
  <li>
    <p>One of our colleagues has sent us a <a href="#gloss:csv">CSV</a> file
containing temperature readings by Robert Olmstead,
which is formatted like this:</p>

<pre>Taken,Temp
619,-21.5
622,-15.5</pre>

    <p>Write a small Python program that reads this file in
and prints out the SQL <code>insert</code> statements needed
to add these records to the survey database.
Note: you will need to add an entry for Olmstead
to the <code>Person</code> table.
If you are testing your program repeatedly,
you may want to investigate SQL's <code>insert or replace</code> command.</p>
  </li>
  <li>
    <p>SQLite has several administrative commands that aren't part of the SQL
standard.
One of them is <code>.dump</code>,
which prints the SQL commands needed to re-create the database.
Another is <code>.load</code>,
which reads a file created by <code>.dump</code> and restores the database.
A colleague of yours thinks that storing dump files (which are text) in
version control
is a good way to track and manage changes to the database.
What are the pros and cons of this approach?</p>
  </li>
</ol>
</div>

          <h2>Programming with Databases</h2>

<p>To close,
let's have a look at how to access a database from
a general-purpose programming language like Python.
Other languages use almost exactly the same model:
library and function names may differ,
but the concepts are the same.</p>

<p>Here's a short Python program that selects latitudes and longitudes
from an SQLite database stored in a file called <code>survey.db</code>:</p>

<pre>import sqlite3
connection = sqlite3.connect("survey.db")
cursor = connection.cursor()
cursor.execute("select site.lat, site.long from site;")
results = cursor.fetchall()
for r in results:
    print r
cursor.close()
connection.close()</pre>

<pre>(-49.85, -128.57)
(-47.15, -126.72)
(-48.87, -123.4)</pre>

<p>The program starts by importing the <code>sqlite3</code> library.
If we were connecting to MySQL, DB2, or some other database,
we would import a different library,
but all of them provide the same functions,
so that the rest of our program does not have to change
(at least, not much)
if we switch from one database to another.</p>

<p>Line 2 establishes a connection to the database.
Since we're using SQLite,
all we need to specify is the name of the database file.
Other systems may require us to provide a username and password as well.
Line 3 then uses this connection to create
a <a href="#gloss:cursor">cursor</a>;
just like the cursor in an editor,
its role is to keep track of where we are in the database.</p>

<p>On line 4, we use that cursor to ask the database to execute a query for us.
The query is written in SQL,
and passed to <code>cursor.execute</code> as a string.
It's our job to make sure that SQL is properly formatted;
if it isn't,
or if something goes wrong when it is being executed,
the database will report an error.</p>

<p>The database returns the results of the query to us
in response to the <code>cursor.fetchall</code> call on line 5.
This result is a list with one entry for each record in the result set;
if we loop over that list (line 6) and print those list entries (line 7),
we can see that each one is a tuple
with one element for each field we asked for.</p>

<p>Finally, lines 8 and 9 close our cursor and our connection,
since the database can only keep a limited number of these open at one time.
Since establishing a connection takes time,
though,
we shouldn't open a connection,
do one operation,
then close the connection,
only to reopen it a few microseconds later to do another operation.
Instead,
it's normal to create one connection that stays open for the lifetime of the
program.</p>

<p>Queries in real applications will often depend on values provided by users.
For example,
this function takes a user's ID as a parameter and returns their name:</p>

<pre>def get_name(database_file, person_ident):
    query = "select personal || ' ' || family from Person where ident='" + person_ident + "';"

    connection = sqlite3.connect(database_file)
    cursor = connection.cursor()
    cursor.execute(query)
    results = cursor.fetchall()
    cursor.close()
    connection.close()

    return results[0][0]

print "full name for dyer:", get_name('survey.db', 'dyer')</pre>

<pre>full name for dyer: William Dyer</pre>

<p>We use string concatenation on the first line of this function
to construct a query containing the user ID we have been given.
This seems simple enough,
but what happens if someone gives us this string as input?</p>

<pre>dyer'; drop table Survey; select '</pre>

<p>It looks like there's garbage after the name of the project,
but it is very carefully chosen garbage.
If we insert this string into our query,
the result is:</p>

<pre>select personal || ' ' || family from Person where ident='dyer'; drop tale Survey; select '';</pre>

<p>If we execute this,
it will erase one of the tables in our database.</p>

<p>This is called an <a href="#gloss:sql-injection-attack">SQL injection attack</a>,
and it has been used to attack thousands of programs over the years.
In particular,
many web sites that take data from users insert values directly into queries
without checking them carefully first.</p>

<p>Since a villain might try to smuggle commands into our queries in many different
ways,
the safest way to deal with this threat is
to replace characters like quotes with their escaped equivalents,
so that we can safely put whatever the user gives us inside a string.
We can do this by using a <a href="#gloss:prepared-statement">prepared statement</a>
instead of formatting our statements as strings.
Here's what our example program looks like if we do this:</p>

<pre>def get_name(database_file, person_ident):
    query = "select personal || ' ' || family from Person where ident=?;"

    connection = sqlite3.connect(database_file)
    cursor = connection.cursor()
    cursor.execute(query, [person_ident])
    results = cursor.fetchall()
    cursor.close()
    connection.close()

    return results[0][0]

print "full name for dyer:", get_name('survey.db', 'dyer')</pre>

<pre>full name for dyer: William Dyer</pre>

<p>The key changes are in the query string and the <code>execute</code> call.
Instead of formatting the query ourselves,
we put question marks in the query template where we want to insert values.
When we call <code>execute</code>,
we provide a list
that contains as many values as there are question marks in the query.
The library matches values to question marks in order,
and translates any special characters in the values
into their escaped equivalents
so that they are safe to use.</p>

<div class="challenges">
<ol>
  <li>
    <p>Write a Python program that creates a new database
in a file called <code>original.db</code>
containing a single table called <code>Pressure</code>,
with a single field called <code>reading</code>,
and inserts 100,000 random numbers between 10.0 and 25.0.
How long does it take this program to run?
How long does it take to run a program
that simply writes those random numbers to a file?</p>
  </li>
  <li>
    <p>Write a Python program that creates a new database
called <code>backup.db</code>
with the same structure as <code>original.db</code>
and copies all the values greater than 20.0
from <code>original.db</code> to <code>backup.db</code>.
Which is faster:
filtering values in the query,
or reading everything into memory and filtering in Python?</p>
  </li>
</ol>
</div>

          <h1>Recommended Reading</h1>
          <h2>Papers</h2>

<ul>
  <li>
    <p>Paul F. Dubois:
"Maintaining Correctness in Scientific Programs".
<em>Computing in Science &amp; Engineering</em>,
May-June 2005.
<br />
This paper shows how several good programming practices fit together
to create defense in depth,
so that errors missed by one will be caught by another.</p>
  </li>
  <li>
    <p>Joel T. Dudley and Atul J. Butte:
"A Quick Guide for Developing Effective Bioinformatics Programming Skills".
<em>PLOS Computational Biology</em>,
5(12),
December 2009.
<br />
Summarizes the skills that bioinformaticians (and others) need
to build usable code with reasonable effort.</p>
  </li>
  <li>
    <p>Jo Erskine Hannay, Hans Petter Langtangen, Carolyn MacLeod, Dietmar Pfahl, Janice Singer, and Greg Wilson:
"How Do Scientists Develop and Use Scientific Software?"
<em>Proc. 2009 ICSE Workshop on Software Engineering for Computational Science and Engineering</em>,
2009.
<br />
The largest study survey done of how scientists use computers in their research
and how much time they spend doing so.</p>
  </li>
  <li>
    <p>William Stafford Noble:
"A Quick Guide to Organizing Computational Biology Projects".
<em>PLoS Computational Biology</em>,
5(7),
2009.
<br />
How and why one scientist organizes his data and scripts.</p>
  </li>
  <li>
    <p>Ethan P. White, Elita Baldridge, Zachary T. Brym, Kenneth J. Locey, Daniel J. McGlinn, and Sarah R. Supp:
"Nine Simple Ways to Make It Easier to (Re)use Your Data."
<em>PeerJ PrePrints</em>,
1:e7v2,
2012.
<br />
Delivers exactly what the title promises:
a straightforward set of practices that will make it easier for other scientists to use your data.</p>
  </li>
  <li>
    <p>Greg Wilson, D. A. Aruliah, C. Titus Brown, Neil P. Chue Hong, Matt Davis, Richard T. Guy, Steven H. D. Haddock, Katy Huff, Ian M. Mitchell, Mark Plumbley, Ben Waugh, Ethan P. White, and Paul Wilson:
"Best Practices for Scientific Computing".
arXiv pre-print,
submitted November 29, 2012.
<br />
Describes a set of best practices for scientific software development
that have solid foundations in research and experience,
and that improve scientists' productivity and the reliability of their software.</p>
  </li>
  <li>
    <p>Greg Wilson: "Software Carpentry: Lessons Learned".
arXiv pre-print,
submitted July 20, 2013.
<br />
Describes what we've learned about how to teach programming to scientists
over the last 15 years.</p>
  </li>
</ul>

<h2>Books</h2>

<ul>
  <li>
    <p>Chris Fehily:
<em>SQL: Visual QuickStart Guide</em> (3rd ed).
Peachpit Press,
0321553578,
2002.
<br />
Describes the 5% of SQL that covers 95% of real-world needs.</p>
  </li>
  <li>
    <p>Karl Fogel:
<em>Producing Open Source Software: How to Run a Successful Free Software Project</em>.
O'Reilly Media,
0596007590,
2005.
<br />
An excellent guide to how open source projects actually work.
Every page offers practical advice on how to earn commit privileges on a project,
get it more attention,
or fork it in case of irreconcilable differences.</p>
  </li>
  <li>
    <p>Steve Haddock and Casey Dunn:
<em>Practical Computing for Biologists</em>.
Sinauer,
0878933913,
2010.
<br />
The best general introduction to "the other 90%" of scientific computing on the market today.</p>
  </li>
  <li>
    <p>Andy Oram and Greg Wilson (eds):
<em>Making Software: What Really Works, and Why We Believe It</em>.
O'Reilly,
0596808321,
2010.
<br />
Leading software engineering researchers take a chapter each
to describe key empirical results and the evidence behind them.
Topics range from the impact of programming languages on programmers' productivity
to whether we can predict software faults using statistical techniques.</p>
  </li>
  <li>
    <p>Deborah S. Ray and Eric J. Ray:
<em>Unix and Linux: Visual QuickStart Guide</em>.
Peachpit Press,
0321636783,
2009.
<br />
A gentle introduction to Unix, with many examples.</p>
  </li>
</ul>


          <h1>Glossary</h1>
          <p><strong>absolute path</strong>: <a name="absolute-path"></a>
A <a href="#path">path</a> that refers to a particular location in a file system.
Absolute paths are usually written with respect to the file system's
<a href="#root-directory">root directory</a>,
and begin with either "/" (on Unix) or "" (on Microsoft Windows).
See also: <a href="#relative-path">relative path</a>.</p>

<p><strong>additive color model</strong>: <a name="additive-color-model"></a>
A way to represent colors as the sum of contributions from primary colors
such as <a href="#rgb">red, green, and blue</a>.</p>

<p><strong>aggregation function</strong>: <a name="aggregation-function"></a>
A function such as <code>sum</code> or <code>max</code> that combines many values to produce a single result.</p>

<p><strong>alias</strong> (a library): <a name="alias-library"></a>
To give a library a nickname while importing it.</p>

<p><strong>assertion</strong>: <a name="assertion"></a>
An expression which is supposed to be true at a particular point in a program.
Programmers typically put assertions in their code to check for errors;
if the assertion fails (i.e., if the expression evaluates as false),
the program halts and produces an error message.
See also: <a href="#invariant">invariant</a>, <a href="#precondition">precondition</a>, <a href="#postcondition">postcondition</a>.</p>

<p><strong>assignment</strong>: <a name="assignment"></a>
To give a value a name by associating a variable with it.</p>

<p><strong>atomic value</strong>: <a name="atomic-value"></a>
A value that cannot be decomposed into smaller pieces.
For example,
the number 12 is usually considered atomic
(unless we are teaching addition to school children,
in which case we might decompose it into tens and ones).</p>

<p><strong>call stack</strong>: <a name="call-stack"></a>
A data structure inside a running program that keeps track of active function calls.
Each call's variables are stored in a <a href="#stack-frame">stack frame</a>;
a new stack frame is put on top of the stack for each call,
and discarded when the call is finished.</p>

<p><strong>cascading delete</strong>: <a name="cascading-delete"></a>
The practice of automatically deleting things in a database
that depend on a record
when that record is deleted.
See also: <a href="#referential-integrity">referential integrity</a>.</p>

<p><strong>case insensitive</strong>: <a name="case-insensitive"></a>
Treating text as if upper and lower case characters were the same.
See also: <a href="#case-sensitive">case sensitive</a>.</p>

<p><strong>change set</strong>: <a name="change-set"></a>
A group of changes to one or more files
that are <a href="#commit">committed</a> to a <a href="#version-control">version control</a> <a href="#repository">repository</a>
in a single operation.</p>

<p><strong>clone</strong> (a repository): <a name="repository-clone"></a>
To make a copy of a <a href="#repository">version control repository</a>.</p>

<p><strong>comma-separated values</strong> (CSV): <a name="csv"></a>
A common textual representation for tables
in which the values in each row are separated by commas.</p>

<p><strong>command-line interface</strong> (CLI): <a name="cli"></a>
An interface based on typing commands,
usually at a <a href="#repl">REPL</a>.
See also: (graphical user interface)[#gui].</p>

<p><strong>comment</strong>: <a name="comment"></a>
A remark in a program that is intended to help human readers understand what is going on,
but is ignored by the computer.
Comments in Python, R, and the Unix shell start with a <code>#</code> character and run to the end of the line;
comments in SQL start with <code>--</code>,
and other languages have other conventions.</p>

<p><strong>conditional statement</strong>: <a name="conditional-statement"></a>
A statement in a program that might or might not be executed
depending on whether a test is true or false.</p>

<p><strong>conflict</strong>: <a name="conflict"></a>
A change made by one user of a (version control system)[#version-control]
that is incompatible with changes made by other users.
Helping users (resolve)[#resolve] conflicts
is one of version control's major tasks.</p>

<p><strong>cross product</strong>: <a name="cross-product"></a>
A pairing of all elements of one set with all elements of another.</p>

<p><strong>current working directory</strong>: <a name="current-working-directory"></a>
The directory that <a href="#relative-path">relative paths</a> are calculated from;
equivalently,
the place where files referenced by name only are searched for.
Every <a href="#process">process</a> has a current working directory.
The current working directory is usually referred to using the shorthand notation <code>.</code> (pronounced "dot").</p>

<p><strong>cursor</strong>: <a name="cursor"></a>
A pointer into a database that keeps track of outstanding operations.</p>

<p><strong>data type</strong>: <a name="data-type"></a>
A kind of data value,
such as <a href="#integer">integer</a> or <a href="#string">character string</a>.</p>

<p><strong>database manager</strong>: <a name="database-manager"></a>
A program that manages a <a href="#relational-database">relational database</a>.</p>

<p><strong>default parameter value</strong>: <a name="default-parameter-value"></a>
A value to use for a parameter if nothing is specified explicitly.</p>

<p><strong>defensive programming</strong>: <a name="defensive-programming"></a>
The practice of writing programs that check their own operation to catch errors as early as possible.</p>

<p><strong>delimiter</strong>: <a name="delimiter"></a>
A character or characters used to separate individual values,
such as the commas between columns in a <a href="#csv">CSV</a> file.</p>

<p><strong>disk block</strong>: <a name="disk-block"></a>
The smallest unit of storage that can be allocated on a computer disk.
Disk blocks are typically 512 bytes in size.</p>

<p><strong>docstring</strong>: <a name="docstring"></a>
Short for "documentation string",
this refers to textual documentation embedded in Python programs.
Unlike comments,
docstrings are preserved in the running program
and can be examined in interactive sessions.</p>

<p><strong>documentation</strong>: <a name="documentation"></a>
Human-language text written to explain what software does,
how it works,
or how to use it.</p>

<p><strong>dotted notation</strong>: <a name="dotted-notation"></a>
A two-part notation used in many programming languages
in which <code>thing.component</code> refers to the <code>component</code> belonging to <code>thing</code>.</p>

<p><strong>empty string</strong>: <a name="empty-string"></a>
A character string containing no characters,
often thought of as the "zero" of text.</p>

<p><strong>encapsulation</strong>: <a name="encapsulation"></a>
The practice of hiding something's implementation details
so that the rest of a program can worry about <em>what</em> it does
rather than <em>how</em> it does it.</p>

<p><strong>field</strong> (of a database): <a name="field-database"></a>
A set of data values of a particular type,
one for each <a href="#record-database">record</a> in a <a href="#table-database">table</a>.</p>

<p><strong>filename extension</strong>: <a name="filename-extension"></a>
The portion of a file's name that comes after the final "." character.
By convention this identifies the file's type:
<code>.txt</code> means "text file",
<code>.png</code> means "Portable Network Graphics file",
and so on.
These conventions are not enforced by most operating systems:
it is perfectly possible to name an MP3 sound file <code>homepage.html</code>.
Since many applications use filename extensions to identify the <a href="#mime-type">MIME type</a> of the file,
misnaming files may cause those applications to fail.</p>

<p><strong>filesystem</strong>: <a name="filesystem"></a>
A set of files, directories, and I/O devices (such as keyboards and screens).
A filesystem may be spread across many physical devices,
or many filesystems may be stored on a single physical device;
the <a href="#operating-system">operating system</a> manages access.</p>

<p><strong>filter</strong>: <a name="filter"></a>
A program that transforms a stream of data.
Many Unix command-line tools are written as filters:
they read data from <a href="#standard-input">standard input</a>,
process it,
and write the result to <a href="#standard-output">standard output</a>.</p>

<p><strong>flag</strong>: <a name="command-line-flag"></a>
A terse way to specify an option or setting to a command-line program.
By convention Unix applications use a dash followed by a single letter,
such as <code>-v</code>,
or two dashes followed by a word,
such as <code>--verbose</code>,
while DOS applications use a slash,
such as <code>/V</code>.
Depending on the application, a flag may be followed by a single argument, as in <code>-o /tmp/output.txt</code>.</p>

<p><strong>floating point number</strong> (float): <a name="float"></a>
A number containing a fractional part and an exponent.
See also: <a href="#integer">integer</a>.</p>

<p><strong>for loop</strong>: <a name="for-loop"></a>
A loop that is executed once for each value in some kind of set, list, or range.
See also: <a href="#while-loop">while loop</a>.</p>

<p><strong>foreign key</strong>: <a name="foreign-key"></a>
One or more values in a <a href="#table-database">database table</a>
that identify a <a href="#record-database">records</a> in another table.</p>

<p><strong>function composition</strong>: <a name="function-composition"></a>
The immediate application of one function to the result of another,
such as <code>f(g(x))</code>.</p>

<p><strong>graphical user interface</strong> (GUI): <a name="gui"></a>
A graphical user interface,
usually controlled by using a mouse.
See also: <a href="#cli">command-line interface</a>.</p>

<p><strong>home directory</strong>: <a name="home-directory"></a>
The default directory associated with an account on a computer system.
By convention, all of a user's files are stored in or below her home directory.</p>

<p><strong>immutable</strong>: <a name="immutable"></a>
Unchangeable.
The value of immutable data cannot be altered after it has been created.
See also: <a href="#mutable">mutable</a>.</p>

<p><strong>import</strong>: <a name="import"></a>
To load a library into a program.</p>

<p><strong>in-place operator</strong>: <a name="in-place-operator"></a>
An operator such as <code>+=</code> that provides a shorthand notation for
the common case in which the variable being assigned to
is also an operand on the right hand side of the assignment.
For example,
the statement <code>x += 3</code> means the same thing as <code>x = x + 3</code>.</p>

<p><strong>index</strong>: <a name="index"></a>
A subscript that specifies the location of a single value in a collection,
such as a single pixel in an image.</p>

<p><strong>infective license</strong>: <a name="infective-license"></a>
A license such as the <a href="http://opensource.org/licenses/GPL-3.0">GPL</a>
that compels people who incorporate material into their own work
to place similar sharing requirements on it.</p>

<p><strong>inner loop</strong>: <a name="inner-loop"></a>
A loop that is inside another loop.
See also: <a href="#outer-loop">outer loop</a>.</p>

<p><strong>integer</strong>: <a name="integer"></a>
A whole number, such as -12343.
See also: <a href="#float">floating-point number</a>.</p>

<p><strong>invariant</strong>: <a name="invariant"></a>
An expression whose value doesn't change during the execution of a program,
typically used in an <a href="#assertion">assertion</a>.
See also: <a href="#precondition">precondition</a>, <a href="#postcondition">postcondition</a>.</p>

<p><strong>loop body</strong>: <a name="loop-body"></a>
The statements that are executed inside a loop.</p>

<p><strong>loop variable</strong>: <a name="loop-variable"></a>
The variable that keeps track of the progress of the loop.</p>

<p><strong>member</strong>: <a name="member"></a>
A variable contained within an <a href="#object">object</a>.</p>

<p><strong>merge</strong> (a repository): <a name="repository-merge"></a>
To reconcile two sets of change to a [repository].</p>

<p><strong>method</strong>: <a name="method"></a>
A function which is tied to a particular <a href="#object">object</a>.
Each of an object's methods typically implements one of the things it can do,
or one of the questions it can answer.</p>

<p><strong>mutable</strong>: <a name="mutable"></a>
Changeable.
The value of mutable data can be updated in place.
See also: <a href="#immutable">immutable</a>.</p>

<p><strong>notional machine</strong>: <a name="notional-machine"></a>
An abstraction of a computer used to think about what it can and will do.</p>

<p><strong>object</strong>: <a name="object"></a>
A particular "chunk" of data associated with specific operations called <a href="#method">methods</a>.</p>

<p><strong>orthogonal</strong>: <a name="orthogonal"></a>
To have meanings or behaviors that are independent of each other.
If a set of concepts or tools are orthogonal,
they can be combined in any way.</p>

<p><strong>outer loop</strong>: <a name="outer-loop"></a>
A loop that contains another loop.
See also: <a href="#inner-loop">inner loop</a>.</p>

<p><strong>parameter</strong>: <a name="parameter"></a>
A value passed into a function,
or a variable named in the functin's declaration
that is used to hold such a value.</p>

<p><strong>parent directory</strong>: <a name="parent-directory"></a>
The directory that "contains" the one in question.
Every directory in a file system except the <a href="#root-directory">root directory</a> has a parent.
A directory's parent is usually referred to using the shorthand notation <code>..</code> (pronounced "dot dot").</p>

<p><strong>pipe</strong>: <a name="pipe"></a>
A connection from the output of one program to the input of another.
When two or more programs are connected in this way, they are called a "pipeline".</p>

<p><strong>pipe and filter</strong>: <a name="pipe-and-filter"></a>
A model of programming in which <a href="#filter">filters</a> that process <a href="#stream">streams</a> of data
are connected end-to-end.
The pipe and filter model is used extensively in the Unix <a href="#shell">shell</a>.</p>

<p><strong>postcondition</strong>: <a name="postcondition"></a>
A condition that a function (or other block of code) guarantees is true
once it has finished running.
Postconditions are often represented using <a href="#assertion">assertions</a>.</p>

<p><strong>precondition</strong>: <a name="precondition"></a>
A condition that must be true in order for a function (or other block of code) to run correctly.</p>

<p><strong>prepared statement</strong>: <a name="prepared-statement"></a>
A template for an <a href="#sql">SQL</a> query in which some values can be filled in.</p>

<p><strong>primary key</strong>: <a name="primary-key"></a>
One or more <a href="#field-database">fields</a> in a <a href="#table-database">database table</a>
whose values are guaranteed to be unique for each <a href="#record-database">record</a>,
i.e.,
whose values uniquely identify the entry.</p>

<p><strong>process</strong>: <a name="process"></a>
A running instance of a program,
containing code,
variable values,
open files and network connections,
and so on.
Processes are the "actors" that the <a href="#operating-system">operating system</a> manages;
it typically runs each process for a few milliseconds at a time
to give the impression that they are executing simultaneously.</p>

<p><strong>prompt</strong>: <a name="prompt"></a>
A character or characters display by a <a href="#repl">REPL</a> to show that
it is waiting for its next command.</p>

<p><strong>query</strong>: <a name="query"></a>
A database operation that reads values but does not modify anything.
Queries are expressed in a special-purpose language called <a href="#sql">SQL</a>.</p>

<p><strong>quoting</strong> (in the shell): <a name="shell-quoting"></a>
Using quotation marks of various kinds to prevent the shell from interpreting special characters.
For example,
to pass the string <code>*.txt</code> to a program,
it is usually necessary to write it as <code>'*.txt'</code> (with single quotes)
so that the shell will not try to expand the <code>*</code> wildcard.</p>

<p><strong>read-eval-print loop</strong> (REPL): <a name="repl"></a>
a <a href="#cli">command-line interface</a> that reads a command from the user,
executes it,
prints the result,
and waits for another command.</p>

<p><strong>record</strong> (in a database): <a name="record-database"></a>
A set of related values making up a single entry in a <a href="#table-database">database table</a>,
typically shown as a row.
See also: <a href="#field-database">field</a>.</p>

<p><strong>redirect</strong>: <a name="redirect"></a>
To send a command's output to a file rather than to the screen or another command,
or equivalently to read a command's input from a file.</p>

<p><strong>referential integrity</strong>: <a name="referential-integrity"></a>
The internal consistency of values in a database.
If an entry in one table contains a <a href="#foreign-key">foreign key</a>,
but the corresponding <a href="#record-database">records</a> don't exist,
referential integrity has been violated.</p>

<p><strong>regression</strong>: <a name="regression"></a>
To re-introduce a bug that was once fixed.</p>

<p><strong>regular expressions</strong> (RE): <a name="regular-expression"></a>
A pattern that specifies a set of character strings.
REs are most often used to find sequences of characters in strings.</p>

<p><strong>relational database</strong>: <a name="relational-database"></a>
A collection of data organized into <a href="#table-database">tables</a>.</p>

<p><strong>relative path</strong>: <a name="relative-path"></a>
A <a href="#path">path</a> that specifies the location of a file or directory
with respect to the <a href="#current-working-directory">current working directory</a>.
Any path that does not begin with a separator character ("/" or "") is a relative path.
See also: <a href="#absolute-path">absolute path</a>.</p>

<p><strong>remote repository</strong>: <a name="repository-remote"></a>
A version control <a href="#repository">repository</a> other than the current one
that the current one is somehow connected to or mirroring.</p>

<p><strong>repository</strong>: <a name="repository"></a>
A central storage area where a <a href="#version-control">version control</a> system
stores old <a href="#revision">revisions</a> of files
and information about who changed what, when.</p>

<p><strong>resolve</strong>: <a name="resolve"></a>
To eliminate the <a href="#conflict">conflicts</a> between two or more incompatible changes to a file or set of files
being managed by a <a href="#version-control">version control</a> system.</p>

<p><strong>return statement</strong>: <a name="return-statement"></a>
A statement that causes a function to stop executing and return a value to its caller immediately.</p>

<p><strong>revision</strong>: <a name="revision"></a>
A recorded state of a <a href="#version-control">version control</a> <a href="#repository">repository</a>.</p>

<p><strong>RGB</strong> (red-green-blue): <a name="rgb"></a>
An <a href="#additive-color-model">additive model</a>
that represents colors as combinations of red, green, and blue.
Each color's value is typically in the range 0..255
(i.e., a one-byte integer).</p>

<p><strong>root directory</strong>: <a name="root-directory"></a>
The top-most directory in a <a href="#filesystem">filesystem</a>.
Its name is "/" on Unix (including Linux and Mac OS X) and "" on Microsoft Windows.</p>

<p><strong>sentinel value</strong>: <a name="sentinel-value"></a>
A value in a collection that has a special meaning,
such as 999 to mean "age unknown".</p>

<p><strong>sequence</strong>: <a name="sequence"></a>
An ordered collection of values
whose elements can be specified with a single integer index,
such as a vector.</p>

<p><strong>shape</strong> (of an array): <a name="shape"></a>
An array's dimensions, represented as a vector.
For example, a 5&times;3 array's shape is <code>(5,3)</code>.</p>

<p><strong>shell</strong>: <a name="shell"></a>
A <a href="#cli">command-line interface</a>
such as Bash (the Bourne-Again Shell)
or the Microsoft Windows DOS shell
that allows a user to interact with the <a href="#operating-system">operating system</a>.</p>

<p><strong>shell script</strong>: <a name="shell-script"></a>
A set of <a href="#shell">shell</a> commands stored in a file for re-use.
A shell script is a program executed by the shell;
the name "script" is used for historical reasons.</p>

<p><strong>silent failure</strong>: <a name="silent-failure"></a>
Failing without producing any warning messages.
Silent failures are hard to detect and debug.</p>

<p><strong>slice</strong>: <a name="slice"></a>
A regular subsequence of a larger sequence,
such as the first five elements or every second element.</p>

<p><strong>SQL</strong> (Structured Query Language): <a name="sql"></a>
A special-purpose language for describing operations on <a href="#relational-database">relational databases</a>.</p>

<p><strong>SQL injection attack</strong>: <a name="sql-injection-attack"></a>
An attack on a program in which the user's input contains malicious SQL statements.
If this text is copied directly into an SQL statement,
it will be executed in the database.</p>

<p><strong>stack frame</strong>: <a name="stack-frame"></a>
A data structure that provides storage for a function's local variables.
Each time a function is called,
a new stack frame is created
and put on the top of the <a href="#call-stack">call stack</a>.
When the function returns,
the stack frame is discarded.</p>

<p><strong>standard input</strong> (stdin): <a name="standard-input"></a>
A process's default input stream.
In interactive command-line applications,
it is typically connected to the keyboard;;
in a <a href="#pipe">pipe</a>,
it receives data from the <a href="#standard-output">standard output</a> of the preceding process.</p>

<p><strong>standard output</strong> (stdout): <a name="standard-output"></a>
A process's default output stream.
In interactive command-line applications,
data sent to standard output is displayed on the screen;
in a <a href="#pipe">pipe</a>,
it is passed to the <a href="#standard-input">standard input</a> of the next process.</p>

<p><strong>stride</strong>: <a name="stride"></a>
The offset between successive elements of a <a href="#slice">slice</a>.</p>

<p><strong>string</strong>: <a name="string"></a>
Short for "character string",
a <a href="#sequence">sequence</a> of zero or more characters.</p>

<p><strong>sub-directory</strong>: <a name="sub-directory"></a>
A directory contained within another directory.</p>

<p><strong>tab completion</strong>: <a name="tab-completion"></a>
A feature provided by many interactive systems in which
pressing the Tab key triggers automatic completion of the current word or command.</p>

<p><strong>table</strong> (in a database): <a name="table-database"></a>
A set of data in a <a href="#relational-database">relational database</a>
organized into a set of <a href="#record-database">records</a>,
each having the same named <a href="#field-database">fields</a>.</p>

<p><strong>test oracle</strong>: <a name="test-oracle"></a>
A program, device, data set, or human being
against which the results of a test can be compared.</p>

<p><strong>test-driven development</strong> (TDD): <a name="test-driven-development"></a>
The practice of writing unit tests <em>before</em> writing the code they test.</p>

<p><strong>tuple</strong>: <a name="tuple"></a>
An <a href="#immutable">immutable</a> <a href="#sequence">sequence</a> of values.</p>

<p><strong>variable</strong>: <a name="variable"></a>
A name in a program that is associated with a value or a collection of values.</p>

<p><strong>version control</strong>: <a name="version-control"></a>
A tool for managing changes to a set of files.
Each set of changes creates a new <a href="#revision">revision</a> of the files;
the version control system allows users to recover old revisions reliably,
and helps manage conflicting changes made by different users.</p>

<p><strong>wildcard</strong>: <a name="wildcard"></a>
A character used in pattern matching.
In the Unix shell,
the wildcard "*" matches zero or more characters,
so that <code>*.txt</code> matches all files whose names end in <code>.txt</code>.</p>

          <h1>The Rules</h1>
          <ul>
  <li>
    <p>A week of hard work can sometimes save you an hour of thought. <a name="week-hard-work-hour-thought"></a></p>
  </li>
  <li>
    <p>Fail early, fail often. <a name="fail-early-fail-often"></a></p>
  </li>
  <li>
    <p>Turn bugs into assertions or tests. <a name="turn-bugs-into-assertions-or-tests"></a></p>
  </li>
  <li>
    <p>Red, green, refactor. <a name="red-green-refactor"></a></p>
  </li>
  <li>
    <p>Always initialize from data. <a name="always-initialize-from-data"></a></p>
  </li>
  <li>
    <p>Test the simple things first. <a name="test-simple-first"></a></p>
  </li>
  <li>
    <p>Know what it's supposed to do. <a name="know-what-its-supposed-to-do"></a></p>
  </li>
  <li>
    <p>Make it fail every time. <a name="make-it-fail-every-time"></a></p>
  </li>
  <li>
    <p>Make it fail fast. <a name="make-it-fail-fast"></a></p>
  </li>
  <li>
    <p>Change on thing at a time, for a reason. <a name="change-one-thing-at-a-time"></a></p>
  </li>
  <li>
    <p>Keep track of what you've done. <a name="keep-track-of-what-youve-done"></a></p>
  </li>
  <li>
    <p>Be humble. <a name="be-humble"></a></p>
  </li>
</ul>

	</div>
      </div>

</body>
</html>
